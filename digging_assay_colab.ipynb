{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBHDq7lvv-7t"
      },
      "outputs": [],
      "source": [
        "#Install the branch with tf2.x support:\n",
        "!pip install 'deeplabcut'==2.2.1\n",
        "!pip install tf_slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyhZ66Zk1Moa",
        "outputId": "6676d0a7-33ac-467b-e126-2238f750b5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Now, let's link to your GoogleDrive. Run this cell and follow the authorization instructions:\n",
        "#(We recommend putting a copy of the github repo in your google drive if you are using the demo \"examples\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vhENAlQnFENJ",
        "outputId": "fe2d4003-c782-43e6-8049-f8b11646b324"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/dlc-colab/maddie-digging/Digging Assay-Maddie-2022-06-13/config.yaml'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Setup your project variables:\n",
        "# PLEASE EDIT THESE:\n",
        "ProjectFolderName = 'dlc-colab/maddie-digging/Digging Assay-Maddie-2022-06-13' \n",
        "VideoType = 'avi' \n",
        "\n",
        "#don't edit these:\n",
        "videofile_path = ['/content/drive/My Drive/'+ProjectFolderName+'/videos/'] #Enter the list of videos or folder to analyze.\n",
        "videofile_path\n",
        "\n",
        "#This creates a path variable that links to your google drive copy\n",
        "#No need to edit this, as you set it up before: \n",
        "path_config_file = '/content/drive/My Drive/'+ProjectFolderName+'/config.yaml'\n",
        "path_config_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSc2HDQ21bfa",
        "outputId": "9debbff5-cf76-44ca-cb42-a5483eefc3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n",
            "2.8.2\n",
            "2.2.1\n"
          ]
        }
      ],
      "source": [
        "import deeplabcut\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "print(deeplabcut.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl7G4u_QXLbe",
        "outputId": "58cbe52c-931d-4bed-ec07-474e66ad466e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jun 22 01:12:34 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5s1qlnvBQ8n"
      },
      "source": [
        "Create Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv1S_sRLBDtZ"
      },
      "outputs": [],
      "source": [
        "#Set the shuffle you want to create, train, evaluate, use for analysis, etc (1 is default):\n",
        "SHUF = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNYbEThdBFoP",
        "outputId": "7ad7a6d9-6b01-4d58-cbb8-aca8a18fecb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0.95,\n",
              "  1,\n",
              "  (array([157, 235,  96, 213, 172, 135, 210, 113, 233,  75,  50,  47,  78,\n",
              "           62,  21, 141, 194, 219, 209,  95, 184,  90, 185,  98,  12, 236,\n",
              "           42,  15, 107, 134, 179, 191,  40, 231, 183, 229,  10,  82, 170,\n",
              "          222, 100,   1, 232, 171, 186, 211,  19, 125, 230, 165,  77,  76,\n",
              "          148, 104, 175, 205, 228, 132,  57,  37, 188, 216, 137,  54, 193,\n",
              "           86, 119, 153,  23,  56, 156,  60, 234,  71,   6, 130, 237,   7,\n",
              "          204, 124, 118,  38, 154, 127, 180, 161, 177, 182, 192, 115, 208,\n",
              "           59,  48, 102,  70,  65, 144, 139, 155,  55, 174, 142, 121, 207,\n",
              "          109, 212, 169, 159,  99, 238, 163,  49, 110,  52,  74,  26,  45,\n",
              "          226, 227,   4,  11,  53, 147,  79,   8, 214,   5, 143, 224, 166,\n",
              "          122,  22,  68,  20, 160,  14,  32, 195,  64, 152, 201,  81,  58,\n",
              "           13, 187,  72,  87, 123, 164, 196, 206,  51, 198,  24,  94, 106,\n",
              "           16,  63, 128, 105,  28,  73,  89, 149,  93, 239,  83,  43,  92,\n",
              "           18, 145, 158, 150,  39, 225, 223, 200, 111,  66, 117, 221, 140,\n",
              "          101,  69,   2,  84,  17, 146, 217,  29,  30, 114, 202, 103,  67,\n",
              "           25, 176, 215, 116, 168,  91, 120,  35, 112, 129, 189, 136, 190,\n",
              "           80, 181, 126, 197, 220, 203,   0,  36, 133,  33,  88, 162,  34,\n",
              "           44,  97,  85,  61, 167, 199, 173]),\n",
              "   array([ 27, 138,   9,  31,   3, 108, 178, 218,  46, 131, 151,  41])))]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note: if you are using the demo data (i.e. examples/Reaching-Mackenzie-2018-08-30/), first delete the folder called dlc-models! \n",
        "#Then, run this cell. There are many more functions you can set here, including which network to use.\n",
        "#check the docstring for full options you can do!\n",
        "deeplabcut.create_training_dataset(path_config_file, net_type='resnet_50', augmenter_type='imgaug')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5hhcfk7BOdf"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya0hV6SIBI1X",
        "outputId": "cee7fd5d-b10c-4ead-e3c4-cc1b4d54b991"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2]],\n",
            " 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3'],\n",
            " 'alpha_r': 0.02,\n",
            " 'apply_prob': 0.5,\n",
            " 'batch_size': 1,\n",
            " 'clahe': True,\n",
            " 'claheratio': 0.1,\n",
            " 'crop_pad': 0,\n",
            " 'cropratio': 0.4,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Digging '\n",
            "            'AssayJun13/Digging Assay_Maddie95shuffle1.mat',\n",
            " 'dataset_type': 'imgaug',\n",
            " 'decay_steps': 30000,\n",
            " 'deterministic': False,\n",
            " 'display_iters': 1000,\n",
            " 'edge': False,\n",
            " 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'histeq': True,\n",
            " 'histeqratio': 0.1,\n",
            " 'init_weights': '/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 0.05,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'lr_init': 0.0005,\n",
            " 'max_input_size': 1500,\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Digging '\n",
            "                'AssayJun13/Documentation_data-Digging Assay_95shuffle1.pickle',\n",
            " 'min_input_size': 64,\n",
            " 'mirror': False,\n",
            " 'multi_stage': False,\n",
            " 'multi_step': [[0.005, 10000],\n",
            "                [0.02, 430000],\n",
            "                [0.002, 730000],\n",
            "                [0.001, 1030000]],\n",
            " 'net_type': 'resnet_50',\n",
            " 'num_joints': 3,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': False,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_predict': False,\n",
            " 'pos_dist_thresh': 17,\n",
            " 'project_path': '/content/drive/My Drive/dlc-colab/maddie-digging/Digging '\n",
            "                 'Assay-Maddie-2022-06-13',\n",
            " 'regularize': False,\n",
            " 'rotation': 25,\n",
            " 'rotratio': 0.4,\n",
            " 'save_iters': 50000,\n",
            " 'scale_jitter_lo': 0.5,\n",
            " 'scale_jitter_up': 1.25,\n",
            " 'scoremap_dir': 'test',\n",
            " 'sharpen': False,\n",
            " 'sharpenratio': 0.3,\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My Drive/dlc-colab/maddie-digging/Digging '\n",
            "                    'Assay-Maddie-2022-06-13/dlc-models/iteration-0/Digging '\n",
            "                    'AssayJun13-trainset95shuffle1/train/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting single-animal trainer\n",
            "Batch Size is 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  outputs = layer.apply(inputs, training=is_training)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ImageNet-pretrained resnet_50\n",
            "Max_iters overwritten as 500000\n",
            "Display_iters overwritten as 10\n",
            "Save_iters overwritten as 500\n",
            "Training parameter:\n",
            "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/content/drive/My Drive/dlc-colab/maddie-digging/Digging Assay-Maddie-2022-06-13/dlc-models/iteration-0/Digging AssayJun13-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'clahe': True, 'claheratio': 0.1, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Digging AssayJun13/Digging Assay_Maddie95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]}, 'histeq': True, 'histeqratio': 0.1, 'init_weights': '/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Digging AssayJun13/Documentation_data-Digging Assay_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 3, 'pos_dist_thresh': 17, 'project_path': '/content/drive/My Drive/dlc-colab/maddie-digging/Digging Assay-Maddie-2022-06-13', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'sharpen': False, 'sharpenratio': 0.3, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
            "Starting training....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "iteration: 373680 loss: 0.0017 lr: 0.02\n",
            "iteration: 373690 loss: 0.0016 lr: 0.02\n",
            "iteration: 373700 loss: 0.0014 lr: 0.02\n",
            "iteration: 373710 loss: 0.0018 lr: 0.02\n",
            "iteration: 373720 loss: 0.0017 lr: 0.02\n",
            "iteration: 373730 loss: 0.0014 lr: 0.02\n",
            "iteration: 373740 loss: 0.0018 lr: 0.02\n",
            "iteration: 373750 loss: 0.0017 lr: 0.02\n",
            "iteration: 373760 loss: 0.0017 lr: 0.02\n",
            "iteration: 373770 loss: 0.0016 lr: 0.02\n",
            "iteration: 373780 loss: 0.0016 lr: 0.02\n",
            "iteration: 373790 loss: 0.0016 lr: 0.02\n",
            "iteration: 373800 loss: 0.0019 lr: 0.02\n",
            "iteration: 373810 loss: 0.0013 lr: 0.02\n",
            "iteration: 373820 loss: 0.0023 lr: 0.02\n",
            "iteration: 373830 loss: 0.0019 lr: 0.02\n",
            "iteration: 373840 loss: 0.0019 lr: 0.02\n",
            "iteration: 373850 loss: 0.0018 lr: 0.02\n",
            "iteration: 373860 loss: 0.0021 lr: 0.02\n",
            "iteration: 373870 loss: 0.0020 lr: 0.02\n",
            "iteration: 373880 loss: 0.0013 lr: 0.02\n",
            "iteration: 373890 loss: 0.0018 lr: 0.02\n",
            "iteration: 373900 loss: 0.0024 lr: 0.02\n",
            "iteration: 373910 loss: 0.0016 lr: 0.02\n",
            "iteration: 373920 loss: 0.0015 lr: 0.02\n",
            "iteration: 373930 loss: 0.0018 lr: 0.02\n",
            "iteration: 373940 loss: 0.0019 lr: 0.02\n",
            "iteration: 373950 loss: 0.0018 lr: 0.02\n",
            "iteration: 373960 loss: 0.0022 lr: 0.02\n",
            "iteration: 373970 loss: 0.0016 lr: 0.02\n",
            "iteration: 373980 loss: 0.0017 lr: 0.02\n",
            "iteration: 373990 loss: 0.0018 lr: 0.02\n",
            "iteration: 374000 loss: 0.0017 lr: 0.02\n",
            "iteration: 374010 loss: 0.0015 lr: 0.02\n",
            "iteration: 374020 loss: 0.0016 lr: 0.02\n",
            "iteration: 374030 loss: 0.0021 lr: 0.02\n",
            "iteration: 374040 loss: 0.0013 lr: 0.02\n",
            "iteration: 374050 loss: 0.0015 lr: 0.02\n",
            "iteration: 374060 loss: 0.0025 lr: 0.02\n",
            "iteration: 374070 loss: 0.0022 lr: 0.02\n",
            "iteration: 374080 loss: 0.0018 lr: 0.02\n",
            "iteration: 374090 loss: 0.0019 lr: 0.02\n",
            "iteration: 374100 loss: 0.0017 lr: 0.02\n",
            "iteration: 374110 loss: 0.0010 lr: 0.02\n",
            "iteration: 374120 loss: 0.0017 lr: 0.02\n",
            "iteration: 374130 loss: 0.0019 lr: 0.02\n",
            "iteration: 374140 loss: 0.0017 lr: 0.02\n",
            "iteration: 374150 loss: 0.0019 lr: 0.02\n",
            "iteration: 374160 loss: 0.0016 lr: 0.02\n",
            "iteration: 374170 loss: 0.0023 lr: 0.02\n",
            "iteration: 374180 loss: 0.0021 lr: 0.02\n",
            "iteration: 374190 loss: 0.0021 lr: 0.02\n",
            "iteration: 374200 loss: 0.0014 lr: 0.02\n",
            "iteration: 374210 loss: 0.0021 lr: 0.02\n",
            "iteration: 374220 loss: 0.0018 lr: 0.02\n",
            "iteration: 374230 loss: 0.0017 lr: 0.02\n",
            "iteration: 374240 loss: 0.0017 lr: 0.02\n",
            "iteration: 374250 loss: 0.0015 lr: 0.02\n",
            "iteration: 374260 loss: 0.0020 lr: 0.02\n",
            "iteration: 374270 loss: 0.0015 lr: 0.02\n",
            "iteration: 374280 loss: 0.0015 lr: 0.02\n",
            "iteration: 374290 loss: 0.0017 lr: 0.02\n",
            "iteration: 374300 loss: 0.0017 lr: 0.02\n",
            "iteration: 374310 loss: 0.0025 lr: 0.02\n",
            "iteration: 374320 loss: 0.0015 lr: 0.02\n",
            "iteration: 374330 loss: 0.0015 lr: 0.02\n",
            "iteration: 374340 loss: 0.0017 lr: 0.02\n",
            "iteration: 374350 loss: 0.0012 lr: 0.02\n",
            "iteration: 374360 loss: 0.0018 lr: 0.02\n",
            "iteration: 374370 loss: 0.0018 lr: 0.02\n",
            "iteration: 374380 loss: 0.0021 lr: 0.02\n",
            "iteration: 374390 loss: 0.0014 lr: 0.02\n",
            "iteration: 374400 loss: 0.0023 lr: 0.02\n",
            "iteration: 374410 loss: 0.0019 lr: 0.02\n",
            "iteration: 374420 loss: 0.0015 lr: 0.02\n",
            "iteration: 374430 loss: 0.0014 lr: 0.02\n",
            "iteration: 374440 loss: 0.0015 lr: 0.02\n",
            "iteration: 374450 loss: 0.0012 lr: 0.02\n",
            "iteration: 374460 loss: 0.0014 lr: 0.02\n",
            "iteration: 374470 loss: 0.0019 lr: 0.02\n",
            "iteration: 374480 loss: 0.0014 lr: 0.02\n",
            "iteration: 374490 loss: 0.0016 lr: 0.02\n",
            "iteration: 374500 loss: 0.0016 lr: 0.02\n",
            "iteration: 374510 loss: 0.0015 lr: 0.02\n",
            "iteration: 374520 loss: 0.0018 lr: 0.02\n",
            "iteration: 374530 loss: 0.0015 lr: 0.02\n",
            "iteration: 374540 loss: 0.0020 lr: 0.02\n",
            "iteration: 374550 loss: 0.0021 lr: 0.02\n",
            "iteration: 374560 loss: 0.0020 lr: 0.02\n",
            "iteration: 374570 loss: 0.0020 lr: 0.02\n",
            "iteration: 374580 loss: 0.0014 lr: 0.02\n",
            "iteration: 374590 loss: 0.0022 lr: 0.02\n",
            "iteration: 374600 loss: 0.0015 lr: 0.02\n",
            "iteration: 374610 loss: 0.0020 lr: 0.02\n",
            "iteration: 374620 loss: 0.0016 lr: 0.02\n",
            "iteration: 374630 loss: 0.0016 lr: 0.02\n",
            "iteration: 374640 loss: 0.0019 lr: 0.02\n",
            "iteration: 374650 loss: 0.0018 lr: 0.02\n",
            "iteration: 374660 loss: 0.0017 lr: 0.02\n",
            "iteration: 374670 loss: 0.0021 lr: 0.02\n",
            "iteration: 374680 loss: 0.0018 lr: 0.02\n",
            "iteration: 374690 loss: 0.0018 lr: 0.02\n",
            "iteration: 374700 loss: 0.0020 lr: 0.02\n",
            "iteration: 374710 loss: 0.0013 lr: 0.02\n",
            "iteration: 374720 loss: 0.0017 lr: 0.02\n",
            "iteration: 374730 loss: 0.0015 lr: 0.02\n",
            "iteration: 374740 loss: 0.0014 lr: 0.02\n",
            "iteration: 374750 loss: 0.0014 lr: 0.02\n",
            "iteration: 374760 loss: 0.0016 lr: 0.02\n",
            "iteration: 374770 loss: 0.0022 lr: 0.02\n",
            "iteration: 374780 loss: 0.0016 lr: 0.02\n",
            "iteration: 374790 loss: 0.0014 lr: 0.02\n",
            "iteration: 374800 loss: 0.0019 lr: 0.02\n",
            "iteration: 374810 loss: 0.0020 lr: 0.02\n",
            "iteration: 374820 loss: 0.0018 lr: 0.02\n",
            "iteration: 374830 loss: 0.0018 lr: 0.02\n",
            "iteration: 374840 loss: 0.0016 lr: 0.02\n",
            "iteration: 374850 loss: 0.0015 lr: 0.02\n",
            "iteration: 374860 loss: 0.0017 lr: 0.02\n",
            "iteration: 374870 loss: 0.0019 lr: 0.02\n",
            "iteration: 374880 loss: 0.0018 lr: 0.02\n",
            "iteration: 374890 loss: 0.0014 lr: 0.02\n",
            "iteration: 374900 loss: 0.0019 lr: 0.02\n",
            "iteration: 374910 loss: 0.0021 lr: 0.02\n",
            "iteration: 374920 loss: 0.0012 lr: 0.02\n",
            "iteration: 374930 loss: 0.0015 lr: 0.02\n",
            "iteration: 374940 loss: 0.0015 lr: 0.02\n",
            "iteration: 374950 loss: 0.0011 lr: 0.02\n",
            "iteration: 374960 loss: 0.0015 lr: 0.02\n",
            "iteration: 374970 loss: 0.0013 lr: 0.02\n",
            "iteration: 374980 loss: 0.0019 lr: 0.02\n",
            "iteration: 374990 loss: 0.0015 lr: 0.02\n",
            "iteration: 375000 loss: 0.0023 lr: 0.02\n",
            "iteration: 375010 loss: 0.0017 lr: 0.02\n",
            "iteration: 375020 loss: 0.0015 lr: 0.02\n",
            "iteration: 375030 loss: 0.0011 lr: 0.02\n",
            "iteration: 375040 loss: 0.0017 lr: 0.02\n",
            "iteration: 375050 loss: 0.0014 lr: 0.02\n",
            "iteration: 375060 loss: 0.0013 lr: 0.02\n",
            "iteration: 375070 loss: 0.0016 lr: 0.02\n",
            "iteration: 375080 loss: 0.0013 lr: 0.02\n",
            "iteration: 375090 loss: 0.0016 lr: 0.02\n",
            "iteration: 375100 loss: 0.0018 lr: 0.02\n",
            "iteration: 375110 loss: 0.0015 lr: 0.02\n",
            "iteration: 375120 loss: 0.0018 lr: 0.02\n",
            "iteration: 375130 loss: 0.0013 lr: 0.02\n",
            "iteration: 375140 loss: 0.0017 lr: 0.02\n",
            "iteration: 375150 loss: 0.0023 lr: 0.02\n",
            "iteration: 375160 loss: 0.0014 lr: 0.02\n",
            "iteration: 375170 loss: 0.0016 lr: 0.02\n",
            "iteration: 375180 loss: 0.0019 lr: 0.02\n",
            "iteration: 375190 loss: 0.0018 lr: 0.02\n",
            "iteration: 375200 loss: 0.0010 lr: 0.02\n",
            "iteration: 375210 loss: 0.0019 lr: 0.02\n",
            "iteration: 375220 loss: 0.0019 lr: 0.02\n",
            "iteration: 375230 loss: 0.0012 lr: 0.02\n",
            "iteration: 375240 loss: 0.0022 lr: 0.02\n",
            "iteration: 375250 loss: 0.0017 lr: 0.02\n",
            "iteration: 375260 loss: 0.0012 lr: 0.02\n",
            "iteration: 375270 loss: 0.0015 lr: 0.02\n",
            "iteration: 375280 loss: 0.0016 lr: 0.02\n",
            "iteration: 375290 loss: 0.0016 lr: 0.02\n",
            "iteration: 375300 loss: 0.0013 lr: 0.02\n",
            "iteration: 375310 loss: 0.0017 lr: 0.02\n",
            "iteration: 375320 loss: 0.0020 lr: 0.02\n",
            "iteration: 375330 loss: 0.0012 lr: 0.02\n",
            "iteration: 375340 loss: 0.0022 lr: 0.02\n",
            "iteration: 375350 loss: 0.0018 lr: 0.02\n",
            "iteration: 375360 loss: 0.0018 lr: 0.02\n",
            "iteration: 375370 loss: 0.0019 lr: 0.02\n",
            "iteration: 375380 loss: 0.0015 lr: 0.02\n",
            "iteration: 375390 loss: 0.0019 lr: 0.02\n",
            "iteration: 375400 loss: 0.0013 lr: 0.02\n",
            "iteration: 375410 loss: 0.0017 lr: 0.02\n",
            "iteration: 375420 loss: 0.0016 lr: 0.02\n",
            "iteration: 375430 loss: 0.0015 lr: 0.02\n",
            "iteration: 375440 loss: 0.0016 lr: 0.02\n",
            "iteration: 375450 loss: 0.0013 lr: 0.02\n",
            "iteration: 375460 loss: 0.0015 lr: 0.02\n",
            "iteration: 375470 loss: 0.0016 lr: 0.02\n",
            "iteration: 375480 loss: 0.0020 lr: 0.02\n",
            "iteration: 375490 loss: 0.0018 lr: 0.02\n",
            "iteration: 375500 loss: 0.0019 lr: 0.02\n",
            "iteration: 375510 loss: 0.0019 lr: 0.02\n",
            "iteration: 375520 loss: 0.0016 lr: 0.02\n",
            "iteration: 375530 loss: 0.0016 lr: 0.02\n",
            "iteration: 375540 loss: 0.0016 lr: 0.02\n",
            "iteration: 375550 loss: 0.0016 lr: 0.02\n",
            "iteration: 375560 loss: 0.0018 lr: 0.02\n",
            "iteration: 375570 loss: 0.0026 lr: 0.02\n",
            "iteration: 375580 loss: 0.0016 lr: 0.02\n",
            "iteration: 375590 loss: 0.0024 lr: 0.02\n",
            "iteration: 375600 loss: 0.0017 lr: 0.02\n",
            "iteration: 375610 loss: 0.0011 lr: 0.02\n",
            "iteration: 375620 loss: 0.0021 lr: 0.02\n",
            "iteration: 375630 loss: 0.0015 lr: 0.02\n",
            "iteration: 375640 loss: 0.0016 lr: 0.02\n",
            "iteration: 375650 loss: 0.0015 lr: 0.02\n",
            "iteration: 375660 loss: 0.0019 lr: 0.02\n",
            "iteration: 375670 loss: 0.0013 lr: 0.02\n",
            "iteration: 375680 loss: 0.0017 lr: 0.02\n",
            "iteration: 375690 loss: 0.0016 lr: 0.02\n",
            "iteration: 375700 loss: 0.0012 lr: 0.02\n",
            "iteration: 375710 loss: 0.0023 lr: 0.02\n",
            "iteration: 375720 loss: 0.0014 lr: 0.02\n",
            "iteration: 375730 loss: 0.0014 lr: 0.02\n",
            "iteration: 375740 loss: 0.0017 lr: 0.02\n",
            "iteration: 375750 loss: 0.0018 lr: 0.02\n",
            "iteration: 375760 loss: 0.0016 lr: 0.02\n",
            "iteration: 375770 loss: 0.0010 lr: 0.02\n",
            "iteration: 375780 loss: 0.0019 lr: 0.02\n",
            "iteration: 375790 loss: 0.0015 lr: 0.02\n",
            "iteration: 375800 loss: 0.0016 lr: 0.02\n",
            "iteration: 375810 loss: 0.0020 lr: 0.02\n",
            "iteration: 375820 loss: 0.0019 lr: 0.02\n",
            "iteration: 375830 loss: 0.0019 lr: 0.02\n",
            "iteration: 375840 loss: 0.0015 lr: 0.02\n",
            "iteration: 375850 loss: 0.0018 lr: 0.02\n",
            "iteration: 375860 loss: 0.0020 lr: 0.02\n",
            "iteration: 375870 loss: 0.0013 lr: 0.02\n",
            "iteration: 375880 loss: 0.0011 lr: 0.02\n",
            "iteration: 375890 loss: 0.0018 lr: 0.02\n",
            "iteration: 375900 loss: 0.0017 lr: 0.02\n",
            "iteration: 375910 loss: 0.0013 lr: 0.02\n",
            "iteration: 375920 loss: 0.0023 lr: 0.02\n",
            "iteration: 375930 loss: 0.0015 lr: 0.02\n",
            "iteration: 375940 loss: 0.0019 lr: 0.02\n",
            "iteration: 375950 loss: 0.0017 lr: 0.02\n",
            "iteration: 375960 loss: 0.0014 lr: 0.02\n",
            "iteration: 375970 loss: 0.0016 lr: 0.02\n",
            "iteration: 375980 loss: 0.0017 lr: 0.02\n",
            "iteration: 375990 loss: 0.0012 lr: 0.02\n",
            "iteration: 376000 loss: 0.0021 lr: 0.02\n",
            "iteration: 376010 loss: 0.0012 lr: 0.02\n",
            "iteration: 376020 loss: 0.0013 lr: 0.02\n",
            "iteration: 376030 loss: 0.0016 lr: 0.02\n",
            "iteration: 376040 loss: 0.0018 lr: 0.02\n",
            "iteration: 376050 loss: 0.0022 lr: 0.02\n",
            "iteration: 376060 loss: 0.0020 lr: 0.02\n",
            "iteration: 376070 loss: 0.0017 lr: 0.02\n",
            "iteration: 376080 loss: 0.0014 lr: 0.02\n",
            "iteration: 376090 loss: 0.0015 lr: 0.02\n",
            "iteration: 376100 loss: 0.0012 lr: 0.02\n",
            "iteration: 376110 loss: 0.0014 lr: 0.02\n",
            "iteration: 376120 loss: 0.0013 lr: 0.02\n",
            "iteration: 376130 loss: 0.0021 lr: 0.02\n",
            "iteration: 376140 loss: 0.0015 lr: 0.02\n",
            "iteration: 376150 loss: 0.0014 lr: 0.02\n",
            "iteration: 376160 loss: 0.0014 lr: 0.02\n",
            "iteration: 376170 loss: 0.0015 lr: 0.02\n",
            "iteration: 376180 loss: 0.0014 lr: 0.02\n",
            "iteration: 376190 loss: 0.0018 lr: 0.02\n",
            "iteration: 376200 loss: 0.0017 lr: 0.02\n",
            "iteration: 376210 loss: 0.0021 lr: 0.02\n",
            "iteration: 376220 loss: 0.0024 lr: 0.02\n",
            "iteration: 376230 loss: 0.0021 lr: 0.02\n",
            "iteration: 376240 loss: 0.0015 lr: 0.02\n",
            "iteration: 376250 loss: 0.0017 lr: 0.02\n",
            "iteration: 376260 loss: 0.0018 lr: 0.02\n",
            "iteration: 376270 loss: 0.0019 lr: 0.02\n",
            "iteration: 376280 loss: 0.0014 lr: 0.02\n",
            "iteration: 376290 loss: 0.0015 lr: 0.02\n",
            "iteration: 376300 loss: 0.0021 lr: 0.02\n",
            "iteration: 376310 loss: 0.0018 lr: 0.02\n",
            "iteration: 376320 loss: 0.0013 lr: 0.02\n",
            "iteration: 376330 loss: 0.0017 lr: 0.02\n",
            "iteration: 376340 loss: 0.0015 lr: 0.02\n",
            "iteration: 376350 loss: 0.0019 lr: 0.02\n",
            "iteration: 376360 loss: 0.0016 lr: 0.02\n",
            "iteration: 376370 loss: 0.0017 lr: 0.02\n",
            "iteration: 376380 loss: 0.0013 lr: 0.02\n",
            "iteration: 376390 loss: 0.0018 lr: 0.02\n",
            "iteration: 376400 loss: 0.0013 lr: 0.02\n",
            "iteration: 376410 loss: 0.0017 lr: 0.02\n",
            "iteration: 376420 loss: 0.0012 lr: 0.02\n",
            "iteration: 376430 loss: 0.0020 lr: 0.02\n",
            "iteration: 376440 loss: 0.0017 lr: 0.02\n",
            "iteration: 376450 loss: 0.0018 lr: 0.02\n",
            "iteration: 376460 loss: 0.0012 lr: 0.02\n",
            "iteration: 376470 loss: 0.0020 lr: 0.02\n",
            "iteration: 376480 loss: 0.0016 lr: 0.02\n",
            "iteration: 376490 loss: 0.0023 lr: 0.02\n",
            "iteration: 376500 loss: 0.0026 lr: 0.02\n",
            "iteration: 376510 loss: 0.0016 lr: 0.02\n",
            "iteration: 376520 loss: 0.0013 lr: 0.02\n",
            "iteration: 376530 loss: 0.0016 lr: 0.02\n",
            "iteration: 376540 loss: 0.0015 lr: 0.02\n",
            "iteration: 376550 loss: 0.0018 lr: 0.02\n",
            "iteration: 376560 loss: 0.0015 lr: 0.02\n",
            "iteration: 376570 loss: 0.0014 lr: 0.02\n",
            "iteration: 376580 loss: 0.0014 lr: 0.02\n",
            "iteration: 376590 loss: 0.0020 lr: 0.02\n",
            "iteration: 376600 loss: 0.0016 lr: 0.02\n",
            "iteration: 376610 loss: 0.0012 lr: 0.02\n",
            "iteration: 376620 loss: 0.0019 lr: 0.02\n",
            "iteration: 376630 loss: 0.0015 lr: 0.02\n",
            "iteration: 376640 loss: 0.0016 lr: 0.02\n",
            "iteration: 376650 loss: 0.0016 lr: 0.02\n",
            "iteration: 376660 loss: 0.0017 lr: 0.02\n",
            "iteration: 376670 loss: 0.0019 lr: 0.02\n",
            "iteration: 376680 loss: 0.0013 lr: 0.02\n",
            "iteration: 376690 loss: 0.0014 lr: 0.02\n",
            "iteration: 376700 loss: 0.0017 lr: 0.02\n",
            "iteration: 376710 loss: 0.0020 lr: 0.02\n",
            "iteration: 376720 loss: 0.0014 lr: 0.02\n",
            "iteration: 376730 loss: 0.0018 lr: 0.02\n",
            "iteration: 376740 loss: 0.0013 lr: 0.02\n",
            "iteration: 376750 loss: 0.0014 lr: 0.02\n",
            "iteration: 376760 loss: 0.0013 lr: 0.02\n",
            "iteration: 376770 loss: 0.0012 lr: 0.02\n",
            "iteration: 376780 loss: 0.0015 lr: 0.02\n",
            "iteration: 376790 loss: 0.0014 lr: 0.02\n",
            "iteration: 376800 loss: 0.0011 lr: 0.02\n",
            "iteration: 376810 loss: 0.0015 lr: 0.02\n",
            "iteration: 376820 loss: 0.0011 lr: 0.02\n",
            "iteration: 376830 loss: 0.0021 lr: 0.02\n",
            "iteration: 376840 loss: 0.0018 lr: 0.02\n",
            "iteration: 376850 loss: 0.0015 lr: 0.02\n",
            "iteration: 376860 loss: 0.0017 lr: 0.02\n",
            "iteration: 376870 loss: 0.0022 lr: 0.02\n",
            "iteration: 376880 loss: 0.0017 lr: 0.02\n",
            "iteration: 376890 loss: 0.0010 lr: 0.02\n",
            "iteration: 376900 loss: 0.0013 lr: 0.02\n",
            "iteration: 376910 loss: 0.0017 lr: 0.02\n",
            "iteration: 376920 loss: 0.0017 lr: 0.02\n",
            "iteration: 376930 loss: 0.0020 lr: 0.02\n",
            "iteration: 376940 loss: 0.0018 lr: 0.02\n",
            "iteration: 376950 loss: 0.0021 lr: 0.02\n",
            "iteration: 376960 loss: 0.0017 lr: 0.02\n",
            "iteration: 376970 loss: 0.0018 lr: 0.02\n",
            "iteration: 376980 loss: 0.0013 lr: 0.02\n",
            "iteration: 376990 loss: 0.0012 lr: 0.02\n",
            "iteration: 377000 loss: 0.0014 lr: 0.02\n",
            "iteration: 377010 loss: 0.0015 lr: 0.02\n",
            "iteration: 377020 loss: 0.0012 lr: 0.02\n",
            "iteration: 377030 loss: 0.0020 lr: 0.02\n",
            "iteration: 377040 loss: 0.0033 lr: 0.02\n",
            "iteration: 377050 loss: 0.0015 lr: 0.02\n",
            "iteration: 377060 loss: 0.0016 lr: 0.02\n",
            "iteration: 377070 loss: 0.0019 lr: 0.02\n",
            "iteration: 377080 loss: 0.0015 lr: 0.02\n",
            "iteration: 377090 loss: 0.0015 lr: 0.02\n",
            "iteration: 377100 loss: 0.0014 lr: 0.02\n",
            "iteration: 377110 loss: 0.0021 lr: 0.02\n",
            "iteration: 377120 loss: 0.0020 lr: 0.02\n",
            "iteration: 377130 loss: 0.0020 lr: 0.02\n",
            "iteration: 377140 loss: 0.0020 lr: 0.02\n",
            "iteration: 377150 loss: 0.0018 lr: 0.02\n",
            "iteration: 377160 loss: 0.0020 lr: 0.02\n",
            "iteration: 377170 loss: 0.0021 lr: 0.02\n",
            "iteration: 377180 loss: 0.0018 lr: 0.02\n",
            "iteration: 377190 loss: 0.0014 lr: 0.02\n",
            "iteration: 377200 loss: 0.0017 lr: 0.02\n",
            "iteration: 377210 loss: 0.0016 lr: 0.02\n",
            "iteration: 377220 loss: 0.0015 lr: 0.02\n",
            "iteration: 377230 loss: 0.0017 lr: 0.02\n",
            "iteration: 377240 loss: 0.0022 lr: 0.02\n",
            "iteration: 377250 loss: 0.0019 lr: 0.02\n",
            "iteration: 377260 loss: 0.0014 lr: 0.02\n",
            "iteration: 377270 loss: 0.0016 lr: 0.02\n",
            "iteration: 377280 loss: 0.0016 lr: 0.02\n",
            "iteration: 377290 loss: 0.0016 lr: 0.02\n",
            "iteration: 377300 loss: 0.0011 lr: 0.02\n",
            "iteration: 377310 loss: 0.0013 lr: 0.02\n",
            "iteration: 377320 loss: 0.0015 lr: 0.02\n",
            "iteration: 377330 loss: 0.0026 lr: 0.02\n",
            "iteration: 377340 loss: 0.0019 lr: 0.02\n",
            "iteration: 377350 loss: 0.0014 lr: 0.02\n",
            "iteration: 377360 loss: 0.0015 lr: 0.02\n",
            "iteration: 377370 loss: 0.0020 lr: 0.02\n",
            "iteration: 377380 loss: 0.0020 lr: 0.02\n",
            "iteration: 377390 loss: 0.0017 lr: 0.02\n",
            "iteration: 377400 loss: 0.0024 lr: 0.02\n",
            "iteration: 377410 loss: 0.0020 lr: 0.02\n",
            "iteration: 377420 loss: 0.0014 lr: 0.02\n",
            "iteration: 377430 loss: 0.0015 lr: 0.02\n",
            "iteration: 377440 loss: 0.0015 lr: 0.02\n",
            "iteration: 377450 loss: 0.0017 lr: 0.02\n",
            "iteration: 377460 loss: 0.0024 lr: 0.02\n",
            "iteration: 377470 loss: 0.0024 lr: 0.02\n",
            "iteration: 377480 loss: 0.0014 lr: 0.02\n",
            "iteration: 377490 loss: 0.0018 lr: 0.02\n",
            "iteration: 377500 loss: 0.0018 lr: 0.02\n",
            "iteration: 377510 loss: 0.0013 lr: 0.02\n",
            "iteration: 377520 loss: 0.0019 lr: 0.02\n",
            "iteration: 377530 loss: 0.0014 lr: 0.02\n",
            "iteration: 377540 loss: 0.0021 lr: 0.02\n",
            "iteration: 377550 loss: 0.0017 lr: 0.02\n",
            "iteration: 377560 loss: 0.0021 lr: 0.02\n",
            "iteration: 377570 loss: 0.0015 lr: 0.02\n",
            "iteration: 377580 loss: 0.0014 lr: 0.02\n",
            "iteration: 377590 loss: 0.0016 lr: 0.02\n",
            "iteration: 377600 loss: 0.0015 lr: 0.02\n",
            "iteration: 377610 loss: 0.0017 lr: 0.02\n",
            "iteration: 377620 loss: 0.0020 lr: 0.02\n",
            "iteration: 377630 loss: 0.0014 lr: 0.02\n",
            "iteration: 377640 loss: 0.0017 lr: 0.02\n",
            "iteration: 377650 loss: 0.0015 lr: 0.02\n",
            "iteration: 377660 loss: 0.0015 lr: 0.02\n",
            "iteration: 377670 loss: 0.0019 lr: 0.02\n",
            "iteration: 377680 loss: 0.0021 lr: 0.02\n",
            "iteration: 377690 loss: 0.0016 lr: 0.02\n",
            "iteration: 377700 loss: 0.0024 lr: 0.02\n",
            "iteration: 377710 loss: 0.0017 lr: 0.02\n",
            "iteration: 377720 loss: 0.0011 lr: 0.02\n",
            "iteration: 377730 loss: 0.0021 lr: 0.02\n",
            "iteration: 377740 loss: 0.0017 lr: 0.02\n",
            "iteration: 377750 loss: 0.0015 lr: 0.02\n",
            "iteration: 377760 loss: 0.0014 lr: 0.02\n",
            "iteration: 377770 loss: 0.0016 lr: 0.02\n",
            "iteration: 377780 loss: 0.0012 lr: 0.02\n",
            "iteration: 377790 loss: 0.0016 lr: 0.02\n",
            "iteration: 377800 loss: 0.0015 lr: 0.02\n",
            "iteration: 377810 loss: 0.0018 lr: 0.02\n",
            "iteration: 377820 loss: 0.0016 lr: 0.02\n",
            "iteration: 377830 loss: 0.0014 lr: 0.02\n",
            "iteration: 377840 loss: 0.0015 lr: 0.02\n",
            "iteration: 377850 loss: 0.0020 lr: 0.02\n",
            "iteration: 377860 loss: 0.0014 lr: 0.02\n",
            "iteration: 377870 loss: 0.0017 lr: 0.02\n",
            "iteration: 377880 loss: 0.0017 lr: 0.02\n",
            "iteration: 377890 loss: 0.0016 lr: 0.02\n",
            "iteration: 377900 loss: 0.0018 lr: 0.02\n",
            "iteration: 377910 loss: 0.0021 lr: 0.02\n",
            "iteration: 377920 loss: 0.0014 lr: 0.02\n",
            "iteration: 377930 loss: 0.0017 lr: 0.02\n",
            "iteration: 377940 loss: 0.0012 lr: 0.02\n",
            "iteration: 377950 loss: 0.0013 lr: 0.02\n",
            "iteration: 377960 loss: 0.0014 lr: 0.02\n",
            "iteration: 377970 loss: 0.0018 lr: 0.02\n",
            "iteration: 377980 loss: 0.0018 lr: 0.02\n",
            "iteration: 377990 loss: 0.0015 lr: 0.02\n",
            "iteration: 378000 loss: 0.0014 lr: 0.02\n",
            "iteration: 378010 loss: 0.0011 lr: 0.02\n",
            "iteration: 378020 loss: 0.0011 lr: 0.02\n",
            "iteration: 378030 loss: 0.0017 lr: 0.02\n",
            "iteration: 378040 loss: 0.0018 lr: 0.02\n",
            "iteration: 378050 loss: 0.0019 lr: 0.02\n",
            "iteration: 378060 loss: 0.0019 lr: 0.02\n",
            "iteration: 378070 loss: 0.0017 lr: 0.02\n",
            "iteration: 378080 loss: 0.0019 lr: 0.02\n",
            "iteration: 378090 loss: 0.0016 lr: 0.02\n",
            "iteration: 378100 loss: 0.0014 lr: 0.02\n",
            "iteration: 378110 loss: 0.0015 lr: 0.02\n",
            "iteration: 378120 loss: 0.0019 lr: 0.02\n",
            "iteration: 378130 loss: 0.0012 lr: 0.02\n",
            "iteration: 378140 loss: 0.0010 lr: 0.02\n",
            "iteration: 378150 loss: 0.0013 lr: 0.02\n",
            "iteration: 378160 loss: 0.0013 lr: 0.02\n",
            "iteration: 378170 loss: 0.0025 lr: 0.02\n",
            "iteration: 378180 loss: 0.0024 lr: 0.02\n",
            "iteration: 378190 loss: 0.0016 lr: 0.02\n",
            "iteration: 378200 loss: 0.0016 lr: 0.02\n",
            "iteration: 378210 loss: 0.0017 lr: 0.02\n",
            "iteration: 378220 loss: 0.0016 lr: 0.02\n",
            "iteration: 378230 loss: 0.0017 lr: 0.02\n",
            "iteration: 378240 loss: 0.0019 lr: 0.02\n",
            "iteration: 378250 loss: 0.0018 lr: 0.02\n",
            "iteration: 378260 loss: 0.0015 lr: 0.02\n",
            "iteration: 378270 loss: 0.0020 lr: 0.02\n",
            "iteration: 378280 loss: 0.0012 lr: 0.02\n",
            "iteration: 378290 loss: 0.0016 lr: 0.02\n",
            "iteration: 378300 loss: 0.0017 lr: 0.02\n",
            "iteration: 378310 loss: 0.0030 lr: 0.02\n",
            "iteration: 378320 loss: 0.0019 lr: 0.02\n",
            "iteration: 378330 loss: 0.0014 lr: 0.02\n",
            "iteration: 378340 loss: 0.0019 lr: 0.02\n",
            "iteration: 378350 loss: 0.0023 lr: 0.02\n",
            "iteration: 378360 loss: 0.0016 lr: 0.02\n",
            "iteration: 378370 loss: 0.0018 lr: 0.02\n",
            "iteration: 378380 loss: 0.0010 lr: 0.02\n",
            "iteration: 378390 loss: 0.0019 lr: 0.02\n",
            "iteration: 378400 loss: 0.0011 lr: 0.02\n",
            "iteration: 378410 loss: 0.0017 lr: 0.02\n",
            "iteration: 378420 loss: 0.0016 lr: 0.02\n",
            "iteration: 378430 loss: 0.0016 lr: 0.02\n",
            "iteration: 378440 loss: 0.0016 lr: 0.02\n",
            "iteration: 378450 loss: 0.0017 lr: 0.02\n",
            "iteration: 378460 loss: 0.0021 lr: 0.02\n",
            "iteration: 378470 loss: 0.0018 lr: 0.02\n",
            "iteration: 378480 loss: 0.0016 lr: 0.02\n",
            "iteration: 378490 loss: 0.0010 lr: 0.02\n",
            "iteration: 378500 loss: 0.0018 lr: 0.02\n",
            "iteration: 378510 loss: 0.0018 lr: 0.02\n",
            "iteration: 378520 loss: 0.0016 lr: 0.02\n",
            "iteration: 378530 loss: 0.0013 lr: 0.02\n",
            "iteration: 378540 loss: 0.0014 lr: 0.02\n",
            "iteration: 378550 loss: 0.0019 lr: 0.02\n",
            "iteration: 378560 loss: 0.0017 lr: 0.02\n",
            "iteration: 378570 loss: 0.0014 lr: 0.02\n",
            "iteration: 378580 loss: 0.0013 lr: 0.02\n",
            "iteration: 378590 loss: 0.0015 lr: 0.02\n",
            "iteration: 378600 loss: 0.0010 lr: 0.02\n",
            "iteration: 378610 loss: 0.0013 lr: 0.02\n",
            "iteration: 378620 loss: 0.0016 lr: 0.02\n",
            "iteration: 378630 loss: 0.0014 lr: 0.02\n",
            "iteration: 378640 loss: 0.0014 lr: 0.02\n",
            "iteration: 378650 loss: 0.0015 lr: 0.02\n",
            "iteration: 378660 loss: 0.0013 lr: 0.02\n",
            "iteration: 378670 loss: 0.0016 lr: 0.02\n",
            "iteration: 378680 loss: 0.0013 lr: 0.02\n",
            "iteration: 378690 loss: 0.0017 lr: 0.02\n",
            "iteration: 378700 loss: 0.0014 lr: 0.02\n",
            "iteration: 378710 loss: 0.0014 lr: 0.02\n",
            "iteration: 378720 loss: 0.0019 lr: 0.02\n",
            "iteration: 378730 loss: 0.0015 lr: 0.02\n",
            "iteration: 378740 loss: 0.0015 lr: 0.02\n",
            "iteration: 378750 loss: 0.0017 lr: 0.02\n",
            "iteration: 378760 loss: 0.0017 lr: 0.02\n",
            "iteration: 378770 loss: 0.0020 lr: 0.02\n",
            "iteration: 378780 loss: 0.0018 lr: 0.02\n",
            "iteration: 378790 loss: 0.0016 lr: 0.02\n",
            "iteration: 378800 loss: 0.0016 lr: 0.02\n",
            "iteration: 378810 loss: 0.0014 lr: 0.02\n",
            "iteration: 378820 loss: 0.0012 lr: 0.02\n",
            "iteration: 378830 loss: 0.0016 lr: 0.02\n",
            "iteration: 378840 loss: 0.0014 lr: 0.02\n",
            "iteration: 378850 loss: 0.0018 lr: 0.02\n",
            "iteration: 378860 loss: 0.0020 lr: 0.02\n",
            "iteration: 378870 loss: 0.0021 lr: 0.02\n",
            "iteration: 378880 loss: 0.0016 lr: 0.02\n",
            "iteration: 378890 loss: 0.0016 lr: 0.02\n",
            "iteration: 378900 loss: 0.0018 lr: 0.02\n",
            "iteration: 378910 loss: 0.0011 lr: 0.02\n",
            "iteration: 378920 loss: 0.0015 lr: 0.02\n",
            "iteration: 378930 loss: 0.0011 lr: 0.02\n",
            "iteration: 378940 loss: 0.0017 lr: 0.02\n",
            "iteration: 378950 loss: 0.0013 lr: 0.02\n",
            "iteration: 378960 loss: 0.0016 lr: 0.02\n",
            "iteration: 378970 loss: 0.0019 lr: 0.02\n",
            "iteration: 378980 loss: 0.0019 lr: 0.02\n",
            "iteration: 378990 loss: 0.0014 lr: 0.02\n",
            "iteration: 379000 loss: 0.0012 lr: 0.02\n",
            "iteration: 379010 loss: 0.0020 lr: 0.02\n",
            "iteration: 379020 loss: 0.0018 lr: 0.02\n",
            "iteration: 379030 loss: 0.0016 lr: 0.02\n",
            "iteration: 379040 loss: 0.0027 lr: 0.02\n",
            "iteration: 379050 loss: 0.0022 lr: 0.02\n",
            "iteration: 379060 loss: 0.0017 lr: 0.02\n",
            "iteration: 379070 loss: 0.0014 lr: 0.02\n",
            "iteration: 379080 loss: 0.0014 lr: 0.02\n",
            "iteration: 379090 loss: 0.0019 lr: 0.02\n",
            "iteration: 379100 loss: 0.0027 lr: 0.02\n",
            "iteration: 379110 loss: 0.0019 lr: 0.02\n",
            "iteration: 379120 loss: 0.0017 lr: 0.02\n",
            "iteration: 379130 loss: 0.0014 lr: 0.02\n",
            "iteration: 379140 loss: 0.0014 lr: 0.02\n",
            "iteration: 379150 loss: 0.0015 lr: 0.02\n",
            "iteration: 379160 loss: 0.0020 lr: 0.02\n",
            "iteration: 379170 loss: 0.0014 lr: 0.02\n",
            "iteration: 379180 loss: 0.0019 lr: 0.02\n",
            "iteration: 379190 loss: 0.0018 lr: 0.02\n",
            "iteration: 379200 loss: 0.0022 lr: 0.02\n",
            "iteration: 379210 loss: 0.0014 lr: 0.02\n",
            "iteration: 379220 loss: 0.0020 lr: 0.02\n",
            "iteration: 379230 loss: 0.0015 lr: 0.02\n",
            "iteration: 379240 loss: 0.0018 lr: 0.02\n",
            "iteration: 379250 loss: 0.0015 lr: 0.02\n",
            "iteration: 379260 loss: 0.0018 lr: 0.02\n",
            "iteration: 379270 loss: 0.0022 lr: 0.02\n",
            "iteration: 379280 loss: 0.0015 lr: 0.02\n",
            "iteration: 379290 loss: 0.0016 lr: 0.02\n",
            "iteration: 379300 loss: 0.0025 lr: 0.02\n",
            "iteration: 379310 loss: 0.0017 lr: 0.02\n",
            "iteration: 379320 loss: 0.0015 lr: 0.02\n",
            "iteration: 379330 loss: 0.0014 lr: 0.02\n",
            "iteration: 379340 loss: 0.0015 lr: 0.02\n",
            "iteration: 379350 loss: 0.0012 lr: 0.02\n",
            "iteration: 379360 loss: 0.0014 lr: 0.02\n",
            "iteration: 379370 loss: 0.0024 lr: 0.02\n",
            "iteration: 379380 loss: 0.0016 lr: 0.02\n",
            "iteration: 379390 loss: 0.0012 lr: 0.02\n",
            "iteration: 379400 loss: 0.0015 lr: 0.02\n",
            "iteration: 379410 loss: 0.0015 lr: 0.02\n",
            "iteration: 379420 loss: 0.0011 lr: 0.02\n",
            "iteration: 379430 loss: 0.0013 lr: 0.02\n",
            "iteration: 379440 loss: 0.0014 lr: 0.02\n",
            "iteration: 379450 loss: 0.0015 lr: 0.02\n",
            "iteration: 379460 loss: 0.0024 lr: 0.02\n",
            "iteration: 379470 loss: 0.0017 lr: 0.02\n",
            "iteration: 379480 loss: 0.0024 lr: 0.02\n",
            "iteration: 379490 loss: 0.0015 lr: 0.02\n",
            "iteration: 379500 loss: 0.0018 lr: 0.02\n",
            "iteration: 379510 loss: 0.0023 lr: 0.02\n",
            "iteration: 379520 loss: 0.0017 lr: 0.02\n",
            "iteration: 379530 loss: 0.0022 lr: 0.02\n",
            "iteration: 379540 loss: 0.0017 lr: 0.02\n",
            "iteration: 379550 loss: 0.0017 lr: 0.02\n",
            "iteration: 379560 loss: 0.0023 lr: 0.02\n",
            "iteration: 379570 loss: 0.0017 lr: 0.02\n",
            "iteration: 379580 loss: 0.0014 lr: 0.02\n",
            "iteration: 379590 loss: 0.0019 lr: 0.02\n",
            "iteration: 379600 loss: 0.0013 lr: 0.02\n",
            "iteration: 379610 loss: 0.0019 lr: 0.02\n",
            "iteration: 379620 loss: 0.0013 lr: 0.02\n",
            "iteration: 379630 loss: 0.0021 lr: 0.02\n",
            "iteration: 379640 loss: 0.0016 lr: 0.02\n",
            "iteration: 379650 loss: 0.0013 lr: 0.02\n",
            "iteration: 379660 loss: 0.0016 lr: 0.02\n",
            "iteration: 379670 loss: 0.0019 lr: 0.02\n",
            "iteration: 379680 loss: 0.0019 lr: 0.02\n",
            "iteration: 379690 loss: 0.0015 lr: 0.02\n",
            "iteration: 379700 loss: 0.0017 lr: 0.02\n",
            "iteration: 379710 loss: 0.0012 lr: 0.02\n",
            "iteration: 379720 loss: 0.0020 lr: 0.02\n",
            "iteration: 379730 loss: 0.0016 lr: 0.02\n",
            "iteration: 379740 loss: 0.0016 lr: 0.02\n",
            "iteration: 379750 loss: 0.0018 lr: 0.02\n",
            "iteration: 379760 loss: 0.0020 lr: 0.02\n",
            "iteration: 379770 loss: 0.0016 lr: 0.02\n",
            "iteration: 379780 loss: 0.0015 lr: 0.02\n",
            "iteration: 379790 loss: 0.0012 lr: 0.02\n",
            "iteration: 379800 loss: 0.0021 lr: 0.02\n",
            "iteration: 379810 loss: 0.0018 lr: 0.02\n",
            "iteration: 379820 loss: 0.0016 lr: 0.02\n",
            "iteration: 379830 loss: 0.0018 lr: 0.02\n",
            "iteration: 379840 loss: 0.0016 lr: 0.02\n",
            "iteration: 379850 loss: 0.0015 lr: 0.02\n",
            "iteration: 379860 loss: 0.0013 lr: 0.02\n",
            "iteration: 379870 loss: 0.0019 lr: 0.02\n",
            "iteration: 379880 loss: 0.0016 lr: 0.02\n",
            "iteration: 379890 loss: 0.0019 lr: 0.02\n",
            "iteration: 379900 loss: 0.0015 lr: 0.02\n",
            "iteration: 379910 loss: 0.0015 lr: 0.02\n",
            "iteration: 379920 loss: 0.0016 lr: 0.02\n",
            "iteration: 379930 loss: 0.0015 lr: 0.02\n",
            "iteration: 379940 loss: 0.0014 lr: 0.02\n",
            "iteration: 379950 loss: 0.0013 lr: 0.02\n",
            "iteration: 379960 loss: 0.0014 lr: 0.02\n",
            "iteration: 379970 loss: 0.0017 lr: 0.02\n",
            "iteration: 379980 loss: 0.0021 lr: 0.02\n",
            "iteration: 379990 loss: 0.0021 lr: 0.02\n",
            "iteration: 380000 loss: 0.0017 lr: 0.02\n",
            "iteration: 380010 loss: 0.0013 lr: 0.02\n",
            "iteration: 380020 loss: 0.0012 lr: 0.02\n",
            "iteration: 380030 loss: 0.0014 lr: 0.02\n",
            "iteration: 380040 loss: 0.0013 lr: 0.02\n",
            "iteration: 380050 loss: 0.0019 lr: 0.02\n",
            "iteration: 380060 loss: 0.0019 lr: 0.02\n",
            "iteration: 380070 loss: 0.0015 lr: 0.02\n",
            "iteration: 380080 loss: 0.0015 lr: 0.02\n",
            "iteration: 380090 loss: 0.0019 lr: 0.02\n",
            "iteration: 380100 loss: 0.0017 lr: 0.02\n",
            "iteration: 380110 loss: 0.0016 lr: 0.02\n",
            "iteration: 380120 loss: 0.0015 lr: 0.02\n",
            "iteration: 380130 loss: 0.0013 lr: 0.02\n",
            "iteration: 380140 loss: 0.0013 lr: 0.02\n",
            "iteration: 380150 loss: 0.0011 lr: 0.02\n",
            "iteration: 380160 loss: 0.0014 lr: 0.02\n",
            "iteration: 380170 loss: 0.0017 lr: 0.02\n",
            "iteration: 380180 loss: 0.0016 lr: 0.02\n",
            "iteration: 380190 loss: 0.0013 lr: 0.02\n",
            "iteration: 380200 loss: 0.0013 lr: 0.02\n",
            "iteration: 380210 loss: 0.0018 lr: 0.02\n",
            "iteration: 380220 loss: 0.0017 lr: 0.02\n",
            "iteration: 380230 loss: 0.0020 lr: 0.02\n",
            "iteration: 380240 loss: 0.0018 lr: 0.02\n",
            "iteration: 380250 loss: 0.0020 lr: 0.02\n",
            "iteration: 380260 loss: 0.0018 lr: 0.02\n",
            "iteration: 380270 loss: 0.0021 lr: 0.02\n",
            "iteration: 380280 loss: 0.0019 lr: 0.02\n",
            "iteration: 380290 loss: 0.0020 lr: 0.02\n",
            "iteration: 380300 loss: 0.0014 lr: 0.02\n",
            "iteration: 380310 loss: 0.0017 lr: 0.02\n",
            "iteration: 380320 loss: 0.0016 lr: 0.02\n",
            "iteration: 380330 loss: 0.0014 lr: 0.02\n",
            "iteration: 380340 loss: 0.0016 lr: 0.02\n",
            "iteration: 380350 loss: 0.0022 lr: 0.02\n",
            "iteration: 380360 loss: 0.0017 lr: 0.02\n",
            "iteration: 380370 loss: 0.0019 lr: 0.02\n",
            "iteration: 380380 loss: 0.0018 lr: 0.02\n",
            "iteration: 380390 loss: 0.0020 lr: 0.02\n",
            "iteration: 380400 loss: 0.0022 lr: 0.02\n",
            "iteration: 380410 loss: 0.0018 lr: 0.02\n",
            "iteration: 380420 loss: 0.0019 lr: 0.02\n",
            "iteration: 380430 loss: 0.0012 lr: 0.02\n",
            "iteration: 380440 loss: 0.0015 lr: 0.02\n",
            "iteration: 380450 loss: 0.0018 lr: 0.02\n",
            "iteration: 380460 loss: 0.0016 lr: 0.02\n",
            "iteration: 380470 loss: 0.0014 lr: 0.02\n",
            "iteration: 380480 loss: 0.0024 lr: 0.02\n",
            "iteration: 380490 loss: 0.0013 lr: 0.02\n",
            "iteration: 380500 loss: 0.0019 lr: 0.02\n",
            "iteration: 380510 loss: 0.0017 lr: 0.02\n",
            "iteration: 380520 loss: 0.0019 lr: 0.02\n",
            "iteration: 380530 loss: 0.0019 lr: 0.02\n",
            "iteration: 380540 loss: 0.0017 lr: 0.02\n",
            "iteration: 380550 loss: 0.0019 lr: 0.02\n",
            "iteration: 380560 loss: 0.0016 lr: 0.02\n",
            "iteration: 380570 loss: 0.0014 lr: 0.02\n",
            "iteration: 380580 loss: 0.0015 lr: 0.02\n",
            "iteration: 380590 loss: 0.0013 lr: 0.02\n",
            "iteration: 380600 loss: 0.0020 lr: 0.02\n",
            "iteration: 380610 loss: 0.0013 lr: 0.02\n",
            "iteration: 380620 loss: 0.0011 lr: 0.02\n",
            "iteration: 380630 loss: 0.0016 lr: 0.02\n",
            "iteration: 380640 loss: 0.0022 lr: 0.02\n",
            "iteration: 380650 loss: 0.0015 lr: 0.02\n",
            "iteration: 380660 loss: 0.0013 lr: 0.02\n",
            "iteration: 380670 loss: 0.0013 lr: 0.02\n",
            "iteration: 380680 loss: 0.0017 lr: 0.02\n",
            "iteration: 380690 loss: 0.0014 lr: 0.02\n",
            "iteration: 380700 loss: 0.0016 lr: 0.02\n",
            "iteration: 380710 loss: 0.0016 lr: 0.02\n",
            "iteration: 380720 loss: 0.0018 lr: 0.02\n",
            "iteration: 380730 loss: 0.0015 lr: 0.02\n",
            "iteration: 380740 loss: 0.0016 lr: 0.02\n",
            "iteration: 380750 loss: 0.0022 lr: 0.02\n",
            "iteration: 380760 loss: 0.0018 lr: 0.02\n",
            "iteration: 380770 loss: 0.0016 lr: 0.02\n",
            "iteration: 380780 loss: 0.0011 lr: 0.02\n",
            "iteration: 380790 loss: 0.0020 lr: 0.02\n",
            "iteration: 380800 loss: 0.0022 lr: 0.02\n",
            "iteration: 380810 loss: 0.0018 lr: 0.02\n",
            "iteration: 380820 loss: 0.0014 lr: 0.02\n",
            "iteration: 380830 loss: 0.0014 lr: 0.02\n",
            "iteration: 380840 loss: 0.0013 lr: 0.02\n",
            "iteration: 380850 loss: 0.0018 lr: 0.02\n",
            "iteration: 380860 loss: 0.0022 lr: 0.02\n",
            "iteration: 380870 loss: 0.0019 lr: 0.02\n",
            "iteration: 380880 loss: 0.0014 lr: 0.02\n",
            "iteration: 380890 loss: 0.0021 lr: 0.02\n",
            "iteration: 380900 loss: 0.0017 lr: 0.02\n",
            "iteration: 380910 loss: 0.0011 lr: 0.02\n",
            "iteration: 380920 loss: 0.0017 lr: 0.02\n",
            "iteration: 380930 loss: 0.0018 lr: 0.02\n",
            "iteration: 380940 loss: 0.0014 lr: 0.02\n",
            "iteration: 380950 loss: 0.0015 lr: 0.02\n",
            "iteration: 380960 loss: 0.0011 lr: 0.02\n",
            "iteration: 380970 loss: 0.0013 lr: 0.02\n",
            "iteration: 380980 loss: 0.0019 lr: 0.02\n",
            "iteration: 380990 loss: 0.0026 lr: 0.02\n",
            "iteration: 381000 loss: 0.0017 lr: 0.02\n",
            "iteration: 381010 loss: 0.0015 lr: 0.02\n",
            "iteration: 381020 loss: 0.0020 lr: 0.02\n",
            "iteration: 381030 loss: 0.0018 lr: 0.02\n",
            "iteration: 381040 loss: 0.0018 lr: 0.02\n",
            "iteration: 381050 loss: 0.0015 lr: 0.02\n",
            "iteration: 381060 loss: 0.0019 lr: 0.02\n",
            "iteration: 381070 loss: 0.0016 lr: 0.02\n",
            "iteration: 381080 loss: 0.0015 lr: 0.02\n",
            "iteration: 381090 loss: 0.0017 lr: 0.02\n",
            "iteration: 381100 loss: 0.0019 lr: 0.02\n",
            "iteration: 381110 loss: 0.0017 lr: 0.02\n",
            "iteration: 381120 loss: 0.0017 lr: 0.02\n",
            "iteration: 381130 loss: 0.0011 lr: 0.02\n",
            "iteration: 381140 loss: 0.0016 lr: 0.02\n",
            "iteration: 381150 loss: 0.0017 lr: 0.02\n",
            "iteration: 381160 loss: 0.0017 lr: 0.02\n",
            "iteration: 381170 loss: 0.0020 lr: 0.02\n",
            "iteration: 381180 loss: 0.0016 lr: 0.02\n",
            "iteration: 381190 loss: 0.0017 lr: 0.02\n",
            "iteration: 381200 loss: 0.0015 lr: 0.02\n",
            "iteration: 381210 loss: 0.0022 lr: 0.02\n",
            "iteration: 381220 loss: 0.0018 lr: 0.02\n",
            "iteration: 381230 loss: 0.0020 lr: 0.02\n",
            "iteration: 381240 loss: 0.0019 lr: 0.02\n",
            "iteration: 381250 loss: 0.0015 lr: 0.02\n",
            "iteration: 381260 loss: 0.0018 lr: 0.02\n",
            "iteration: 381270 loss: 0.0017 lr: 0.02\n",
            "iteration: 381280 loss: 0.0015 lr: 0.02\n",
            "iteration: 381290 loss: 0.0018 lr: 0.02\n",
            "iteration: 381300 loss: 0.0015 lr: 0.02\n",
            "iteration: 381310 loss: 0.0014 lr: 0.02\n",
            "iteration: 381320 loss: 0.0014 lr: 0.02\n",
            "iteration: 381330 loss: 0.0013 lr: 0.02\n",
            "iteration: 381340 loss: 0.0015 lr: 0.02\n",
            "iteration: 381350 loss: 0.0013 lr: 0.02\n",
            "iteration: 381360 loss: 0.0014 lr: 0.02\n",
            "iteration: 381370 loss: 0.0016 lr: 0.02\n",
            "iteration: 381380 loss: 0.0013 lr: 0.02\n",
            "iteration: 381390 loss: 0.0012 lr: 0.02\n",
            "iteration: 381400 loss: 0.0022 lr: 0.02\n",
            "iteration: 381410 loss: 0.0014 lr: 0.02\n",
            "iteration: 381420 loss: 0.0016 lr: 0.02\n",
            "iteration: 381430 loss: 0.0022 lr: 0.02\n",
            "iteration: 381440 loss: 0.0019 lr: 0.02\n",
            "iteration: 381450 loss: 0.0014 lr: 0.02\n",
            "iteration: 381460 loss: 0.0016 lr: 0.02\n",
            "iteration: 381470 loss: 0.0018 lr: 0.02\n",
            "iteration: 381480 loss: 0.0015 lr: 0.02\n",
            "iteration: 381490 loss: 0.0018 lr: 0.02\n",
            "iteration: 381500 loss: 0.0014 lr: 0.02\n",
            "iteration: 381510 loss: 0.0017 lr: 0.02\n",
            "iteration: 381520 loss: 0.0021 lr: 0.02\n",
            "iteration: 381530 loss: 0.0027 lr: 0.02\n",
            "iteration: 381540 loss: 0.0015 lr: 0.02\n",
            "iteration: 381550 loss: 0.0017 lr: 0.02\n",
            "iteration: 381560 loss: 0.0020 lr: 0.02\n",
            "iteration: 381570 loss: 0.0013 lr: 0.02\n",
            "iteration: 381580 loss: 0.0016 lr: 0.02\n",
            "iteration: 381590 loss: 0.0014 lr: 0.02\n",
            "iteration: 381600 loss: 0.0016 lr: 0.02\n",
            "iteration: 381610 loss: 0.0015 lr: 0.02\n",
            "iteration: 381620 loss: 0.0021 lr: 0.02\n",
            "iteration: 381630 loss: 0.0017 lr: 0.02\n",
            "iteration: 381640 loss: 0.0017 lr: 0.02\n",
            "iteration: 381650 loss: 0.0015 lr: 0.02\n",
            "iteration: 381660 loss: 0.0016 lr: 0.02\n",
            "iteration: 381670 loss: 0.0016 lr: 0.02\n",
            "iteration: 381680 loss: 0.0018 lr: 0.02\n",
            "iteration: 381690 loss: 0.0016 lr: 0.02\n",
            "iteration: 381700 loss: 0.0015 lr: 0.02\n",
            "iteration: 381710 loss: 0.0014 lr: 0.02\n",
            "iteration: 381720 loss: 0.0015 lr: 0.02\n",
            "iteration: 381730 loss: 0.0016 lr: 0.02\n",
            "iteration: 381740 loss: 0.0021 lr: 0.02\n",
            "iteration: 381750 loss: 0.0020 lr: 0.02\n",
            "iteration: 381760 loss: 0.0016 lr: 0.02\n",
            "iteration: 381770 loss: 0.0016 lr: 0.02\n",
            "iteration: 381780 loss: 0.0014 lr: 0.02\n",
            "iteration: 381790 loss: 0.0018 lr: 0.02\n",
            "iteration: 381800 loss: 0.0016 lr: 0.02\n",
            "iteration: 381810 loss: 0.0018 lr: 0.02\n",
            "iteration: 381820 loss: 0.0014 lr: 0.02\n",
            "iteration: 381830 loss: 0.0013 lr: 0.02\n",
            "iteration: 381840 loss: 0.0014 lr: 0.02\n",
            "iteration: 381850 loss: 0.0015 lr: 0.02\n",
            "iteration: 381860 loss: 0.0016 lr: 0.02\n",
            "iteration: 381870 loss: 0.0016 lr: 0.02\n",
            "iteration: 381880 loss: 0.0015 lr: 0.02\n",
            "iteration: 381890 loss: 0.0017 lr: 0.02\n",
            "iteration: 381900 loss: 0.0015 lr: 0.02\n",
            "iteration: 381910 loss: 0.0015 lr: 0.02\n",
            "iteration: 381920 loss: 0.0014 lr: 0.02\n",
            "iteration: 381930 loss: 0.0014 lr: 0.02\n",
            "iteration: 381940 loss: 0.0016 lr: 0.02\n",
            "iteration: 381950 loss: 0.0016 lr: 0.02\n",
            "iteration: 381960 loss: 0.0017 lr: 0.02\n",
            "iteration: 381970 loss: 0.0012 lr: 0.02\n",
            "iteration: 381980 loss: 0.0020 lr: 0.02\n",
            "iteration: 381990 loss: 0.0014 lr: 0.02\n",
            "iteration: 382000 loss: 0.0017 lr: 0.02\n",
            "iteration: 382010 loss: 0.0018 lr: 0.02\n",
            "iteration: 382020 loss: 0.0016 lr: 0.02\n",
            "iteration: 382030 loss: 0.0019 lr: 0.02\n",
            "iteration: 382040 loss: 0.0013 lr: 0.02\n",
            "iteration: 382050 loss: 0.0020 lr: 0.02\n",
            "iteration: 382060 loss: 0.0013 lr: 0.02\n",
            "iteration: 382070 loss: 0.0014 lr: 0.02\n",
            "iteration: 382080 loss: 0.0012 lr: 0.02\n",
            "iteration: 382090 loss: 0.0017 lr: 0.02\n",
            "iteration: 382100 loss: 0.0012 lr: 0.02\n",
            "iteration: 382110 loss: 0.0015 lr: 0.02\n",
            "iteration: 382120 loss: 0.0017 lr: 0.02\n",
            "iteration: 382130 loss: 0.0017 lr: 0.02\n",
            "iteration: 382140 loss: 0.0015 lr: 0.02\n",
            "iteration: 382150 loss: 0.0013 lr: 0.02\n",
            "iteration: 382160 loss: 0.0013 lr: 0.02\n",
            "iteration: 382170 loss: 0.0019 lr: 0.02\n",
            "iteration: 382180 loss: 0.0014 lr: 0.02\n",
            "iteration: 382190 loss: 0.0021 lr: 0.02\n",
            "iteration: 382200 loss: 0.0013 lr: 0.02\n",
            "iteration: 382210 loss: 0.0016 lr: 0.02\n",
            "iteration: 382220 loss: 0.0013 lr: 0.02\n",
            "iteration: 382230 loss: 0.0014 lr: 0.02\n",
            "iteration: 382240 loss: 0.0016 lr: 0.02\n",
            "iteration: 382250 loss: 0.0024 lr: 0.02\n",
            "iteration: 382260 loss: 0.0014 lr: 0.02\n",
            "iteration: 382270 loss: 0.0015 lr: 0.02\n",
            "iteration: 382280 loss: 0.0012 lr: 0.02\n",
            "iteration: 382290 loss: 0.0014 lr: 0.02\n",
            "iteration: 382300 loss: 0.0012 lr: 0.02\n",
            "iteration: 382310 loss: 0.0017 lr: 0.02\n",
            "iteration: 382320 loss: 0.0017 lr: 0.02\n",
            "iteration: 382330 loss: 0.0018 lr: 0.02\n",
            "iteration: 382340 loss: 0.0021 lr: 0.02\n",
            "iteration: 382350 loss: 0.0014 lr: 0.02\n",
            "iteration: 382360 loss: 0.0013 lr: 0.02\n",
            "iteration: 382370 loss: 0.0013 lr: 0.02\n",
            "iteration: 382380 loss: 0.0014 lr: 0.02\n",
            "iteration: 382390 loss: 0.0014 lr: 0.02\n",
            "iteration: 382400 loss: 0.0015 lr: 0.02\n",
            "iteration: 382410 loss: 0.0018 lr: 0.02\n",
            "iteration: 382420 loss: 0.0015 lr: 0.02\n",
            "iteration: 382430 loss: 0.0018 lr: 0.02\n",
            "iteration: 382440 loss: 0.0018 lr: 0.02\n",
            "iteration: 382450 loss: 0.0014 lr: 0.02\n",
            "iteration: 382460 loss: 0.0015 lr: 0.02\n",
            "iteration: 382470 loss: 0.0018 lr: 0.02\n",
            "iteration: 382480 loss: 0.0013 lr: 0.02\n",
            "iteration: 382490 loss: 0.0018 lr: 0.02\n",
            "iteration: 382500 loss: 0.0018 lr: 0.02\n",
            "iteration: 382510 loss: 0.0013 lr: 0.02\n",
            "iteration: 382520 loss: 0.0017 lr: 0.02\n",
            "iteration: 382530 loss: 0.0016 lr: 0.02\n",
            "iteration: 382540 loss: 0.0020 lr: 0.02\n",
            "iteration: 382550 loss: 0.0018 lr: 0.02\n",
            "iteration: 382560 loss: 0.0015 lr: 0.02\n",
            "iteration: 382570 loss: 0.0017 lr: 0.02\n",
            "iteration: 382580 loss: 0.0016 lr: 0.02\n",
            "iteration: 382590 loss: 0.0019 lr: 0.02\n",
            "iteration: 382600 loss: 0.0015 lr: 0.02\n",
            "iteration: 382610 loss: 0.0017 lr: 0.02\n",
            "iteration: 382620 loss: 0.0017 lr: 0.02\n",
            "iteration: 382630 loss: 0.0018 lr: 0.02\n",
            "iteration: 382640 loss: 0.0021 lr: 0.02\n",
            "iteration: 382650 loss: 0.0018 lr: 0.02\n",
            "iteration: 382660 loss: 0.0017 lr: 0.02\n",
            "iteration: 382670 loss: 0.0019 lr: 0.02\n",
            "iteration: 382680 loss: 0.0016 lr: 0.02\n",
            "iteration: 382690 loss: 0.0016 lr: 0.02\n",
            "iteration: 382700 loss: 0.0016 lr: 0.02\n",
            "iteration: 382710 loss: 0.0012 lr: 0.02\n",
            "iteration: 382720 loss: 0.0016 lr: 0.02\n",
            "iteration: 382730 loss: 0.0019 lr: 0.02\n",
            "iteration: 382740 loss: 0.0018 lr: 0.02\n",
            "iteration: 382750 loss: 0.0017 lr: 0.02\n",
            "iteration: 382760 loss: 0.0015 lr: 0.02\n",
            "iteration: 382770 loss: 0.0014 lr: 0.02\n",
            "iteration: 382780 loss: 0.0015 lr: 0.02\n",
            "iteration: 382790 loss: 0.0017 lr: 0.02\n",
            "iteration: 382800 loss: 0.0016 lr: 0.02\n",
            "iteration: 382810 loss: 0.0012 lr: 0.02\n",
            "iteration: 382820 loss: 0.0015 lr: 0.02\n",
            "iteration: 382830 loss: 0.0018 lr: 0.02\n",
            "iteration: 382840 loss: 0.0018 lr: 0.02\n",
            "iteration: 382850 loss: 0.0017 lr: 0.02\n",
            "iteration: 382860 loss: 0.0011 lr: 0.02\n",
            "iteration: 382870 loss: 0.0024 lr: 0.02\n",
            "iteration: 382880 loss: 0.0012 lr: 0.02\n",
            "iteration: 382890 loss: 0.0016 lr: 0.02\n",
            "iteration: 382900 loss: 0.0015 lr: 0.02\n",
            "iteration: 382910 loss: 0.0013 lr: 0.02\n",
            "iteration: 382920 loss: 0.0019 lr: 0.02\n",
            "iteration: 382930 loss: 0.0023 lr: 0.02\n",
            "iteration: 382940 loss: 0.0013 lr: 0.02\n",
            "iteration: 382950 loss: 0.0014 lr: 0.02\n",
            "iteration: 382960 loss: 0.0025 lr: 0.02\n",
            "iteration: 382970 loss: 0.0021 lr: 0.02\n",
            "iteration: 382980 loss: 0.0018 lr: 0.02\n",
            "iteration: 382990 loss: 0.0010 lr: 0.02\n",
            "iteration: 383000 loss: 0.0013 lr: 0.02\n",
            "iteration: 383010 loss: 0.0019 lr: 0.02\n",
            "iteration: 383020 loss: 0.0017 lr: 0.02\n",
            "iteration: 383030 loss: 0.0016 lr: 0.02\n",
            "iteration: 383040 loss: 0.0018 lr: 0.02\n",
            "iteration: 383050 loss: 0.0018 lr: 0.02\n",
            "iteration: 383060 loss: 0.0016 lr: 0.02\n",
            "iteration: 383070 loss: 0.0013 lr: 0.02\n",
            "iteration: 383080 loss: 0.0018 lr: 0.02\n",
            "iteration: 383090 loss: 0.0018 lr: 0.02\n",
            "iteration: 383100 loss: 0.0015 lr: 0.02\n",
            "iteration: 383110 loss: 0.0018 lr: 0.02\n",
            "iteration: 383120 loss: 0.0016 lr: 0.02\n",
            "iteration: 383130 loss: 0.0019 lr: 0.02\n",
            "iteration: 383140 loss: 0.0017 lr: 0.02\n",
            "iteration: 383150 loss: 0.0011 lr: 0.02\n",
            "iteration: 383160 loss: 0.0015 lr: 0.02\n",
            "iteration: 383170 loss: 0.0014 lr: 0.02\n",
            "iteration: 383180 loss: 0.0012 lr: 0.02\n",
            "iteration: 383190 loss: 0.0013 lr: 0.02\n",
            "iteration: 383200 loss: 0.0015 lr: 0.02\n",
            "iteration: 383210 loss: 0.0019 lr: 0.02\n",
            "iteration: 383220 loss: 0.0017 lr: 0.02\n",
            "iteration: 383230 loss: 0.0019 lr: 0.02\n",
            "iteration: 383240 loss: 0.0013 lr: 0.02\n",
            "iteration: 383250 loss: 0.0016 lr: 0.02\n",
            "iteration: 383260 loss: 0.0013 lr: 0.02\n",
            "iteration: 383270 loss: 0.0018 lr: 0.02\n",
            "iteration: 383280 loss: 0.0018 lr: 0.02\n",
            "iteration: 383290 loss: 0.0022 lr: 0.02\n",
            "iteration: 383300 loss: 0.0016 lr: 0.02\n",
            "iteration: 383310 loss: 0.0015 lr: 0.02\n",
            "iteration: 383320 loss: 0.0017 lr: 0.02\n",
            "iteration: 383330 loss: 0.0020 lr: 0.02\n",
            "iteration: 383340 loss: 0.0020 lr: 0.02\n",
            "iteration: 383350 loss: 0.0017 lr: 0.02\n",
            "iteration: 383360 loss: 0.0019 lr: 0.02\n",
            "iteration: 383370 loss: 0.0013 lr: 0.02\n",
            "iteration: 383380 loss: 0.0018 lr: 0.02\n",
            "iteration: 383390 loss: 0.0015 lr: 0.02\n",
            "iteration: 383400 loss: 0.0019 lr: 0.02\n",
            "iteration: 383410 loss: 0.0012 lr: 0.02\n",
            "iteration: 383420 loss: 0.0011 lr: 0.02\n",
            "iteration: 383430 loss: 0.0024 lr: 0.02\n",
            "iteration: 383440 loss: 0.0016 lr: 0.02\n",
            "iteration: 383450 loss: 0.0012 lr: 0.02\n",
            "iteration: 383460 loss: 0.0019 lr: 0.02\n",
            "iteration: 383470 loss: 0.0014 lr: 0.02\n",
            "iteration: 383480 loss: 0.0013 lr: 0.02\n",
            "iteration: 383490 loss: 0.0018 lr: 0.02\n",
            "iteration: 383500 loss: 0.0024 lr: 0.02\n",
            "iteration: 383510 loss: 0.0015 lr: 0.02\n",
            "iteration: 383520 loss: 0.0020 lr: 0.02\n",
            "iteration: 383530 loss: 0.0016 lr: 0.02\n",
            "iteration: 383540 loss: 0.0016 lr: 0.02\n",
            "iteration: 383550 loss: 0.0018 lr: 0.02\n",
            "iteration: 383560 loss: 0.0018 lr: 0.02\n",
            "iteration: 383570 loss: 0.0021 lr: 0.02\n",
            "iteration: 383580 loss: 0.0019 lr: 0.02\n",
            "iteration: 383590 loss: 0.0017 lr: 0.02\n",
            "iteration: 383600 loss: 0.0014 lr: 0.02\n",
            "iteration: 383610 loss: 0.0015 lr: 0.02\n",
            "iteration: 383620 loss: 0.0012 lr: 0.02\n",
            "iteration: 383630 loss: 0.0014 lr: 0.02\n",
            "iteration: 383640 loss: 0.0017 lr: 0.02\n",
            "iteration: 383650 loss: 0.0017 lr: 0.02\n",
            "iteration: 383660 loss: 0.0016 lr: 0.02\n",
            "iteration: 383670 loss: 0.0013 lr: 0.02\n",
            "iteration: 383680 loss: 0.0022 lr: 0.02\n",
            "iteration: 383690 loss: 0.0021 lr: 0.02\n",
            "iteration: 383700 loss: 0.0019 lr: 0.02\n",
            "iteration: 383710 loss: 0.0018 lr: 0.02\n",
            "iteration: 383720 loss: 0.0014 lr: 0.02\n",
            "iteration: 383730 loss: 0.0017 lr: 0.02\n",
            "iteration: 383740 loss: 0.0016 lr: 0.02\n",
            "iteration: 383750 loss: 0.0015 lr: 0.02\n",
            "iteration: 383760 loss: 0.0016 lr: 0.02\n",
            "iteration: 383770 loss: 0.0015 lr: 0.02\n",
            "iteration: 383780 loss: 0.0017 lr: 0.02\n",
            "iteration: 383790 loss: 0.0021 lr: 0.02\n",
            "iteration: 383800 loss: 0.0017 lr: 0.02\n",
            "iteration: 383810 loss: 0.0013 lr: 0.02\n",
            "iteration: 383820 loss: 0.0013 lr: 0.02\n",
            "iteration: 383830 loss: 0.0016 lr: 0.02\n",
            "iteration: 383840 loss: 0.0017 lr: 0.02\n",
            "iteration: 383850 loss: 0.0017 lr: 0.02\n",
            "iteration: 383860 loss: 0.0016 lr: 0.02\n",
            "iteration: 383870 loss: 0.0015 lr: 0.02\n",
            "iteration: 383880 loss: 0.0017 lr: 0.02\n",
            "iteration: 383890 loss: 0.0018 lr: 0.02\n",
            "iteration: 383900 loss: 0.0012 lr: 0.02\n",
            "iteration: 383910 loss: 0.0017 lr: 0.02\n",
            "iteration: 383920 loss: 0.0015 lr: 0.02\n",
            "iteration: 383930 loss: 0.0013 lr: 0.02\n",
            "iteration: 383940 loss: 0.0019 lr: 0.02\n",
            "iteration: 383950 loss: 0.0020 lr: 0.02\n",
            "iteration: 383960 loss: 0.0012 lr: 0.02\n",
            "iteration: 383970 loss: 0.0020 lr: 0.02\n",
            "iteration: 383980 loss: 0.0019 lr: 0.02\n",
            "iteration: 383990 loss: 0.0021 lr: 0.02\n",
            "iteration: 384000 loss: 0.0018 lr: 0.02\n",
            "iteration: 384010 loss: 0.0016 lr: 0.02\n",
            "iteration: 384020 loss: 0.0014 lr: 0.02\n",
            "iteration: 384030 loss: 0.0011 lr: 0.02\n",
            "iteration: 384040 loss: 0.0014 lr: 0.02\n",
            "iteration: 384050 loss: 0.0016 lr: 0.02\n",
            "iteration: 384060 loss: 0.0018 lr: 0.02\n",
            "iteration: 384070 loss: 0.0018 lr: 0.02\n",
            "iteration: 384080 loss: 0.0018 lr: 0.02\n",
            "iteration: 384090 loss: 0.0014 lr: 0.02\n",
            "iteration: 384100 loss: 0.0015 lr: 0.02\n",
            "iteration: 384110 loss: 0.0018 lr: 0.02\n",
            "iteration: 384120 loss: 0.0019 lr: 0.02\n",
            "iteration: 384130 loss: 0.0016 lr: 0.02\n",
            "iteration: 384140 loss: 0.0010 lr: 0.02\n",
            "iteration: 384150 loss: 0.0015 lr: 0.02\n",
            "iteration: 384160 loss: 0.0016 lr: 0.02\n",
            "iteration: 384170 loss: 0.0019 lr: 0.02\n",
            "iteration: 384180 loss: 0.0015 lr: 0.02\n",
            "iteration: 384190 loss: 0.0017 lr: 0.02\n",
            "iteration: 384200 loss: 0.0021 lr: 0.02\n",
            "iteration: 384210 loss: 0.0013 lr: 0.02\n",
            "iteration: 384220 loss: 0.0019 lr: 0.02\n",
            "iteration: 384230 loss: 0.0015 lr: 0.02\n",
            "iteration: 384240 loss: 0.0013 lr: 0.02\n",
            "iteration: 384250 loss: 0.0016 lr: 0.02\n",
            "iteration: 384260 loss: 0.0017 lr: 0.02\n",
            "iteration: 384270 loss: 0.0015 lr: 0.02\n",
            "iteration: 384280 loss: 0.0019 lr: 0.02\n",
            "iteration: 384290 loss: 0.0024 lr: 0.02\n",
            "iteration: 384300 loss: 0.0020 lr: 0.02\n",
            "iteration: 384310 loss: 0.0014 lr: 0.02\n",
            "iteration: 384320 loss: 0.0015 lr: 0.02\n",
            "iteration: 384330 loss: 0.0017 lr: 0.02\n",
            "iteration: 384340 loss: 0.0015 lr: 0.02\n",
            "iteration: 384350 loss: 0.0019 lr: 0.02\n",
            "iteration: 384360 loss: 0.0018 lr: 0.02\n",
            "iteration: 384370 loss: 0.0016 lr: 0.02\n",
            "iteration: 384380 loss: 0.0021 lr: 0.02\n",
            "iteration: 384390 loss: 0.0013 lr: 0.02\n",
            "iteration: 384400 loss: 0.0012 lr: 0.02\n",
            "iteration: 384410 loss: 0.0015 lr: 0.02\n",
            "iteration: 384420 loss: 0.0016 lr: 0.02\n",
            "iteration: 384430 loss: 0.0017 lr: 0.02\n",
            "iteration: 384440 loss: 0.0012 lr: 0.02\n",
            "iteration: 384450 loss: 0.0011 lr: 0.02\n",
            "iteration: 384460 loss: 0.0019 lr: 0.02\n",
            "iteration: 384470 loss: 0.0015 lr: 0.02\n",
            "iteration: 384480 loss: 0.0012 lr: 0.02\n",
            "iteration: 384490 loss: 0.0018 lr: 0.02\n",
            "iteration: 384500 loss: 0.0017 lr: 0.02\n",
            "iteration: 384510 loss: 0.0022 lr: 0.02\n",
            "iteration: 384520 loss: 0.0018 lr: 0.02\n",
            "iteration: 384530 loss: 0.0016 lr: 0.02\n",
            "iteration: 384540 loss: 0.0018 lr: 0.02\n",
            "iteration: 384550 loss: 0.0017 lr: 0.02\n",
            "iteration: 384560 loss: 0.0016 lr: 0.02\n",
            "iteration: 384570 loss: 0.0016 lr: 0.02\n",
            "iteration: 384580 loss: 0.0021 lr: 0.02\n",
            "iteration: 384590 loss: 0.0017 lr: 0.02\n",
            "iteration: 384600 loss: 0.0016 lr: 0.02\n",
            "iteration: 384610 loss: 0.0016 lr: 0.02\n",
            "iteration: 384620 loss: 0.0020 lr: 0.02\n",
            "iteration: 384630 loss: 0.0017 lr: 0.02\n",
            "iteration: 384640 loss: 0.0019 lr: 0.02\n",
            "iteration: 384650 loss: 0.0016 lr: 0.02\n",
            "iteration: 384660 loss: 0.0016 lr: 0.02\n",
            "iteration: 384670 loss: 0.0012 lr: 0.02\n",
            "iteration: 384680 loss: 0.0020 lr: 0.02\n",
            "iteration: 384690 loss: 0.0016 lr: 0.02\n",
            "iteration: 384700 loss: 0.0016 lr: 0.02\n",
            "iteration: 384710 loss: 0.0014 lr: 0.02\n",
            "iteration: 384720 loss: 0.0016 lr: 0.02\n",
            "iteration: 384730 loss: 0.0015 lr: 0.02\n",
            "iteration: 384740 loss: 0.0014 lr: 0.02\n",
            "iteration: 384750 loss: 0.0014 lr: 0.02\n",
            "iteration: 384760 loss: 0.0021 lr: 0.02\n",
            "iteration: 384770 loss: 0.0015 lr: 0.02\n",
            "iteration: 384780 loss: 0.0012 lr: 0.02\n",
            "iteration: 384790 loss: 0.0014 lr: 0.02\n",
            "iteration: 384800 loss: 0.0017 lr: 0.02\n",
            "iteration: 384810 loss: 0.0018 lr: 0.02\n",
            "iteration: 384820 loss: 0.0015 lr: 0.02\n",
            "iteration: 384830 loss: 0.0017 lr: 0.02\n",
            "iteration: 384840 loss: 0.0015 lr: 0.02\n",
            "iteration: 384850 loss: 0.0017 lr: 0.02\n",
            "iteration: 384860 loss: 0.0012 lr: 0.02\n",
            "iteration: 384870 loss: 0.0020 lr: 0.02\n",
            "iteration: 384880 loss: 0.0015 lr: 0.02\n",
            "iteration: 384890 loss: 0.0018 lr: 0.02\n",
            "iteration: 384900 loss: 0.0017 lr: 0.02\n",
            "iteration: 384910 loss: 0.0016 lr: 0.02\n",
            "iteration: 384920 loss: 0.0017 lr: 0.02\n",
            "iteration: 384930 loss: 0.0016 lr: 0.02\n",
            "iteration: 384940 loss: 0.0019 lr: 0.02\n",
            "iteration: 384950 loss: 0.0017 lr: 0.02\n",
            "iteration: 384960 loss: 0.0013 lr: 0.02\n",
            "iteration: 384970 loss: 0.0014 lr: 0.02\n",
            "iteration: 384980 loss: 0.0017 lr: 0.02\n",
            "iteration: 384990 loss: 0.0019 lr: 0.02\n",
            "iteration: 385000 loss: 0.0014 lr: 0.02\n",
            "iteration: 385010 loss: 0.0016 lr: 0.02\n",
            "iteration: 385020 loss: 0.0019 lr: 0.02\n",
            "iteration: 385030 loss: 0.0012 lr: 0.02\n",
            "iteration: 385040 loss: 0.0018 lr: 0.02\n",
            "iteration: 385050 loss: 0.0018 lr: 0.02\n",
            "iteration: 385060 loss: 0.0027 lr: 0.02\n",
            "iteration: 385070 loss: 0.0021 lr: 0.02\n",
            "iteration: 385080 loss: 0.0014 lr: 0.02\n",
            "iteration: 385090 loss: 0.0012 lr: 0.02\n",
            "iteration: 385100 loss: 0.0016 lr: 0.02\n",
            "iteration: 385110 loss: 0.0017 lr: 0.02\n",
            "iteration: 385120 loss: 0.0019 lr: 0.02\n",
            "iteration: 385130 loss: 0.0020 lr: 0.02\n",
            "iteration: 385140 loss: 0.0018 lr: 0.02\n",
            "iteration: 385150 loss: 0.0016 lr: 0.02\n",
            "iteration: 385160 loss: 0.0013 lr: 0.02\n",
            "iteration: 385170 loss: 0.0015 lr: 0.02\n",
            "iteration: 385180 loss: 0.0015 lr: 0.02\n",
            "iteration: 385190 loss: 0.0016 lr: 0.02\n",
            "iteration: 385200 loss: 0.0012 lr: 0.02\n",
            "iteration: 385210 loss: 0.0015 lr: 0.02\n",
            "iteration: 385220 loss: 0.0011 lr: 0.02\n",
            "iteration: 385230 loss: 0.0014 lr: 0.02\n",
            "iteration: 385240 loss: 0.0021 lr: 0.02\n",
            "iteration: 385250 loss: 0.0014 lr: 0.02\n",
            "iteration: 385260 loss: 0.0012 lr: 0.02\n",
            "iteration: 385270 loss: 0.0021 lr: 0.02\n",
            "iteration: 385280 loss: 0.0016 lr: 0.02\n",
            "iteration: 385290 loss: 0.0038 lr: 0.02\n",
            "iteration: 385300 loss: 0.0014 lr: 0.02\n",
            "iteration: 385310 loss: 0.0015 lr: 0.02\n",
            "iteration: 385320 loss: 0.0014 lr: 0.02\n",
            "iteration: 385330 loss: 0.0017 lr: 0.02\n",
            "iteration: 385340 loss: 0.0014 lr: 0.02\n",
            "iteration: 385350 loss: 0.0012 lr: 0.02\n",
            "iteration: 385360 loss: 0.0018 lr: 0.02\n",
            "iteration: 385370 loss: 0.0017 lr: 0.02\n",
            "iteration: 385380 loss: 0.0015 lr: 0.02\n",
            "iteration: 385390 loss: 0.0011 lr: 0.02\n",
            "iteration: 385400 loss: 0.0017 lr: 0.02\n",
            "iteration: 385410 loss: 0.0010 lr: 0.02\n",
            "iteration: 385420 loss: 0.0017 lr: 0.02\n",
            "iteration: 385430 loss: 0.0013 lr: 0.02\n",
            "iteration: 385440 loss: 0.0012 lr: 0.02\n",
            "iteration: 385450 loss: 0.0021 lr: 0.02\n",
            "iteration: 385460 loss: 0.0013 lr: 0.02\n",
            "iteration: 385470 loss: 0.0019 lr: 0.02\n",
            "iteration: 385480 loss: 0.0014 lr: 0.02\n",
            "iteration: 385490 loss: 0.0023 lr: 0.02\n",
            "iteration: 385500 loss: 0.0021 lr: 0.02\n",
            "iteration: 385510 loss: 0.0023 lr: 0.02\n",
            "iteration: 385520 loss: 0.0018 lr: 0.02\n",
            "iteration: 385530 loss: 0.0013 lr: 0.02\n",
            "iteration: 385540 loss: 0.0015 lr: 0.02\n",
            "iteration: 385550 loss: 0.0015 lr: 0.02\n",
            "iteration: 385560 loss: 0.0018 lr: 0.02\n",
            "iteration: 385570 loss: 0.0018 lr: 0.02\n",
            "iteration: 385580 loss: 0.0015 lr: 0.02\n",
            "iteration: 385590 loss: 0.0012 lr: 0.02\n",
            "iteration: 385600 loss: 0.0014 lr: 0.02\n",
            "iteration: 385610 loss: 0.0020 lr: 0.02\n",
            "iteration: 385620 loss: 0.0016 lr: 0.02\n",
            "iteration: 385630 loss: 0.0018 lr: 0.02\n",
            "iteration: 385640 loss: 0.0016 lr: 0.02\n",
            "iteration: 385650 loss: 0.0014 lr: 0.02\n",
            "iteration: 385660 loss: 0.0020 lr: 0.02\n",
            "iteration: 385670 loss: 0.0020 lr: 0.02\n",
            "iteration: 385680 loss: 0.0022 lr: 0.02\n",
            "iteration: 385690 loss: 0.0014 lr: 0.02\n",
            "iteration: 385700 loss: 0.0015 lr: 0.02\n",
            "iteration: 385710 loss: 0.0013 lr: 0.02\n",
            "iteration: 385720 loss: 0.0014 lr: 0.02\n",
            "iteration: 385730 loss: 0.0016 lr: 0.02\n",
            "iteration: 385740 loss: 0.0012 lr: 0.02\n",
            "iteration: 385750 loss: 0.0017 lr: 0.02\n",
            "iteration: 385760 loss: 0.0016 lr: 0.02\n",
            "iteration: 385770 loss: 0.0014 lr: 0.02\n",
            "iteration: 385780 loss: 0.0012 lr: 0.02\n",
            "iteration: 385790 loss: 0.0019 lr: 0.02\n",
            "iteration: 385800 loss: 0.0015 lr: 0.02\n",
            "iteration: 385810 loss: 0.0012 lr: 0.02\n",
            "iteration: 385820 loss: 0.0016 lr: 0.02\n",
            "iteration: 385830 loss: 0.0016 lr: 0.02\n",
            "iteration: 385840 loss: 0.0013 lr: 0.02\n",
            "iteration: 385850 loss: 0.0017 lr: 0.02\n",
            "iteration: 385860 loss: 0.0017 lr: 0.02\n",
            "iteration: 385870 loss: 0.0014 lr: 0.02\n",
            "iteration: 385880 loss: 0.0018 lr: 0.02\n",
            "iteration: 385890 loss: 0.0016 lr: 0.02\n",
            "iteration: 385900 loss: 0.0014 lr: 0.02\n",
            "iteration: 385910 loss: 0.0020 lr: 0.02\n",
            "iteration: 385920 loss: 0.0013 lr: 0.02\n",
            "iteration: 385930 loss: 0.0015 lr: 0.02\n",
            "iteration: 385940 loss: 0.0017 lr: 0.02\n",
            "iteration: 385950 loss: 0.0016 lr: 0.02\n",
            "iteration: 385960 loss: 0.0011 lr: 0.02\n",
            "iteration: 385970 loss: 0.0018 lr: 0.02\n",
            "iteration: 385980 loss: 0.0015 lr: 0.02\n",
            "iteration: 385990 loss: 0.0014 lr: 0.02\n",
            "iteration: 386000 loss: 0.0015 lr: 0.02\n",
            "iteration: 386010 loss: 0.0019 lr: 0.02\n",
            "iteration: 386020 loss: 0.0014 lr: 0.02\n",
            "iteration: 386030 loss: 0.0015 lr: 0.02\n",
            "iteration: 386040 loss: 0.0013 lr: 0.02\n",
            "iteration: 386050 loss: 0.0014 lr: 0.02\n",
            "iteration: 386060 loss: 0.0021 lr: 0.02\n",
            "iteration: 386070 loss: 0.0021 lr: 0.02\n",
            "iteration: 386080 loss: 0.0014 lr: 0.02\n",
            "iteration: 386090 loss: 0.0016 lr: 0.02\n",
            "iteration: 386100 loss: 0.0018 lr: 0.02\n",
            "iteration: 386110 loss: 0.0016 lr: 0.02\n",
            "iteration: 386120 loss: 0.0015 lr: 0.02\n",
            "iteration: 386130 loss: 0.0012 lr: 0.02\n",
            "iteration: 386140 loss: 0.0018 lr: 0.02\n",
            "iteration: 386150 loss: 0.0015 lr: 0.02\n",
            "iteration: 386160 loss: 0.0017 lr: 0.02\n",
            "iteration: 386170 loss: 0.0031 lr: 0.02\n",
            "iteration: 386180 loss: 0.0013 lr: 0.02\n",
            "iteration: 386190 loss: 0.0009 lr: 0.02\n",
            "iteration: 386200 loss: 0.0014 lr: 0.02\n",
            "iteration: 386210 loss: 0.0016 lr: 0.02\n",
            "iteration: 386220 loss: 0.0014 lr: 0.02\n",
            "iteration: 386230 loss: 0.0015 lr: 0.02\n",
            "iteration: 386240 loss: 0.0014 lr: 0.02\n",
            "iteration: 386250 loss: 0.0014 lr: 0.02\n",
            "iteration: 386260 loss: 0.0017 lr: 0.02\n",
            "iteration: 386270 loss: 0.0018 lr: 0.02\n",
            "iteration: 386280 loss: 0.0014 lr: 0.02\n",
            "iteration: 386290 loss: 0.0011 lr: 0.02\n",
            "iteration: 386300 loss: 0.0011 lr: 0.02\n",
            "iteration: 386310 loss: 0.0020 lr: 0.02\n",
            "iteration: 386320 loss: 0.0021 lr: 0.02\n",
            "iteration: 386330 loss: 0.0018 lr: 0.02\n",
            "iteration: 386340 loss: 0.0018 lr: 0.02\n",
            "iteration: 386350 loss: 0.0016 lr: 0.02\n",
            "iteration: 386360 loss: 0.0016 lr: 0.02\n",
            "iteration: 386370 loss: 0.0015 lr: 0.02\n",
            "iteration: 386380 loss: 0.0014 lr: 0.02\n",
            "iteration: 386390 loss: 0.0014 lr: 0.02\n",
            "iteration: 386400 loss: 0.0017 lr: 0.02\n",
            "iteration: 386410 loss: 0.0017 lr: 0.02\n",
            "iteration: 386420 loss: 0.0017 lr: 0.02\n",
            "iteration: 386430 loss: 0.0016 lr: 0.02\n",
            "iteration: 386440 loss: 0.0014 lr: 0.02\n",
            "iteration: 386450 loss: 0.0018 lr: 0.02\n",
            "iteration: 386460 loss: 0.0015 lr: 0.02\n",
            "iteration: 386470 loss: 0.0015 lr: 0.02\n",
            "iteration: 386480 loss: 0.0018 lr: 0.02\n",
            "iteration: 386490 loss: 0.0014 lr: 0.02\n",
            "iteration: 386500 loss: 0.0020 lr: 0.02\n",
            "iteration: 386510 loss: 0.0020 lr: 0.02\n",
            "iteration: 386520 loss: 0.0014 lr: 0.02\n",
            "iteration: 386530 loss: 0.0018 lr: 0.02\n",
            "iteration: 386540 loss: 0.0012 lr: 0.02\n",
            "iteration: 386550 loss: 0.0012 lr: 0.02\n",
            "iteration: 386560 loss: 0.0013 lr: 0.02\n",
            "iteration: 386570 loss: 0.0014 lr: 0.02\n",
            "iteration: 386580 loss: 0.0016 lr: 0.02\n",
            "iteration: 386590 loss: 0.0011 lr: 0.02\n",
            "iteration: 386600 loss: 0.0026 lr: 0.02\n",
            "iteration: 386610 loss: 0.0017 lr: 0.02\n",
            "iteration: 386620 loss: 0.0015 lr: 0.02\n",
            "iteration: 386630 loss: 0.0015 lr: 0.02\n",
            "iteration: 386640 loss: 0.0019 lr: 0.02\n",
            "iteration: 386650 loss: 0.0020 lr: 0.02\n",
            "iteration: 386660 loss: 0.0016 lr: 0.02\n",
            "iteration: 386670 loss: 0.0015 lr: 0.02\n",
            "iteration: 386680 loss: 0.0015 lr: 0.02\n",
            "iteration: 386690 loss: 0.0017 lr: 0.02\n",
            "iteration: 386700 loss: 0.0018 lr: 0.02\n",
            "iteration: 386710 loss: 0.0014 lr: 0.02\n",
            "iteration: 386720 loss: 0.0015 lr: 0.02\n",
            "iteration: 386730 loss: 0.0016 lr: 0.02\n",
            "iteration: 386740 loss: 0.0013 lr: 0.02\n",
            "iteration: 386750 loss: 0.0018 lr: 0.02\n",
            "iteration: 386760 loss: 0.0017 lr: 0.02\n",
            "iteration: 386770 loss: 0.0018 lr: 0.02\n",
            "iteration: 386780 loss: 0.0014 lr: 0.02\n",
            "iteration: 386790 loss: 0.0012 lr: 0.02\n",
            "iteration: 386800 loss: 0.0012 lr: 0.02\n",
            "iteration: 386810 loss: 0.0015 lr: 0.02\n",
            "iteration: 386820 loss: 0.0016 lr: 0.02\n",
            "iteration: 386830 loss: 0.0019 lr: 0.02\n",
            "iteration: 386840 loss: 0.0016 lr: 0.02\n",
            "iteration: 386850 loss: 0.0017 lr: 0.02\n",
            "iteration: 386860 loss: 0.0016 lr: 0.02\n",
            "iteration: 386870 loss: 0.0014 lr: 0.02\n",
            "iteration: 386880 loss: 0.0017 lr: 0.02\n",
            "iteration: 386890 loss: 0.0017 lr: 0.02\n",
            "iteration: 386900 loss: 0.0013 lr: 0.02\n",
            "iteration: 386910 loss: 0.0018 lr: 0.02\n",
            "iteration: 386920 loss: 0.0017 lr: 0.02\n",
            "iteration: 386930 loss: 0.0017 lr: 0.02\n",
            "iteration: 386940 loss: 0.0015 lr: 0.02\n",
            "iteration: 386950 loss: 0.0015 lr: 0.02\n",
            "iteration: 386960 loss: 0.0015 lr: 0.02\n",
            "iteration: 386970 loss: 0.0016 lr: 0.02\n",
            "iteration: 386980 loss: 0.0020 lr: 0.02\n",
            "iteration: 386990 loss: 0.0015 lr: 0.02\n",
            "iteration: 387000 loss: 0.0020 lr: 0.02\n",
            "iteration: 387010 loss: 0.0014 lr: 0.02\n",
            "iteration: 387020 loss: 0.0015 lr: 0.02\n",
            "iteration: 387030 loss: 0.0020 lr: 0.02\n",
            "iteration: 387040 loss: 0.0020 lr: 0.02\n",
            "iteration: 387050 loss: 0.0011 lr: 0.02\n",
            "iteration: 387060 loss: 0.0013 lr: 0.02\n",
            "iteration: 387070 loss: 0.0012 lr: 0.02\n",
            "iteration: 387080 loss: 0.0018 lr: 0.02\n",
            "iteration: 387090 loss: 0.0011 lr: 0.02\n",
            "iteration: 387100 loss: 0.0016 lr: 0.02\n",
            "iteration: 387110 loss: 0.0023 lr: 0.02\n",
            "iteration: 387120 loss: 0.0017 lr: 0.02\n",
            "iteration: 387130 loss: 0.0015 lr: 0.02\n",
            "iteration: 387140 loss: 0.0021 lr: 0.02\n",
            "iteration: 387150 loss: 0.0014 lr: 0.02\n",
            "iteration: 387160 loss: 0.0019 lr: 0.02\n",
            "iteration: 387170 loss: 0.0016 lr: 0.02\n",
            "iteration: 387180 loss: 0.0015 lr: 0.02\n",
            "iteration: 387190 loss: 0.0017 lr: 0.02\n",
            "iteration: 387200 loss: 0.0017 lr: 0.02\n",
            "iteration: 387210 loss: 0.0015 lr: 0.02\n",
            "iteration: 387220 loss: 0.0014 lr: 0.02\n",
            "iteration: 387230 loss: 0.0013 lr: 0.02\n",
            "iteration: 387240 loss: 0.0020 lr: 0.02\n",
            "iteration: 387250 loss: 0.0014 lr: 0.02\n",
            "iteration: 387260 loss: 0.0019 lr: 0.02\n",
            "iteration: 387270 loss: 0.0017 lr: 0.02\n",
            "iteration: 387280 loss: 0.0018 lr: 0.02\n",
            "iteration: 387290 loss: 0.0012 lr: 0.02\n",
            "iteration: 387300 loss: 0.0015 lr: 0.02\n",
            "iteration: 387310 loss: 0.0019 lr: 0.02\n",
            "iteration: 387320 loss: 0.0011 lr: 0.02\n",
            "iteration: 387330 loss: 0.0010 lr: 0.02\n",
            "iteration: 387340 loss: 0.0015 lr: 0.02\n",
            "iteration: 387350 loss: 0.0017 lr: 0.02\n",
            "iteration: 387360 loss: 0.0011 lr: 0.02\n",
            "iteration: 387370 loss: 0.0015 lr: 0.02\n",
            "iteration: 387380 loss: 0.0020 lr: 0.02\n",
            "iteration: 387390 loss: 0.0014 lr: 0.02\n",
            "iteration: 387400 loss: 0.0014 lr: 0.02\n",
            "iteration: 387410 loss: 0.0017 lr: 0.02\n",
            "iteration: 387420 loss: 0.0013 lr: 0.02\n",
            "iteration: 387430 loss: 0.0015 lr: 0.02\n",
            "iteration: 387440 loss: 0.0012 lr: 0.02\n",
            "iteration: 387450 loss: 0.0018 lr: 0.02\n",
            "iteration: 387460 loss: 0.0012 lr: 0.02\n",
            "iteration: 387470 loss: 0.0024 lr: 0.02\n",
            "iteration: 387480 loss: 0.0013 lr: 0.02\n",
            "iteration: 387490 loss: 0.0017 lr: 0.02\n",
            "iteration: 387500 loss: 0.0018 lr: 0.02\n",
            "iteration: 387510 loss: 0.0015 lr: 0.02\n",
            "iteration: 387520 loss: 0.0017 lr: 0.02\n",
            "iteration: 387530 loss: 0.0023 lr: 0.02\n",
            "iteration: 387540 loss: 0.0015 lr: 0.02\n",
            "iteration: 387550 loss: 0.0019 lr: 0.02\n",
            "iteration: 387560 loss: 0.0017 lr: 0.02\n",
            "iteration: 387570 loss: 0.0014 lr: 0.02\n",
            "iteration: 387580 loss: 0.0013 lr: 0.02\n",
            "iteration: 387590 loss: 0.0018 lr: 0.02\n",
            "iteration: 387600 loss: 0.0017 lr: 0.02\n",
            "iteration: 387610 loss: 0.0017 lr: 0.02\n",
            "iteration: 387620 loss: 0.0018 lr: 0.02\n",
            "iteration: 387630 loss: 0.0013 lr: 0.02\n",
            "iteration: 387640 loss: 0.0016 lr: 0.02\n",
            "iteration: 387650 loss: 0.0017 lr: 0.02\n",
            "iteration: 387660 loss: 0.0015 lr: 0.02\n",
            "iteration: 387670 loss: 0.0016 lr: 0.02\n",
            "iteration: 387680 loss: 0.0019 lr: 0.02\n",
            "iteration: 387690 loss: 0.0014 lr: 0.02\n",
            "iteration: 387700 loss: 0.0016 lr: 0.02\n",
            "iteration: 387710 loss: 0.0015 lr: 0.02\n",
            "iteration: 387720 loss: 0.0012 lr: 0.02\n",
            "iteration: 387730 loss: 0.0014 lr: 0.02\n",
            "iteration: 387740 loss: 0.0017 lr: 0.02\n",
            "iteration: 387750 loss: 0.0013 lr: 0.02\n",
            "iteration: 387760 loss: 0.0015 lr: 0.02\n",
            "iteration: 387770 loss: 0.0011 lr: 0.02\n",
            "iteration: 387780 loss: 0.0020 lr: 0.02\n",
            "iteration: 387790 loss: 0.0019 lr: 0.02\n",
            "iteration: 387800 loss: 0.0011 lr: 0.02\n",
            "iteration: 387810 loss: 0.0018 lr: 0.02\n",
            "iteration: 387820 loss: 0.0012 lr: 0.02\n",
            "iteration: 387830 loss: 0.0014 lr: 0.02\n",
            "iteration: 387840 loss: 0.0015 lr: 0.02\n",
            "iteration: 387850 loss: 0.0013 lr: 0.02\n",
            "iteration: 387860 loss: 0.0012 lr: 0.02\n",
            "iteration: 387870 loss: 0.0016 lr: 0.02\n",
            "iteration: 387880 loss: 0.0020 lr: 0.02\n",
            "iteration: 387890 loss: 0.0018 lr: 0.02\n",
            "iteration: 387900 loss: 0.0018 lr: 0.02\n",
            "iteration: 387910 loss: 0.0020 lr: 0.02\n",
            "iteration: 387920 loss: 0.0018 lr: 0.02\n",
            "iteration: 387930 loss: 0.0012 lr: 0.02\n",
            "iteration: 387940 loss: 0.0012 lr: 0.02\n",
            "iteration: 387950 loss: 0.0020 lr: 0.02\n",
            "iteration: 387960 loss: 0.0014 lr: 0.02\n",
            "iteration: 387970 loss: 0.0015 lr: 0.02\n",
            "iteration: 387980 loss: 0.0018 lr: 0.02\n",
            "iteration: 387990 loss: 0.0014 lr: 0.02\n",
            "iteration: 388000 loss: 0.0019 lr: 0.02\n",
            "iteration: 388010 loss: 0.0017 lr: 0.02\n",
            "iteration: 388020 loss: 0.0019 lr: 0.02\n",
            "iteration: 388030 loss: 0.0017 lr: 0.02\n",
            "iteration: 388040 loss: 0.0018 lr: 0.02\n",
            "iteration: 388050 loss: 0.0015 lr: 0.02\n",
            "iteration: 388060 loss: 0.0019 lr: 0.02\n",
            "iteration: 388070 loss: 0.0019 lr: 0.02\n",
            "iteration: 388080 loss: 0.0013 lr: 0.02\n",
            "iteration: 388090 loss: 0.0014 lr: 0.02\n",
            "iteration: 388100 loss: 0.0019 lr: 0.02\n",
            "iteration: 388110 loss: 0.0011 lr: 0.02\n",
            "iteration: 388120 loss: 0.0014 lr: 0.02\n",
            "iteration: 388130 loss: 0.0013 lr: 0.02\n",
            "iteration: 388140 loss: 0.0013 lr: 0.02\n",
            "iteration: 388150 loss: 0.0011 lr: 0.02\n",
            "iteration: 388160 loss: 0.0021 lr: 0.02\n",
            "iteration: 388170 loss: 0.0018 lr: 0.02\n",
            "iteration: 388180 loss: 0.0019 lr: 0.02\n",
            "iteration: 388190 loss: 0.0018 lr: 0.02\n",
            "iteration: 388200 loss: 0.0020 lr: 0.02\n",
            "iteration: 388210 loss: 0.0016 lr: 0.02\n",
            "iteration: 388220 loss: 0.0020 lr: 0.02\n",
            "iteration: 388230 loss: 0.0016 lr: 0.02\n",
            "iteration: 388240 loss: 0.0017 lr: 0.02\n",
            "iteration: 388250 loss: 0.0014 lr: 0.02\n",
            "iteration: 388260 loss: 0.0013 lr: 0.02\n",
            "iteration: 388270 loss: 0.0015 lr: 0.02\n",
            "iteration: 388280 loss: 0.0019 lr: 0.02\n",
            "iteration: 388290 loss: 0.0016 lr: 0.02\n",
            "iteration: 388300 loss: 0.0014 lr: 0.02\n",
            "iteration: 388310 loss: 0.0014 lr: 0.02\n",
            "iteration: 388320 loss: 0.0017 lr: 0.02\n",
            "iteration: 388330 loss: 0.0015 lr: 0.02\n",
            "iteration: 388340 loss: 0.0013 lr: 0.02\n",
            "iteration: 388350 loss: 0.0022 lr: 0.02\n",
            "iteration: 388360 loss: 0.0015 lr: 0.02\n",
            "iteration: 388370 loss: 0.0016 lr: 0.02\n",
            "iteration: 388380 loss: 0.0019 lr: 0.02\n",
            "iteration: 388390 loss: 0.0016 lr: 0.02\n",
            "iteration: 388400 loss: 0.0017 lr: 0.02\n",
            "iteration: 388410 loss: 0.0021 lr: 0.02\n",
            "iteration: 388420 loss: 0.0013 lr: 0.02\n",
            "iteration: 388430 loss: 0.0016 lr: 0.02\n",
            "iteration: 388440 loss: 0.0018 lr: 0.02\n",
            "iteration: 388450 loss: 0.0015 lr: 0.02\n",
            "iteration: 388460 loss: 0.0019 lr: 0.02\n",
            "iteration: 388470 loss: 0.0017 lr: 0.02\n",
            "iteration: 388480 loss: 0.0017 lr: 0.02\n",
            "iteration: 388490 loss: 0.0019 lr: 0.02\n",
            "iteration: 388500 loss: 0.0011 lr: 0.02\n",
            "iteration: 388510 loss: 0.0014 lr: 0.02\n",
            "iteration: 388520 loss: 0.0034 lr: 0.02\n",
            "iteration: 388530 loss: 0.0022 lr: 0.02\n",
            "iteration: 388540 loss: 0.0014 lr: 0.02\n",
            "iteration: 388550 loss: 0.0019 lr: 0.02\n",
            "iteration: 388560 loss: 0.0013 lr: 0.02\n",
            "iteration: 388570 loss: 0.0017 lr: 0.02\n",
            "iteration: 388580 loss: 0.0018 lr: 0.02\n",
            "iteration: 388590 loss: 0.0011 lr: 0.02\n",
            "iteration: 388600 loss: 0.0018 lr: 0.02\n",
            "iteration: 388610 loss: 0.0014 lr: 0.02\n",
            "iteration: 388620 loss: 0.0018 lr: 0.02\n",
            "iteration: 388630 loss: 0.0021 lr: 0.02\n",
            "iteration: 388640 loss: 0.0020 lr: 0.02\n",
            "iteration: 388650 loss: 0.0018 lr: 0.02\n",
            "iteration: 388660 loss: 0.0015 lr: 0.02\n",
            "iteration: 388670 loss: 0.0022 lr: 0.02\n",
            "iteration: 388680 loss: 0.0021 lr: 0.02\n",
            "iteration: 388690 loss: 0.0015 lr: 0.02\n",
            "iteration: 388700 loss: 0.0014 lr: 0.02\n",
            "iteration: 388710 loss: 0.0020 lr: 0.02\n",
            "iteration: 388720 loss: 0.0012 lr: 0.02\n",
            "iteration: 388730 loss: 0.0017 lr: 0.02\n",
            "iteration: 388740 loss: 0.0013 lr: 0.02\n",
            "iteration: 388750 loss: 0.0013 lr: 0.02\n",
            "iteration: 388760 loss: 0.0014 lr: 0.02\n",
            "iteration: 388770 loss: 0.0014 lr: 0.02\n",
            "iteration: 388780 loss: 0.0014 lr: 0.02\n",
            "iteration: 388790 loss: 0.0013 lr: 0.02\n",
            "iteration: 388800 loss: 0.0015 lr: 0.02\n",
            "iteration: 388810 loss: 0.0019 lr: 0.02\n",
            "iteration: 388820 loss: 0.0015 lr: 0.02\n",
            "iteration: 388830 loss: 0.0016 lr: 0.02\n",
            "iteration: 388840 loss: 0.0019 lr: 0.02\n",
            "iteration: 388850 loss: 0.0015 lr: 0.02\n",
            "iteration: 388860 loss: 0.0019 lr: 0.02\n",
            "iteration: 388870 loss: 0.0012 lr: 0.02\n",
            "iteration: 388880 loss: 0.0014 lr: 0.02\n",
            "iteration: 388890 loss: 0.0015 lr: 0.02\n",
            "iteration: 388900 loss: 0.0018 lr: 0.02\n",
            "iteration: 388910 loss: 0.0024 lr: 0.02\n",
            "iteration: 388920 loss: 0.0020 lr: 0.02\n",
            "iteration: 388930 loss: 0.0024 lr: 0.02\n",
            "iteration: 388940 loss: 0.0019 lr: 0.02\n",
            "iteration: 388950 loss: 0.0016 lr: 0.02\n",
            "iteration: 388960 loss: 0.0013 lr: 0.02\n",
            "iteration: 388970 loss: 0.0014 lr: 0.02\n",
            "iteration: 388980 loss: 0.0021 lr: 0.02\n",
            "iteration: 388990 loss: 0.0016 lr: 0.02\n",
            "iteration: 389000 loss: 0.0015 lr: 0.02\n",
            "iteration: 389010 loss: 0.0015 lr: 0.02\n",
            "iteration: 389020 loss: 0.0018 lr: 0.02\n",
            "iteration: 389030 loss: 0.0014 lr: 0.02\n",
            "iteration: 389040 loss: 0.0037 lr: 0.02\n",
            "iteration: 389050 loss: 0.0022 lr: 0.02\n",
            "iteration: 389060 loss: 0.0018 lr: 0.02\n",
            "iteration: 389070 loss: 0.0016 lr: 0.02\n",
            "iteration: 389080 loss: 0.0018 lr: 0.02\n",
            "iteration: 389090 loss: 0.0023 lr: 0.02\n",
            "iteration: 389100 loss: 0.0015 lr: 0.02\n",
            "iteration: 389110 loss: 0.0018 lr: 0.02\n",
            "iteration: 389120 loss: 0.0020 lr: 0.02\n",
            "iteration: 389130 loss: 0.0014 lr: 0.02\n",
            "iteration: 389140 loss: 0.0028 lr: 0.02\n",
            "iteration: 389150 loss: 0.0019 lr: 0.02\n",
            "iteration: 389160 loss: 0.0016 lr: 0.02\n",
            "iteration: 389170 loss: 0.0019 lr: 0.02\n",
            "iteration: 389180 loss: 0.0015 lr: 0.02\n",
            "iteration: 389190 loss: 0.0018 lr: 0.02\n",
            "iteration: 389200 loss: 0.0021 lr: 0.02\n",
            "iteration: 389210 loss: 0.0016 lr: 0.02\n",
            "iteration: 389220 loss: 0.0019 lr: 0.02\n",
            "iteration: 389230 loss: 0.0019 lr: 0.02\n",
            "iteration: 389240 loss: 0.0017 lr: 0.02\n",
            "iteration: 389250 loss: 0.0018 lr: 0.02\n",
            "iteration: 389260 loss: 0.0017 lr: 0.02\n",
            "iteration: 389270 loss: 0.0018 lr: 0.02\n",
            "iteration: 389280 loss: 0.0021 lr: 0.02\n",
            "iteration: 389290 loss: 0.0020 lr: 0.02\n",
            "iteration: 389300 loss: 0.0020 lr: 0.02\n",
            "iteration: 389310 loss: 0.0014 lr: 0.02\n",
            "iteration: 389320 loss: 0.0014 lr: 0.02\n",
            "iteration: 389330 loss: 0.0016 lr: 0.02\n",
            "iteration: 389340 loss: 0.0013 lr: 0.02\n",
            "iteration: 389350 loss: 0.0019 lr: 0.02\n",
            "iteration: 389360 loss: 0.0019 lr: 0.02\n",
            "iteration: 389370 loss: 0.0017 lr: 0.02\n",
            "iteration: 389380 loss: 0.0014 lr: 0.02\n",
            "iteration: 389390 loss: 0.0016 lr: 0.02\n",
            "iteration: 389400 loss: 0.0017 lr: 0.02\n",
            "iteration: 389410 loss: 0.0017 lr: 0.02\n",
            "iteration: 389420 loss: 0.0015 lr: 0.02\n",
            "iteration: 389430 loss: 0.0028 lr: 0.02\n",
            "iteration: 389440 loss: 0.0017 lr: 0.02\n",
            "iteration: 389450 loss: 0.0018 lr: 0.02\n",
            "iteration: 389460 loss: 0.0017 lr: 0.02\n",
            "iteration: 389470 loss: 0.0014 lr: 0.02\n",
            "iteration: 389480 loss: 0.0016 lr: 0.02\n",
            "iteration: 389490 loss: 0.0014 lr: 0.02\n",
            "iteration: 389500 loss: 0.0013 lr: 0.02\n",
            "iteration: 389510 loss: 0.0016 lr: 0.02\n",
            "iteration: 389520 loss: 0.0015 lr: 0.02\n",
            "iteration: 389530 loss: 0.0015 lr: 0.02\n",
            "iteration: 389540 loss: 0.0012 lr: 0.02\n",
            "iteration: 389550 loss: 0.0016 lr: 0.02\n",
            "iteration: 389560 loss: 0.0014 lr: 0.02\n",
            "iteration: 389570 loss: 0.0015 lr: 0.02\n",
            "iteration: 389580 loss: 0.0026 lr: 0.02\n",
            "iteration: 389590 loss: 0.0019 lr: 0.02\n",
            "iteration: 389600 loss: 0.0017 lr: 0.02\n",
            "iteration: 389610 loss: 0.0017 lr: 0.02\n",
            "iteration: 389620 loss: 0.0015 lr: 0.02\n",
            "iteration: 389630 loss: 0.0015 lr: 0.02\n",
            "iteration: 389640 loss: 0.0011 lr: 0.02\n",
            "iteration: 389650 loss: 0.0018 lr: 0.02\n",
            "iteration: 389660 loss: 0.0015 lr: 0.02\n",
            "iteration: 389670 loss: 0.0014 lr: 0.02\n",
            "iteration: 389680 loss: 0.0014 lr: 0.02\n",
            "iteration: 389690 loss: 0.0013 lr: 0.02\n",
            "iteration: 389700 loss: 0.0020 lr: 0.02\n",
            "iteration: 389710 loss: 0.0016 lr: 0.02\n",
            "iteration: 389720 loss: 0.0013 lr: 0.02\n",
            "iteration: 389730 loss: 0.0019 lr: 0.02\n",
            "iteration: 389740 loss: 0.0013 lr: 0.02\n",
            "iteration: 389750 loss: 0.0020 lr: 0.02\n",
            "iteration: 389760 loss: 0.0017 lr: 0.02\n",
            "iteration: 389770 loss: 0.0015 lr: 0.02\n",
            "iteration: 389780 loss: 0.0017 lr: 0.02\n",
            "iteration: 389790 loss: 0.0014 lr: 0.02\n",
            "iteration: 389800 loss: 0.0013 lr: 0.02\n",
            "iteration: 389810 loss: 0.0021 lr: 0.02\n",
            "iteration: 389820 loss: 0.0014 lr: 0.02\n",
            "iteration: 389830 loss: 0.0016 lr: 0.02\n",
            "iteration: 389840 loss: 0.0014 lr: 0.02\n",
            "iteration: 389850 loss: 0.0018 lr: 0.02\n",
            "iteration: 389860 loss: 0.0014 lr: 0.02\n",
            "iteration: 389870 loss: 0.0014 lr: 0.02\n",
            "iteration: 389880 loss: 0.0015 lr: 0.02\n",
            "iteration: 389890 loss: 0.0013 lr: 0.02\n",
            "iteration: 389900 loss: 0.0017 lr: 0.02\n",
            "iteration: 389910 loss: 0.0019 lr: 0.02\n",
            "iteration: 389920 loss: 0.0011 lr: 0.02\n",
            "iteration: 389930 loss: 0.0014 lr: 0.02\n",
            "iteration: 389940 loss: 0.0012 lr: 0.02\n",
            "iteration: 389950 loss: 0.0016 lr: 0.02\n",
            "iteration: 389960 loss: 0.0017 lr: 0.02\n",
            "iteration: 389970 loss: 0.0016 lr: 0.02\n",
            "iteration: 389980 loss: 0.0015 lr: 0.02\n",
            "iteration: 389990 loss: 0.0012 lr: 0.02\n",
            "iteration: 390000 loss: 0.0013 lr: 0.02\n",
            "iteration: 390010 loss: 0.0019 lr: 0.02\n",
            "iteration: 390020 loss: 0.0019 lr: 0.02\n",
            "iteration: 390030 loss: 0.0015 lr: 0.02\n",
            "iteration: 390040 loss: 0.0014 lr: 0.02\n",
            "iteration: 390050 loss: 0.0019 lr: 0.02\n",
            "iteration: 390060 loss: 0.0011 lr: 0.02\n",
            "iteration: 390070 loss: 0.0021 lr: 0.02\n",
            "iteration: 390080 loss: 0.0014 lr: 0.02\n",
            "iteration: 390090 loss: 0.0015 lr: 0.02\n",
            "iteration: 390100 loss: 0.0013 lr: 0.02\n",
            "iteration: 390110 loss: 0.0013 lr: 0.02\n",
            "iteration: 390120 loss: 0.0017 lr: 0.02\n",
            "iteration: 390130 loss: 0.0018 lr: 0.02\n",
            "iteration: 390140 loss: 0.0012 lr: 0.02\n",
            "iteration: 390150 loss: 0.0017 lr: 0.02\n",
            "iteration: 390160 loss: 0.0017 lr: 0.02\n",
            "iteration: 390170 loss: 0.0014 lr: 0.02\n",
            "iteration: 390180 loss: 0.0013 lr: 0.02\n",
            "iteration: 390190 loss: 0.0013 lr: 0.02\n",
            "iteration: 390200 loss: 0.0015 lr: 0.02\n",
            "iteration: 390210 loss: 0.0018 lr: 0.02\n",
            "iteration: 390220 loss: 0.0022 lr: 0.02\n",
            "iteration: 390230 loss: 0.0013 lr: 0.02\n",
            "iteration: 390240 loss: 0.0011 lr: 0.02\n",
            "iteration: 390250 loss: 0.0017 lr: 0.02\n",
            "iteration: 390260 loss: 0.0010 lr: 0.02\n",
            "iteration: 390270 loss: 0.0019 lr: 0.02\n",
            "iteration: 390280 loss: 0.0017 lr: 0.02\n",
            "iteration: 390290 loss: 0.0017 lr: 0.02\n",
            "iteration: 390300 loss: 0.0019 lr: 0.02\n",
            "iteration: 390310 loss: 0.0009 lr: 0.02\n",
            "iteration: 390320 loss: 0.0017 lr: 0.02\n",
            "iteration: 390330 loss: 0.0018 lr: 0.02\n",
            "iteration: 390340 loss: 0.0020 lr: 0.02\n",
            "iteration: 390350 loss: 0.0019 lr: 0.02\n",
            "iteration: 390360 loss: 0.0018 lr: 0.02\n",
            "iteration: 390370 loss: 0.0010 lr: 0.02\n",
            "iteration: 390380 loss: 0.0019 lr: 0.02\n",
            "iteration: 390390 loss: 0.0013 lr: 0.02\n",
            "iteration: 390400 loss: 0.0024 lr: 0.02\n",
            "iteration: 390410 loss: 0.0015 lr: 0.02\n",
            "iteration: 390420 loss: 0.0013 lr: 0.02\n",
            "iteration: 390430 loss: 0.0012 lr: 0.02\n",
            "iteration: 390440 loss: 0.0017 lr: 0.02\n",
            "iteration: 390450 loss: 0.0016 lr: 0.02\n",
            "iteration: 390460 loss: 0.0013 lr: 0.02\n",
            "iteration: 390470 loss: 0.0014 lr: 0.02\n",
            "iteration: 390480 loss: 0.0016 lr: 0.02\n",
            "iteration: 390490 loss: 0.0014 lr: 0.02\n",
            "iteration: 390500 loss: 0.0016 lr: 0.02\n",
            "iteration: 390510 loss: 0.0017 lr: 0.02\n",
            "iteration: 390520 loss: 0.0011 lr: 0.02\n",
            "iteration: 390530 loss: 0.0014 lr: 0.02\n",
            "iteration: 390540 loss: 0.0018 lr: 0.02\n",
            "iteration: 390550 loss: 0.0020 lr: 0.02\n",
            "iteration: 390560 loss: 0.0018 lr: 0.02\n",
            "iteration: 390570 loss: 0.0015 lr: 0.02\n",
            "iteration: 390580 loss: 0.0018 lr: 0.02\n",
            "iteration: 390590 loss: 0.0017 lr: 0.02\n",
            "iteration: 390600 loss: 0.0014 lr: 0.02\n",
            "iteration: 390610 loss: 0.0018 lr: 0.02\n",
            "iteration: 390620 loss: 0.0016 lr: 0.02\n",
            "iteration: 390630 loss: 0.0017 lr: 0.02\n",
            "iteration: 390640 loss: 0.0015 lr: 0.02\n",
            "iteration: 390650 loss: 0.0012 lr: 0.02\n",
            "iteration: 390660 loss: 0.0015 lr: 0.02\n",
            "iteration: 390670 loss: 0.0019 lr: 0.02\n",
            "iteration: 390680 loss: 0.0018 lr: 0.02\n",
            "iteration: 390690 loss: 0.0017 lr: 0.02\n",
            "iteration: 390700 loss: 0.0017 lr: 0.02\n",
            "iteration: 390710 loss: 0.0021 lr: 0.02\n",
            "iteration: 390720 loss: 0.0019 lr: 0.02\n",
            "iteration: 390730 loss: 0.0016 lr: 0.02\n",
            "iteration: 390740 loss: 0.0018 lr: 0.02\n",
            "iteration: 390750 loss: 0.0020 lr: 0.02\n",
            "iteration: 390760 loss: 0.0015 lr: 0.02\n",
            "iteration: 390770 loss: 0.0013 lr: 0.02\n",
            "iteration: 390780 loss: 0.0016 lr: 0.02\n",
            "iteration: 390790 loss: 0.0021 lr: 0.02\n",
            "iteration: 390800 loss: 0.0020 lr: 0.02\n",
            "iteration: 390810 loss: 0.0019 lr: 0.02\n",
            "iteration: 390820 loss: 0.0017 lr: 0.02\n",
            "iteration: 390830 loss: 0.0016 lr: 0.02\n",
            "iteration: 390840 loss: 0.0014 lr: 0.02\n",
            "iteration: 390850 loss: 0.0016 lr: 0.02\n",
            "iteration: 390860 loss: 0.0019 lr: 0.02\n",
            "iteration: 390870 loss: 0.0018 lr: 0.02\n",
            "iteration: 390880 loss: 0.0013 lr: 0.02\n",
            "iteration: 390890 loss: 0.0015 lr: 0.02\n",
            "iteration: 390900 loss: 0.0017 lr: 0.02\n",
            "iteration: 390910 loss: 0.0012 lr: 0.02\n",
            "iteration: 390920 loss: 0.0017 lr: 0.02\n",
            "iteration: 390930 loss: 0.0020 lr: 0.02\n",
            "iteration: 390940 loss: 0.0020 lr: 0.02\n",
            "iteration: 390950 loss: 0.0018 lr: 0.02\n",
            "iteration: 390960 loss: 0.0020 lr: 0.02\n",
            "iteration: 390970 loss: 0.0018 lr: 0.02\n",
            "iteration: 390980 loss: 0.0014 lr: 0.02\n",
            "iteration: 390990 loss: 0.0018 lr: 0.02\n",
            "iteration: 391000 loss: 0.0013 lr: 0.02\n",
            "iteration: 391010 loss: 0.0013 lr: 0.02\n",
            "iteration: 391020 loss: 0.0024 lr: 0.02\n",
            "iteration: 391030 loss: 0.0017 lr: 0.02\n",
            "iteration: 391040 loss: 0.0016 lr: 0.02\n",
            "iteration: 391050 loss: 0.0018 lr: 0.02\n",
            "iteration: 391060 loss: 0.0011 lr: 0.02\n",
            "iteration: 391070 loss: 0.0020 lr: 0.02\n",
            "iteration: 391080 loss: 0.0013 lr: 0.02\n",
            "iteration: 391090 loss: 0.0014 lr: 0.02\n",
            "iteration: 391100 loss: 0.0017 lr: 0.02\n",
            "iteration: 391110 loss: 0.0017 lr: 0.02\n",
            "iteration: 391120 loss: 0.0014 lr: 0.02\n",
            "iteration: 391130 loss: 0.0014 lr: 0.02\n",
            "iteration: 391140 loss: 0.0019 lr: 0.02\n",
            "iteration: 391150 loss: 0.0019 lr: 0.02\n",
            "iteration: 391160 loss: 0.0016 lr: 0.02\n",
            "iteration: 391170 loss: 0.0018 lr: 0.02\n",
            "iteration: 391180 loss: 0.0014 lr: 0.02\n",
            "iteration: 391190 loss: 0.0011 lr: 0.02\n",
            "iteration: 391200 loss: 0.0017 lr: 0.02\n",
            "iteration: 391210 loss: 0.0015 lr: 0.02\n",
            "iteration: 391220 loss: 0.0017 lr: 0.02\n",
            "iteration: 391230 loss: 0.0021 lr: 0.02\n",
            "iteration: 391240 loss: 0.0019 lr: 0.02\n",
            "iteration: 391250 loss: 0.0022 lr: 0.02\n",
            "iteration: 391260 loss: 0.0015 lr: 0.02\n",
            "iteration: 391270 loss: 0.0015 lr: 0.02\n",
            "iteration: 391280 loss: 0.0013 lr: 0.02\n",
            "iteration: 391290 loss: 0.0018 lr: 0.02\n",
            "iteration: 391300 loss: 0.0015 lr: 0.02\n",
            "iteration: 391310 loss: 0.0016 lr: 0.02\n",
            "iteration: 391320 loss: 0.0018 lr: 0.02\n",
            "iteration: 391330 loss: 0.0019 lr: 0.02\n",
            "iteration: 391340 loss: 0.0018 lr: 0.02\n",
            "iteration: 391350 loss: 0.0017 lr: 0.02\n",
            "iteration: 391360 loss: 0.0018 lr: 0.02\n",
            "iteration: 391370 loss: 0.0021 lr: 0.02\n",
            "iteration: 391380 loss: 0.0015 lr: 0.02\n",
            "iteration: 391390 loss: 0.0014 lr: 0.02\n",
            "iteration: 391400 loss: 0.0017 lr: 0.02\n",
            "iteration: 391410 loss: 0.0018 lr: 0.02\n",
            "iteration: 391420 loss: 0.0017 lr: 0.02\n",
            "iteration: 391430 loss: 0.0018 lr: 0.02\n",
            "iteration: 391440 loss: 0.0013 lr: 0.02\n",
            "iteration: 391450 loss: 0.0014 lr: 0.02\n",
            "iteration: 391460 loss: 0.0014 lr: 0.02\n",
            "iteration: 391470 loss: 0.0012 lr: 0.02\n",
            "iteration: 391480 loss: 0.0014 lr: 0.02\n",
            "iteration: 391490 loss: 0.0016 lr: 0.02\n",
            "iteration: 391500 loss: 0.0016 lr: 0.02\n",
            "iteration: 391510 loss: 0.0016 lr: 0.02\n",
            "iteration: 391520 loss: 0.0016 lr: 0.02\n",
            "iteration: 391530 loss: 0.0018 lr: 0.02\n",
            "iteration: 391540 loss: 0.0019 lr: 0.02\n",
            "iteration: 391550 loss: 0.0015 lr: 0.02\n",
            "iteration: 391560 loss: 0.0018 lr: 0.02\n",
            "iteration: 391570 loss: 0.0017 lr: 0.02\n",
            "iteration: 391580 loss: 0.0017 lr: 0.02\n",
            "iteration: 391590 loss: 0.0011 lr: 0.02\n",
            "iteration: 391600 loss: 0.0012 lr: 0.02\n",
            "iteration: 391610 loss: 0.0013 lr: 0.02\n",
            "iteration: 391620 loss: 0.0014 lr: 0.02\n",
            "iteration: 391630 loss: 0.0014 lr: 0.02\n",
            "iteration: 391640 loss: 0.0016 lr: 0.02\n",
            "iteration: 391650 loss: 0.0018 lr: 0.02\n",
            "iteration: 391660 loss: 0.0018 lr: 0.02\n",
            "iteration: 391670 loss: 0.0014 lr: 0.02\n",
            "iteration: 391680 loss: 0.0018 lr: 0.02\n",
            "iteration: 391690 loss: 0.0016 lr: 0.02\n",
            "iteration: 391700 loss: 0.0018 lr: 0.02\n",
            "iteration: 391710 loss: 0.0018 lr: 0.02\n",
            "iteration: 391720 loss: 0.0016 lr: 0.02\n",
            "iteration: 391730 loss: 0.0015 lr: 0.02\n",
            "iteration: 391740 loss: 0.0020 lr: 0.02\n",
            "iteration: 391750 loss: 0.0017 lr: 0.02\n",
            "iteration: 391760 loss: 0.0022 lr: 0.02\n",
            "iteration: 391770 loss: 0.0015 lr: 0.02\n",
            "iteration: 391780 loss: 0.0014 lr: 0.02\n",
            "iteration: 391790 loss: 0.0014 lr: 0.02\n",
            "iteration: 391800 loss: 0.0017 lr: 0.02\n",
            "iteration: 391810 loss: 0.0019 lr: 0.02\n",
            "iteration: 391820 loss: 0.0022 lr: 0.02\n",
            "iteration: 391830 loss: 0.0019 lr: 0.02\n",
            "iteration: 391840 loss: 0.0022 lr: 0.02\n",
            "iteration: 391850 loss: 0.0014 lr: 0.02\n",
            "iteration: 391860 loss: 0.0011 lr: 0.02\n",
            "iteration: 391870 loss: 0.0015 lr: 0.02\n",
            "iteration: 391880 loss: 0.0017 lr: 0.02\n",
            "iteration: 391890 loss: 0.0014 lr: 0.02\n",
            "iteration: 391900 loss: 0.0013 lr: 0.02\n",
            "iteration: 391910 loss: 0.0019 lr: 0.02\n",
            "iteration: 391920 loss: 0.0016 lr: 0.02\n",
            "iteration: 391930 loss: 0.0024 lr: 0.02\n",
            "iteration: 391940 loss: 0.0016 lr: 0.02\n",
            "iteration: 391950 loss: 0.0018 lr: 0.02\n",
            "iteration: 391960 loss: 0.0014 lr: 0.02\n",
            "iteration: 391970 loss: 0.0018 lr: 0.02\n",
            "iteration: 391980 loss: 0.0015 lr: 0.02\n",
            "iteration: 391990 loss: 0.0016 lr: 0.02\n",
            "iteration: 392000 loss: 0.0016 lr: 0.02\n",
            "iteration: 392010 loss: 0.0013 lr: 0.02\n",
            "iteration: 392020 loss: 0.0015 lr: 0.02\n",
            "iteration: 392030 loss: 0.0016 lr: 0.02\n",
            "iteration: 392040 loss: 0.0016 lr: 0.02\n",
            "iteration: 392050 loss: 0.0014 lr: 0.02\n",
            "iteration: 392060 loss: 0.0015 lr: 0.02\n",
            "iteration: 392070 loss: 0.0014 lr: 0.02\n",
            "iteration: 392080 loss: 0.0015 lr: 0.02\n",
            "iteration: 392090 loss: 0.0015 lr: 0.02\n",
            "iteration: 392100 loss: 0.0013 lr: 0.02\n",
            "iteration: 392110 loss: 0.0012 lr: 0.02\n",
            "iteration: 392120 loss: 0.0014 lr: 0.02\n",
            "iteration: 392130 loss: 0.0014 lr: 0.02\n",
            "iteration: 392140 loss: 0.0013 lr: 0.02\n",
            "iteration: 392150 loss: 0.0016 lr: 0.02\n",
            "iteration: 392160 loss: 0.0016 lr: 0.02\n",
            "iteration: 392170 loss: 0.0019 lr: 0.02\n",
            "iteration: 392180 loss: 0.0013 lr: 0.02\n",
            "iteration: 392190 loss: 0.0021 lr: 0.02\n",
            "iteration: 392200 loss: 0.0020 lr: 0.02\n",
            "iteration: 392210 loss: 0.0015 lr: 0.02\n",
            "iteration: 392220 loss: 0.0016 lr: 0.02\n",
            "iteration: 392230 loss: 0.0015 lr: 0.02\n",
            "iteration: 392240 loss: 0.0018 lr: 0.02\n",
            "iteration: 392250 loss: 0.0016 lr: 0.02\n",
            "iteration: 392260 loss: 0.0019 lr: 0.02\n",
            "iteration: 392270 loss: 0.0018 lr: 0.02\n",
            "iteration: 392280 loss: 0.0019 lr: 0.02\n",
            "iteration: 392290 loss: 0.0017 lr: 0.02\n",
            "iteration: 392300 loss: 0.0015 lr: 0.02\n",
            "iteration: 392310 loss: 0.0015 lr: 0.02\n",
            "iteration: 392320 loss: 0.0017 lr: 0.02\n",
            "iteration: 392330 loss: 0.0017 lr: 0.02\n",
            "iteration: 392340 loss: 0.0015 lr: 0.02\n",
            "iteration: 392350 loss: 0.0022 lr: 0.02\n",
            "iteration: 392360 loss: 0.0011 lr: 0.02\n",
            "iteration: 392370 loss: 0.0019 lr: 0.02\n",
            "iteration: 392380 loss: 0.0014 lr: 0.02\n",
            "iteration: 392390 loss: 0.0013 lr: 0.02\n",
            "iteration: 392400 loss: 0.0012 lr: 0.02\n",
            "iteration: 392410 loss: 0.0021 lr: 0.02\n",
            "iteration: 392420 loss: 0.0015 lr: 0.02\n",
            "iteration: 392430 loss: 0.0019 lr: 0.02\n",
            "iteration: 392440 loss: 0.0016 lr: 0.02\n",
            "iteration: 392450 loss: 0.0020 lr: 0.02\n",
            "iteration: 392460 loss: 0.0016 lr: 0.02\n",
            "iteration: 392470 loss: 0.0017 lr: 0.02\n",
            "iteration: 392480 loss: 0.0019 lr: 0.02\n",
            "iteration: 392490 loss: 0.0016 lr: 0.02\n",
            "iteration: 392500 loss: 0.0016 lr: 0.02\n",
            "iteration: 392510 loss: 0.0013 lr: 0.02\n",
            "iteration: 392520 loss: 0.0019 lr: 0.02\n",
            "iteration: 392530 loss: 0.0018 lr: 0.02\n",
            "iteration: 392540 loss: 0.0020 lr: 0.02\n",
            "iteration: 392550 loss: 0.0013 lr: 0.02\n",
            "iteration: 392560 loss: 0.0017 lr: 0.02\n",
            "iteration: 392570 loss: 0.0017 lr: 0.02\n",
            "iteration: 392580 loss: 0.0016 lr: 0.02\n",
            "iteration: 392590 loss: 0.0016 lr: 0.02\n",
            "iteration: 392600 loss: 0.0010 lr: 0.02\n",
            "iteration: 392610 loss: 0.0015 lr: 0.02\n",
            "iteration: 392620 loss: 0.0012 lr: 0.02\n",
            "iteration: 392630 loss: 0.0016 lr: 0.02\n",
            "iteration: 392640 loss: 0.0017 lr: 0.02\n",
            "iteration: 392650 loss: 0.0017 lr: 0.02\n",
            "iteration: 392660 loss: 0.0011 lr: 0.02\n",
            "iteration: 392670 loss: 0.0017 lr: 0.02\n",
            "iteration: 392680 loss: 0.0015 lr: 0.02\n",
            "iteration: 392690 loss: 0.0019 lr: 0.02\n",
            "iteration: 392700 loss: 0.0012 lr: 0.02\n",
            "iteration: 392710 loss: 0.0018 lr: 0.02\n",
            "iteration: 392720 loss: 0.0013 lr: 0.02\n",
            "iteration: 392730 loss: 0.0023 lr: 0.02\n",
            "iteration: 392740 loss: 0.0016 lr: 0.02\n",
            "iteration: 392750 loss: 0.0014 lr: 0.02\n",
            "iteration: 392760 loss: 0.0020 lr: 0.02\n",
            "iteration: 392770 loss: 0.0022 lr: 0.02\n",
            "iteration: 392780 loss: 0.0013 lr: 0.02\n",
            "iteration: 392790 loss: 0.0016 lr: 0.02\n",
            "iteration: 392800 loss: 0.0013 lr: 0.02\n",
            "iteration: 392810 loss: 0.0014 lr: 0.02\n",
            "iteration: 392820 loss: 0.0013 lr: 0.02\n",
            "iteration: 392830 loss: 0.0016 lr: 0.02\n",
            "iteration: 392840 loss: 0.0014 lr: 0.02\n",
            "iteration: 392850 loss: 0.0012 lr: 0.02\n",
            "iteration: 392860 loss: 0.0012 lr: 0.02\n",
            "iteration: 392870 loss: 0.0014 lr: 0.02\n",
            "iteration: 392880 loss: 0.0017 lr: 0.02\n",
            "iteration: 392890 loss: 0.0016 lr: 0.02\n",
            "iteration: 392900 loss: 0.0018 lr: 0.02\n",
            "iteration: 392910 loss: 0.0013 lr: 0.02\n",
            "iteration: 392920 loss: 0.0013 lr: 0.02\n",
            "iteration: 392930 loss: 0.0014 lr: 0.02\n",
            "iteration: 392940 loss: 0.0013 lr: 0.02\n",
            "iteration: 392950 loss: 0.0033 lr: 0.02\n",
            "iteration: 392960 loss: 0.0013 lr: 0.02\n",
            "iteration: 392970 loss: 0.0014 lr: 0.02\n",
            "iteration: 392980 loss: 0.0020 lr: 0.02\n",
            "iteration: 392990 loss: 0.0014 lr: 0.02\n",
            "iteration: 393000 loss: 0.0011 lr: 0.02\n",
            "iteration: 393010 loss: 0.0012 lr: 0.02\n",
            "iteration: 393020 loss: 0.0014 lr: 0.02\n",
            "iteration: 393030 loss: 0.0013 lr: 0.02\n",
            "iteration: 393040 loss: 0.0019 lr: 0.02\n",
            "iteration: 393050 loss: 0.0019 lr: 0.02\n",
            "iteration: 393060 loss: 0.0018 lr: 0.02\n",
            "iteration: 393070 loss: 0.0017 lr: 0.02\n",
            "iteration: 393080 loss: 0.0017 lr: 0.02\n",
            "iteration: 393090 loss: 0.0022 lr: 0.02\n",
            "iteration: 393100 loss: 0.0019 lr: 0.02\n",
            "iteration: 393110 loss: 0.0010 lr: 0.02\n",
            "iteration: 393120 loss: 0.0014 lr: 0.02\n",
            "iteration: 393130 loss: 0.0015 lr: 0.02\n",
            "iteration: 393140 loss: 0.0015 lr: 0.02\n",
            "iteration: 393150 loss: 0.0018 lr: 0.02\n",
            "iteration: 393160 loss: 0.0016 lr: 0.02\n",
            "iteration: 393170 loss: 0.0020 lr: 0.02\n",
            "iteration: 393180 loss: 0.0023 lr: 0.02\n",
            "iteration: 393190 loss: 0.0016 lr: 0.02\n",
            "iteration: 393200 loss: 0.0014 lr: 0.02\n",
            "iteration: 393210 loss: 0.0020 lr: 0.02\n",
            "iteration: 393220 loss: 0.0018 lr: 0.02\n",
            "iteration: 393230 loss: 0.0017 lr: 0.02\n",
            "iteration: 393240 loss: 0.0017 lr: 0.02\n",
            "iteration: 393250 loss: 0.0017 lr: 0.02\n",
            "iteration: 393260 loss: 0.0011 lr: 0.02\n",
            "iteration: 393270 loss: 0.0018 lr: 0.02\n",
            "iteration: 393280 loss: 0.0019 lr: 0.02\n",
            "iteration: 393290 loss: 0.0016 lr: 0.02\n",
            "iteration: 393300 loss: 0.0013 lr: 0.02\n",
            "iteration: 393310 loss: 0.0015 lr: 0.02\n",
            "iteration: 393320 loss: 0.0020 lr: 0.02\n",
            "iteration: 393330 loss: 0.0014 lr: 0.02\n",
            "iteration: 393340 loss: 0.0017 lr: 0.02\n",
            "iteration: 393350 loss: 0.0023 lr: 0.02\n",
            "iteration: 393360 loss: 0.0019 lr: 0.02\n",
            "iteration: 393370 loss: 0.0017 lr: 0.02\n",
            "iteration: 393380 loss: 0.0017 lr: 0.02\n",
            "iteration: 393390 loss: 0.0015 lr: 0.02\n",
            "iteration: 393400 loss: 0.0015 lr: 0.02\n",
            "iteration: 393410 loss: 0.0014 lr: 0.02\n",
            "iteration: 393420 loss: 0.0013 lr: 0.02\n",
            "iteration: 393430 loss: 0.0018 lr: 0.02\n",
            "iteration: 393440 loss: 0.0018 lr: 0.02\n",
            "iteration: 393450 loss: 0.0012 lr: 0.02\n",
            "iteration: 393460 loss: 0.0022 lr: 0.02\n",
            "iteration: 393470 loss: 0.0011 lr: 0.02\n",
            "iteration: 393480 loss: 0.0010 lr: 0.02\n",
            "iteration: 393490 loss: 0.0017 lr: 0.02\n",
            "iteration: 393500 loss: 0.0016 lr: 0.02\n",
            "iteration: 393510 loss: 0.0016 lr: 0.02\n",
            "iteration: 393520 loss: 0.0027 lr: 0.02\n",
            "iteration: 393530 loss: 0.0014 lr: 0.02\n",
            "iteration: 393540 loss: 0.0014 lr: 0.02\n",
            "iteration: 393550 loss: 0.0024 lr: 0.02\n",
            "iteration: 393560 loss: 0.0015 lr: 0.02\n",
            "iteration: 393570 loss: 0.0013 lr: 0.02\n",
            "iteration: 393580 loss: 0.0016 lr: 0.02\n",
            "iteration: 393590 loss: 0.0014 lr: 0.02\n",
            "iteration: 393600 loss: 0.0016 lr: 0.02\n",
            "iteration: 393610 loss: 0.0019 lr: 0.02\n",
            "iteration: 393620 loss: 0.0021 lr: 0.02\n",
            "iteration: 393630 loss: 0.0015 lr: 0.02\n",
            "iteration: 393640 loss: 0.0021 lr: 0.02\n",
            "iteration: 393650 loss: 0.0020 lr: 0.02\n",
            "iteration: 393660 loss: 0.0019 lr: 0.02\n",
            "iteration: 393670 loss: 0.0013 lr: 0.02\n",
            "iteration: 393680 loss: 0.0012 lr: 0.02\n",
            "iteration: 393690 loss: 0.0016 lr: 0.02\n",
            "iteration: 393700 loss: 0.0019 lr: 0.02\n",
            "iteration: 393710 loss: 0.0017 lr: 0.02\n",
            "iteration: 393720 loss: 0.0016 lr: 0.02\n",
            "iteration: 393730 loss: 0.0013 lr: 0.02\n",
            "iteration: 393740 loss: 0.0018 lr: 0.02\n",
            "iteration: 393750 loss: 0.0019 lr: 0.02\n",
            "iteration: 393760 loss: 0.0012 lr: 0.02\n",
            "iteration: 393770 loss: 0.0013 lr: 0.02\n",
            "iteration: 393780 loss: 0.0017 lr: 0.02\n",
            "iteration: 393790 loss: 0.0019 lr: 0.02\n",
            "iteration: 393800 loss: 0.0014 lr: 0.02\n",
            "iteration: 393810 loss: 0.0015 lr: 0.02\n",
            "iteration: 393820 loss: 0.0014 lr: 0.02\n",
            "iteration: 393830 loss: 0.0014 lr: 0.02\n",
            "iteration: 393840 loss: 0.0018 lr: 0.02\n",
            "iteration: 393850 loss: 0.0019 lr: 0.02\n",
            "iteration: 393860 loss: 0.0018 lr: 0.02\n",
            "iteration: 393870 loss: 0.0015 lr: 0.02\n",
            "iteration: 393880 loss: 0.0014 lr: 0.02\n",
            "iteration: 393890 loss: 0.0014 lr: 0.02\n",
            "iteration: 393900 loss: 0.0015 lr: 0.02\n",
            "iteration: 393910 loss: 0.0018 lr: 0.02\n",
            "iteration: 393920 loss: 0.0015 lr: 0.02\n",
            "iteration: 393930 loss: 0.0018 lr: 0.02\n",
            "iteration: 393940 loss: 0.0018 lr: 0.02\n",
            "iteration: 393950 loss: 0.0020 lr: 0.02\n",
            "iteration: 393960 loss: 0.0017 lr: 0.02\n",
            "iteration: 393970 loss: 0.0015 lr: 0.02\n",
            "iteration: 393980 loss: 0.0012 lr: 0.02\n",
            "iteration: 393990 loss: 0.0016 lr: 0.02\n",
            "iteration: 394000 loss: 0.0012 lr: 0.02\n",
            "iteration: 394010 loss: 0.0016 lr: 0.02\n",
            "iteration: 394020 loss: 0.0019 lr: 0.02\n",
            "iteration: 394030 loss: 0.0021 lr: 0.02\n",
            "iteration: 394040 loss: 0.0015 lr: 0.02\n",
            "iteration: 394050 loss: 0.0015 lr: 0.02\n",
            "iteration: 394060 loss: 0.0020 lr: 0.02\n",
            "iteration: 394070 loss: 0.0014 lr: 0.02\n",
            "iteration: 394080 loss: 0.0018 lr: 0.02\n",
            "iteration: 394090 loss: 0.0014 lr: 0.02\n",
            "iteration: 394100 loss: 0.0019 lr: 0.02\n",
            "iteration: 394110 loss: 0.0013 lr: 0.02\n",
            "iteration: 394120 loss: 0.0020 lr: 0.02\n",
            "iteration: 394130 loss: 0.0014 lr: 0.02\n",
            "iteration: 394140 loss: 0.0021 lr: 0.02\n",
            "iteration: 394150 loss: 0.0024 lr: 0.02\n",
            "iteration: 394160 loss: 0.0014 lr: 0.02\n",
            "iteration: 394170 loss: 0.0019 lr: 0.02\n",
            "iteration: 394180 loss: 0.0013 lr: 0.02\n",
            "iteration: 394190 loss: 0.0013 lr: 0.02\n",
            "iteration: 394200 loss: 0.0017 lr: 0.02\n",
            "iteration: 394210 loss: 0.0017 lr: 0.02\n",
            "iteration: 394220 loss: 0.0014 lr: 0.02\n",
            "iteration: 394230 loss: 0.0015 lr: 0.02\n",
            "iteration: 394240 loss: 0.0017 lr: 0.02\n",
            "iteration: 394250 loss: 0.0016 lr: 0.02\n",
            "iteration: 394260 loss: 0.0017 lr: 0.02\n",
            "iteration: 394270 loss: 0.0015 lr: 0.02\n",
            "iteration: 394280 loss: 0.0018 lr: 0.02\n",
            "iteration: 394290 loss: 0.0014 lr: 0.02\n",
            "iteration: 394300 loss: 0.0010 lr: 0.02\n",
            "iteration: 394310 loss: 0.0016 lr: 0.02\n",
            "iteration: 394320 loss: 0.0013 lr: 0.02\n",
            "iteration: 394330 loss: 0.0018 lr: 0.02\n",
            "iteration: 394340 loss: 0.0011 lr: 0.02\n",
            "iteration: 394350 loss: 0.0017 lr: 0.02\n",
            "iteration: 394360 loss: 0.0013 lr: 0.02\n",
            "iteration: 394370 loss: 0.0018 lr: 0.02\n",
            "iteration: 394380 loss: 0.0021 lr: 0.02\n",
            "iteration: 394390 loss: 0.0013 lr: 0.02\n",
            "iteration: 394400 loss: 0.0017 lr: 0.02\n",
            "iteration: 394410 loss: 0.0015 lr: 0.02\n",
            "iteration: 394420 loss: 0.0014 lr: 0.02\n",
            "iteration: 394430 loss: 0.0013 lr: 0.02\n",
            "iteration: 394440 loss: 0.0019 lr: 0.02\n",
            "iteration: 394450 loss: 0.0018 lr: 0.02\n",
            "iteration: 394460 loss: 0.0012 lr: 0.02\n",
            "iteration: 394470 loss: 0.0018 lr: 0.02\n",
            "iteration: 394480 loss: 0.0014 lr: 0.02\n",
            "iteration: 394490 loss: 0.0018 lr: 0.02\n",
            "iteration: 394500 loss: 0.0016 lr: 0.02\n",
            "iteration: 394510 loss: 0.0016 lr: 0.02\n",
            "iteration: 394520 loss: 0.0018 lr: 0.02\n",
            "iteration: 394530 loss: 0.0013 lr: 0.02\n",
            "iteration: 394540 loss: 0.0015 lr: 0.02\n",
            "iteration: 394550 loss: 0.0015 lr: 0.02\n",
            "iteration: 394560 loss: 0.0026 lr: 0.02\n",
            "iteration: 394570 loss: 0.0017 lr: 0.02\n",
            "iteration: 394580 loss: 0.0019 lr: 0.02\n",
            "iteration: 394590 loss: 0.0016 lr: 0.02\n",
            "iteration: 394600 loss: 0.0016 lr: 0.02\n",
            "iteration: 394610 loss: 0.0016 lr: 0.02\n",
            "iteration: 394620 loss: 0.0019 lr: 0.02\n",
            "iteration: 394630 loss: 0.0015 lr: 0.02\n",
            "iteration: 394640 loss: 0.0013 lr: 0.02\n",
            "iteration: 394650 loss: 0.0013 lr: 0.02\n",
            "iteration: 394660 loss: 0.0020 lr: 0.02\n",
            "iteration: 394670 loss: 0.0016 lr: 0.02\n",
            "iteration: 394680 loss: 0.0014 lr: 0.02\n",
            "iteration: 394690 loss: 0.0017 lr: 0.02\n",
            "iteration: 394700 loss: 0.0014 lr: 0.02\n",
            "iteration: 394710 loss: 0.0021 lr: 0.02\n",
            "iteration: 394720 loss: 0.0017 lr: 0.02\n",
            "iteration: 394730 loss: 0.0014 lr: 0.02\n",
            "iteration: 394740 loss: 0.0020 lr: 0.02\n",
            "iteration: 394750 loss: 0.0013 lr: 0.02\n",
            "iteration: 394760 loss: 0.0015 lr: 0.02\n",
            "iteration: 394770 loss: 0.0016 lr: 0.02\n",
            "iteration: 394780 loss: 0.0023 lr: 0.02\n",
            "iteration: 394790 loss: 0.0016 lr: 0.02\n",
            "iteration: 394800 loss: 0.0013 lr: 0.02\n",
            "iteration: 394810 loss: 0.0018 lr: 0.02\n",
            "iteration: 394820 loss: 0.0010 lr: 0.02\n",
            "iteration: 394830 loss: 0.0017 lr: 0.02\n",
            "iteration: 394840 loss: 0.0016 lr: 0.02\n",
            "iteration: 394850 loss: 0.0016 lr: 0.02\n",
            "iteration: 394860 loss: 0.0015 lr: 0.02\n",
            "iteration: 394870 loss: 0.0024 lr: 0.02\n",
            "iteration: 394880 loss: 0.0022 lr: 0.02\n",
            "iteration: 394890 loss: 0.0015 lr: 0.02\n",
            "iteration: 394900 loss: 0.0015 lr: 0.02\n",
            "iteration: 394910 loss: 0.0013 lr: 0.02\n",
            "iteration: 394920 loss: 0.0016 lr: 0.02\n",
            "iteration: 394930 loss: 0.0018 lr: 0.02\n",
            "iteration: 394940 loss: 0.0015 lr: 0.02\n",
            "iteration: 394950 loss: 0.0016 lr: 0.02\n",
            "iteration: 394960 loss: 0.0014 lr: 0.02\n",
            "iteration: 394970 loss: 0.0018 lr: 0.02\n",
            "iteration: 394980 loss: 0.0017 lr: 0.02\n",
            "iteration: 394990 loss: 0.0013 lr: 0.02\n",
            "iteration: 395000 loss: 0.0011 lr: 0.02\n",
            "iteration: 395010 loss: 0.0015 lr: 0.02\n",
            "iteration: 395020 loss: 0.0012 lr: 0.02\n",
            "iteration: 395030 loss: 0.0011 lr: 0.02\n",
            "iteration: 395040 loss: 0.0014 lr: 0.02\n",
            "iteration: 395050 loss: 0.0016 lr: 0.02\n",
            "iteration: 395060 loss: 0.0013 lr: 0.02\n",
            "iteration: 395070 loss: 0.0019 lr: 0.02\n",
            "iteration: 395080 loss: 0.0015 lr: 0.02\n",
            "iteration: 395090 loss: 0.0017 lr: 0.02\n",
            "iteration: 395100 loss: 0.0017 lr: 0.02\n",
            "iteration: 395110 loss: 0.0018 lr: 0.02\n",
            "iteration: 395120 loss: 0.0017 lr: 0.02\n",
            "iteration: 395130 loss: 0.0017 lr: 0.02\n",
            "iteration: 395140 loss: 0.0015 lr: 0.02\n",
            "iteration: 395150 loss: 0.0015 lr: 0.02\n",
            "iteration: 395160 loss: 0.0012 lr: 0.02\n",
            "iteration: 395170 loss: 0.0014 lr: 0.02\n",
            "iteration: 395180 loss: 0.0019 lr: 0.02\n",
            "iteration: 395190 loss: 0.0012 lr: 0.02\n",
            "iteration: 395200 loss: 0.0017 lr: 0.02\n",
            "iteration: 395210 loss: 0.0012 lr: 0.02\n",
            "iteration: 395220 loss: 0.0014 lr: 0.02\n",
            "iteration: 395230 loss: 0.0017 lr: 0.02\n",
            "iteration: 395240 loss: 0.0015 lr: 0.02\n",
            "iteration: 395250 loss: 0.0017 lr: 0.02\n",
            "iteration: 395260 loss: 0.0014 lr: 0.02\n",
            "iteration: 395270 loss: 0.0017 lr: 0.02\n",
            "iteration: 395280 loss: 0.0012 lr: 0.02\n",
            "iteration: 395290 loss: 0.0013 lr: 0.02\n",
            "iteration: 395300 loss: 0.0022 lr: 0.02\n",
            "iteration: 395310 loss: 0.0012 lr: 0.02\n",
            "iteration: 395320 loss: 0.0018 lr: 0.02\n",
            "iteration: 395330 loss: 0.0022 lr: 0.02\n",
            "iteration: 395340 loss: 0.0016 lr: 0.02\n",
            "iteration: 395350 loss: 0.0015 lr: 0.02\n",
            "iteration: 395360 loss: 0.0017 lr: 0.02\n",
            "iteration: 395370 loss: 0.0017 lr: 0.02\n",
            "iteration: 395380 loss: 0.0018 lr: 0.02\n",
            "iteration: 395390 loss: 0.0016 lr: 0.02\n",
            "iteration: 395400 loss: 0.0014 lr: 0.02\n",
            "iteration: 395410 loss: 0.0017 lr: 0.02\n",
            "iteration: 395420 loss: 0.0020 lr: 0.02\n",
            "iteration: 395430 loss: 0.0016 lr: 0.02\n",
            "iteration: 395440 loss: 0.0015 lr: 0.02\n",
            "iteration: 395450 loss: 0.0015 lr: 0.02\n",
            "iteration: 395460 loss: 0.0016 lr: 0.02\n",
            "iteration: 395470 loss: 0.0019 lr: 0.02\n",
            "iteration: 395480 loss: 0.0018 lr: 0.02\n",
            "iteration: 395490 loss: 0.0016 lr: 0.02\n",
            "iteration: 395500 loss: 0.0015 lr: 0.02\n",
            "iteration: 395510 loss: 0.0017 lr: 0.02\n",
            "iteration: 395520 loss: 0.0023 lr: 0.02\n",
            "iteration: 395530 loss: 0.0016 lr: 0.02\n",
            "iteration: 395540 loss: 0.0022 lr: 0.02\n",
            "iteration: 395550 loss: 0.0016 lr: 0.02\n",
            "iteration: 395560 loss: 0.0023 lr: 0.02\n",
            "iteration: 395570 loss: 0.0015 lr: 0.02\n",
            "iteration: 395580 loss: 0.0020 lr: 0.02\n",
            "iteration: 395590 loss: 0.0014 lr: 0.02\n",
            "iteration: 395600 loss: 0.0017 lr: 0.02\n",
            "iteration: 395610 loss: 0.0012 lr: 0.02\n",
            "iteration: 395620 loss: 0.0015 lr: 0.02\n",
            "iteration: 395630 loss: 0.0019 lr: 0.02\n",
            "iteration: 395640 loss: 0.0015 lr: 0.02\n",
            "iteration: 395650 loss: 0.0013 lr: 0.02\n",
            "iteration: 395660 loss: 0.0015 lr: 0.02\n",
            "iteration: 395670 loss: 0.0016 lr: 0.02\n",
            "iteration: 395680 loss: 0.0013 lr: 0.02\n",
            "iteration: 395690 loss: 0.0014 lr: 0.02\n",
            "iteration: 395700 loss: 0.0013 lr: 0.02\n",
            "iteration: 395710 loss: 0.0012 lr: 0.02\n",
            "iteration: 395720 loss: 0.0017 lr: 0.02\n",
            "iteration: 395730 loss: 0.0018 lr: 0.02\n",
            "iteration: 395740 loss: 0.0016 lr: 0.02\n",
            "iteration: 395750 loss: 0.0015 lr: 0.02\n",
            "iteration: 395760 loss: 0.0022 lr: 0.02\n",
            "iteration: 395770 loss: 0.0016 lr: 0.02\n",
            "iteration: 395780 loss: 0.0027 lr: 0.02\n",
            "iteration: 395790 loss: 0.0016 lr: 0.02\n",
            "iteration: 395800 loss: 0.0016 lr: 0.02\n",
            "iteration: 395810 loss: 0.0021 lr: 0.02\n",
            "iteration: 395820 loss: 0.0028 lr: 0.02\n",
            "iteration: 395830 loss: 0.0019 lr: 0.02\n",
            "iteration: 395840 loss: 0.0016 lr: 0.02\n",
            "iteration: 395850 loss: 0.0015 lr: 0.02\n",
            "iteration: 395860 loss: 0.0019 lr: 0.02\n",
            "iteration: 395870 loss: 0.0017 lr: 0.02\n",
            "iteration: 395880 loss: 0.0026 lr: 0.02\n",
            "iteration: 395890 loss: 0.0012 lr: 0.02\n",
            "iteration: 395900 loss: 0.0014 lr: 0.02\n",
            "iteration: 395910 loss: 0.0017 lr: 0.02\n",
            "iteration: 395920 loss: 0.0026 lr: 0.02\n",
            "iteration: 395930 loss: 0.0019 lr: 0.02\n",
            "iteration: 395940 loss: 0.0016 lr: 0.02\n",
            "iteration: 395950 loss: 0.0014 lr: 0.02\n",
            "iteration: 395960 loss: 0.0013 lr: 0.02\n",
            "iteration: 395970 loss: 0.0019 lr: 0.02\n",
            "iteration: 395980 loss: 0.0014 lr: 0.02\n",
            "iteration: 395990 loss: 0.0020 lr: 0.02\n",
            "iteration: 396000 loss: 0.0015 lr: 0.02\n",
            "iteration: 396010 loss: 0.0013 lr: 0.02\n",
            "iteration: 396020 loss: 0.0016 lr: 0.02\n",
            "iteration: 396030 loss: 0.0014 lr: 0.02\n",
            "iteration: 396040 loss: 0.0020 lr: 0.02\n",
            "iteration: 396050 loss: 0.0014 lr: 0.02\n",
            "iteration: 396060 loss: 0.0017 lr: 0.02\n",
            "iteration: 396070 loss: 0.0014 lr: 0.02\n",
            "iteration: 396080 loss: 0.0011 lr: 0.02\n",
            "iteration: 396090 loss: 0.0012 lr: 0.02\n",
            "iteration: 396100 loss: 0.0014 lr: 0.02\n",
            "iteration: 396110 loss: 0.0014 lr: 0.02\n",
            "iteration: 396120 loss: 0.0020 lr: 0.02\n",
            "iteration: 396130 loss: 0.0028 lr: 0.02\n",
            "iteration: 396140 loss: 0.0022 lr: 0.02\n",
            "iteration: 396150 loss: 0.0028 lr: 0.02\n",
            "iteration: 396160 loss: 0.0019 lr: 0.02\n",
            "iteration: 396170 loss: 0.0014 lr: 0.02\n",
            "iteration: 396180 loss: 0.0026 lr: 0.02\n",
            "iteration: 396190 loss: 0.0015 lr: 0.02\n",
            "iteration: 396200 loss: 0.0014 lr: 0.02\n",
            "iteration: 396210 loss: 0.0013 lr: 0.02\n",
            "iteration: 396220 loss: 0.0014 lr: 0.02\n",
            "iteration: 396230 loss: 0.0024 lr: 0.02\n",
            "iteration: 396240 loss: 0.0038 lr: 0.02\n",
            "iteration: 396250 loss: 0.0016 lr: 0.02\n",
            "iteration: 396260 loss: 0.0016 lr: 0.02\n",
            "iteration: 396270 loss: 0.0019 lr: 0.02\n",
            "iteration: 396280 loss: 0.0018 lr: 0.02\n",
            "iteration: 396290 loss: 0.0012 lr: 0.02\n",
            "iteration: 396300 loss: 0.0022 lr: 0.02\n",
            "iteration: 396310 loss: 0.0016 lr: 0.02\n",
            "iteration: 396320 loss: 0.0017 lr: 0.02\n",
            "iteration: 396330 loss: 0.0016 lr: 0.02\n",
            "iteration: 396340 loss: 0.0017 lr: 0.02\n",
            "iteration: 396350 loss: 0.0017 lr: 0.02\n",
            "iteration: 396360 loss: 0.0016 lr: 0.02\n",
            "iteration: 396370 loss: 0.0014 lr: 0.02\n",
            "iteration: 396380 loss: 0.0015 lr: 0.02\n",
            "iteration: 396390 loss: 0.0022 lr: 0.02\n",
            "iteration: 396400 loss: 0.0012 lr: 0.02\n",
            "iteration: 396410 loss: 0.0017 lr: 0.02\n",
            "iteration: 396420 loss: 0.0016 lr: 0.02\n",
            "iteration: 396430 loss: 0.0014 lr: 0.02\n",
            "iteration: 396440 loss: 0.0017 lr: 0.02\n",
            "iteration: 396450 loss: 0.0018 lr: 0.02\n",
            "iteration: 396460 loss: 0.0018 lr: 0.02\n",
            "iteration: 396470 loss: 0.0015 lr: 0.02\n",
            "iteration: 396480 loss: 0.0016 lr: 0.02\n",
            "iteration: 396490 loss: 0.0016 lr: 0.02\n",
            "iteration: 396500 loss: 0.0017 lr: 0.02\n",
            "iteration: 396510 loss: 0.0017 lr: 0.02\n",
            "iteration: 396520 loss: 0.0015 lr: 0.02\n",
            "iteration: 396530 loss: 0.0016 lr: 0.02\n",
            "iteration: 396540 loss: 0.0015 lr: 0.02\n",
            "iteration: 396550 loss: 0.0011 lr: 0.02\n",
            "iteration: 396560 loss: 0.0015 lr: 0.02\n",
            "iteration: 396570 loss: 0.0015 lr: 0.02\n",
            "iteration: 396580 loss: 0.0014 lr: 0.02\n",
            "iteration: 396590 loss: 0.0013 lr: 0.02\n",
            "iteration: 396600 loss: 0.0020 lr: 0.02\n",
            "iteration: 396610 loss: 0.0017 lr: 0.02\n",
            "iteration: 396620 loss: 0.0015 lr: 0.02\n",
            "iteration: 396630 loss: 0.0024 lr: 0.02\n",
            "iteration: 396640 loss: 0.0012 lr: 0.02\n",
            "iteration: 396650 loss: 0.0026 lr: 0.02\n",
            "iteration: 396660 loss: 0.0017 lr: 0.02\n",
            "iteration: 396670 loss: 0.0020 lr: 0.02\n",
            "iteration: 396680 loss: 0.0019 lr: 0.02\n",
            "iteration: 396690 loss: 0.0018 lr: 0.02\n",
            "iteration: 396700 loss: 0.0015 lr: 0.02\n",
            "iteration: 396710 loss: 0.0016 lr: 0.02\n",
            "iteration: 396720 loss: 0.0016 lr: 0.02\n",
            "iteration: 396730 loss: 0.0017 lr: 0.02\n",
            "iteration: 396740 loss: 0.0019 lr: 0.02\n",
            "iteration: 396750 loss: 0.0020 lr: 0.02\n",
            "iteration: 396760 loss: 0.0020 lr: 0.02\n",
            "iteration: 396770 loss: 0.0015 lr: 0.02\n",
            "iteration: 396780 loss: 0.0014 lr: 0.02\n",
            "iteration: 396790 loss: 0.0018 lr: 0.02\n",
            "iteration: 396800 loss: 0.0017 lr: 0.02\n",
            "iteration: 396810 loss: 0.0023 lr: 0.02\n",
            "iteration: 396820 loss: 0.0018 lr: 0.02\n",
            "iteration: 396830 loss: 0.0017 lr: 0.02\n",
            "iteration: 396840 loss: 0.0016 lr: 0.02\n",
            "iteration: 396850 loss: 0.0015 lr: 0.02\n",
            "iteration: 396860 loss: 0.0022 lr: 0.02\n",
            "iteration: 396870 loss: 0.0019 lr: 0.02\n",
            "iteration: 396880 loss: 0.0014 lr: 0.02\n",
            "iteration: 396890 loss: 0.0014 lr: 0.02\n",
            "iteration: 396900 loss: 0.0015 lr: 0.02\n",
            "iteration: 396910 loss: 0.0014 lr: 0.02\n",
            "iteration: 396920 loss: 0.0019 lr: 0.02\n",
            "iteration: 396930 loss: 0.0019 lr: 0.02\n",
            "iteration: 396940 loss: 0.0029 lr: 0.02\n",
            "iteration: 396950 loss: 0.0016 lr: 0.02\n",
            "iteration: 396960 loss: 0.0016 lr: 0.02\n",
            "iteration: 396970 loss: 0.0016 lr: 0.02\n",
            "iteration: 396980 loss: 0.0012 lr: 0.02\n",
            "iteration: 396990 loss: 0.0014 lr: 0.02\n",
            "iteration: 397000 loss: 0.0014 lr: 0.02\n",
            "iteration: 397010 loss: 0.0023 lr: 0.02\n",
            "iteration: 397020 loss: 0.0025 lr: 0.02\n",
            "iteration: 397030 loss: 0.0022 lr: 0.02\n",
            "iteration: 397040 loss: 0.0011 lr: 0.02\n",
            "iteration: 397050 loss: 0.0017 lr: 0.02\n",
            "iteration: 397060 loss: 0.0023 lr: 0.02\n",
            "iteration: 397070 loss: 0.0019 lr: 0.02\n",
            "iteration: 397080 loss: 0.0010 lr: 0.02\n",
            "iteration: 397090 loss: 0.0013 lr: 0.02\n",
            "iteration: 397100 loss: 0.0015 lr: 0.02\n",
            "iteration: 397110 loss: 0.0014 lr: 0.02\n",
            "iteration: 397120 loss: 0.0015 lr: 0.02\n",
            "iteration: 397130 loss: 0.0020 lr: 0.02\n",
            "iteration: 397140 loss: 0.0022 lr: 0.02\n",
            "iteration: 397150 loss: 0.0017 lr: 0.02\n",
            "iteration: 397160 loss: 0.0014 lr: 0.02\n",
            "iteration: 397170 loss: 0.0021 lr: 0.02\n",
            "iteration: 397180 loss: 0.0018 lr: 0.02\n",
            "iteration: 397190 loss: 0.0015 lr: 0.02\n",
            "iteration: 397200 loss: 0.0014 lr: 0.02\n",
            "iteration: 397210 loss: 0.0014 lr: 0.02\n",
            "iteration: 397220 loss: 0.0013 lr: 0.02\n",
            "iteration: 397230 loss: 0.0017 lr: 0.02\n",
            "iteration: 397240 loss: 0.0017 lr: 0.02\n",
            "iteration: 397250 loss: 0.0015 lr: 0.02\n",
            "iteration: 397260 loss: 0.0016 lr: 0.02\n",
            "iteration: 397270 loss: 0.0020 lr: 0.02\n",
            "iteration: 397280 loss: 0.0023 lr: 0.02\n",
            "iteration: 397290 loss: 0.0018 lr: 0.02\n",
            "iteration: 397300 loss: 0.0019 lr: 0.02\n",
            "iteration: 397310 loss: 0.0018 lr: 0.02\n",
            "iteration: 397320 loss: 0.0019 lr: 0.02\n",
            "iteration: 397330 loss: 0.0016 lr: 0.02\n",
            "iteration: 397340 loss: 0.0019 lr: 0.02\n",
            "iteration: 397350 loss: 0.0014 lr: 0.02\n",
            "iteration: 397360 loss: 0.0018 lr: 0.02\n",
            "iteration: 397370 loss: 0.0023 lr: 0.02\n",
            "iteration: 397380 loss: 0.0019 lr: 0.02\n",
            "iteration: 397390 loss: 0.0019 lr: 0.02\n",
            "iteration: 397400 loss: 0.0016 lr: 0.02\n",
            "iteration: 397410 loss: 0.0016 lr: 0.02\n",
            "iteration: 397420 loss: 0.0013 lr: 0.02\n",
            "iteration: 397430 loss: 0.0018 lr: 0.02\n",
            "iteration: 397440 loss: 0.0016 lr: 0.02\n",
            "iteration: 397450 loss: 0.0018 lr: 0.02\n",
            "iteration: 397460 loss: 0.0013 lr: 0.02\n",
            "iteration: 397470 loss: 0.0013 lr: 0.02\n",
            "iteration: 397480 loss: 0.0016 lr: 0.02\n",
            "iteration: 397490 loss: 0.0021 lr: 0.02\n",
            "iteration: 397500 loss: 0.0013 lr: 0.02\n",
            "iteration: 397510 loss: 0.0018 lr: 0.02\n",
            "iteration: 397520 loss: 0.0014 lr: 0.02\n",
            "iteration: 397530 loss: 0.0011 lr: 0.02\n",
            "iteration: 397540 loss: 0.0021 lr: 0.02\n",
            "iteration: 397550 loss: 0.0017 lr: 0.02\n",
            "iteration: 397560 loss: 0.0015 lr: 0.02\n",
            "iteration: 397570 loss: 0.0015 lr: 0.02\n",
            "iteration: 397580 loss: 0.0017 lr: 0.02\n",
            "iteration: 397590 loss: 0.0013 lr: 0.02\n",
            "iteration: 397600 loss: 0.0015 lr: 0.02\n",
            "iteration: 397610 loss: 0.0011 lr: 0.02\n",
            "iteration: 397620 loss: 0.0020 lr: 0.02\n",
            "iteration: 397630 loss: 0.0018 lr: 0.02\n",
            "iteration: 397640 loss: 0.0014 lr: 0.02\n",
            "iteration: 397650 loss: 0.0019 lr: 0.02\n",
            "iteration: 397660 loss: 0.0014 lr: 0.02\n",
            "iteration: 397670 loss: 0.0011 lr: 0.02\n",
            "iteration: 397680 loss: 0.0023 lr: 0.02\n",
            "iteration: 397690 loss: 0.0021 lr: 0.02\n",
            "iteration: 397700 loss: 0.0020 lr: 0.02\n",
            "iteration: 397710 loss: 0.0014 lr: 0.02\n",
            "iteration: 397720 loss: 0.0013 lr: 0.02\n",
            "iteration: 397730 loss: 0.0017 lr: 0.02\n",
            "iteration: 397740 loss: 0.0017 lr: 0.02\n",
            "iteration: 397750 loss: 0.0013 lr: 0.02\n",
            "iteration: 397760 loss: 0.0018 lr: 0.02\n",
            "iteration: 397770 loss: 0.0014 lr: 0.02\n",
            "iteration: 397780 loss: 0.0013 lr: 0.02\n",
            "iteration: 397790 loss: 0.0017 lr: 0.02\n",
            "iteration: 397800 loss: 0.0021 lr: 0.02\n",
            "iteration: 397810 loss: 0.0019 lr: 0.02\n",
            "iteration: 397820 loss: 0.0015 lr: 0.02\n",
            "iteration: 397830 loss: 0.0013 lr: 0.02\n",
            "iteration: 397840 loss: 0.0020 lr: 0.02\n",
            "iteration: 397850 loss: 0.0016 lr: 0.02\n",
            "iteration: 397860 loss: 0.0016 lr: 0.02\n",
            "iteration: 397870 loss: 0.0013 lr: 0.02\n",
            "iteration: 397880 loss: 0.0015 lr: 0.02\n",
            "iteration: 397890 loss: 0.0016 lr: 0.02\n",
            "iteration: 397900 loss: 0.0017 lr: 0.02\n",
            "iteration: 397910 loss: 0.0015 lr: 0.02\n",
            "iteration: 397920 loss: 0.0011 lr: 0.02\n",
            "iteration: 397930 loss: 0.0013 lr: 0.02\n",
            "iteration: 397940 loss: 0.0021 lr: 0.02\n",
            "iteration: 397950 loss: 0.0018 lr: 0.02\n",
            "iteration: 397960 loss: 0.0019 lr: 0.02\n",
            "iteration: 397970 loss: 0.0027 lr: 0.02\n",
            "iteration: 397980 loss: 0.0018 lr: 0.02\n",
            "iteration: 397990 loss: 0.0018 lr: 0.02\n",
            "iteration: 398000 loss: 0.0018 lr: 0.02\n",
            "iteration: 398010 loss: 0.0013 lr: 0.02\n",
            "iteration: 398020 loss: 0.0014 lr: 0.02\n",
            "iteration: 398030 loss: 0.0020 lr: 0.02\n",
            "iteration: 398040 loss: 0.0019 lr: 0.02\n",
            "iteration: 398050 loss: 0.0017 lr: 0.02\n",
            "iteration: 398060 loss: 0.0019 lr: 0.02\n",
            "iteration: 398070 loss: 0.0019 lr: 0.02\n",
            "iteration: 398080 loss: 0.0015 lr: 0.02\n",
            "iteration: 398090 loss: 0.0017 lr: 0.02\n",
            "iteration: 398100 loss: 0.0015 lr: 0.02\n",
            "iteration: 398110 loss: 0.0016 lr: 0.02\n",
            "iteration: 398120 loss: 0.0021 lr: 0.02\n",
            "iteration: 398130 loss: 0.0021 lr: 0.02\n",
            "iteration: 398140 loss: 0.0015 lr: 0.02\n",
            "iteration: 398150 loss: 0.0013 lr: 0.02\n",
            "iteration: 398160 loss: 0.0015 lr: 0.02\n",
            "iteration: 398170 loss: 0.0020 lr: 0.02\n",
            "iteration: 398180 loss: 0.0015 lr: 0.02\n",
            "iteration: 398190 loss: 0.0016 lr: 0.02\n",
            "iteration: 398200 loss: 0.0018 lr: 0.02\n",
            "iteration: 398210 loss: 0.0016 lr: 0.02\n",
            "iteration: 398220 loss: 0.0012 lr: 0.02\n",
            "iteration: 398230 loss: 0.0013 lr: 0.02\n",
            "iteration: 398240 loss: 0.0017 lr: 0.02\n",
            "iteration: 398250 loss: 0.0021 lr: 0.02\n",
            "iteration: 398260 loss: 0.0016 lr: 0.02\n",
            "iteration: 398270 loss: 0.0014 lr: 0.02\n",
            "iteration: 398280 loss: 0.0016 lr: 0.02\n",
            "iteration: 398290 loss: 0.0016 lr: 0.02\n",
            "iteration: 398300 loss: 0.0011 lr: 0.02\n",
            "iteration: 398310 loss: 0.0029 lr: 0.02\n",
            "iteration: 398320 loss: 0.0018 lr: 0.02\n",
            "iteration: 398330 loss: 0.0016 lr: 0.02\n",
            "iteration: 398340 loss: 0.0021 lr: 0.02\n",
            "iteration: 398350 loss: 0.0016 lr: 0.02\n",
            "iteration: 398360 loss: 0.0019 lr: 0.02\n",
            "iteration: 398370 loss: 0.0021 lr: 0.02\n",
            "iteration: 398380 loss: 0.0014 lr: 0.02\n",
            "iteration: 398390 loss: 0.0021 lr: 0.02\n",
            "iteration: 398400 loss: 0.0018 lr: 0.02\n",
            "iteration: 398410 loss: 0.0019 lr: 0.02\n",
            "iteration: 398420 loss: 0.0016 lr: 0.02\n",
            "iteration: 398430 loss: 0.0020 lr: 0.02\n",
            "iteration: 398440 loss: 0.0014 lr: 0.02\n",
            "iteration: 398450 loss: 0.0014 lr: 0.02\n",
            "iteration: 398460 loss: 0.0015 lr: 0.02\n",
            "iteration: 398470 loss: 0.0022 lr: 0.02\n",
            "iteration: 398480 loss: 0.0017 lr: 0.02\n",
            "iteration: 398490 loss: 0.0017 lr: 0.02\n",
            "iteration: 398500 loss: 0.0012 lr: 0.02\n",
            "iteration: 398510 loss: 0.0018 lr: 0.02\n",
            "iteration: 398520 loss: 0.0019 lr: 0.02\n",
            "iteration: 398530 loss: 0.0015 lr: 0.02\n",
            "iteration: 398540 loss: 0.0019 lr: 0.02\n",
            "iteration: 398550 loss: 0.0018 lr: 0.02\n",
            "iteration: 398560 loss: 0.0013 lr: 0.02\n",
            "iteration: 398570 loss: 0.0013 lr: 0.02\n",
            "iteration: 398580 loss: 0.0015 lr: 0.02\n",
            "iteration: 398590 loss: 0.0019 lr: 0.02\n",
            "iteration: 398600 loss: 0.0018 lr: 0.02\n",
            "iteration: 398610 loss: 0.0015 lr: 0.02\n",
            "iteration: 398620 loss: 0.0015 lr: 0.02\n",
            "iteration: 398630 loss: 0.0011 lr: 0.02\n",
            "iteration: 398640 loss: 0.0015 lr: 0.02\n",
            "iteration: 398650 loss: 0.0015 lr: 0.02\n",
            "iteration: 398660 loss: 0.0014 lr: 0.02\n",
            "iteration: 398670 loss: 0.0022 lr: 0.02\n",
            "iteration: 398680 loss: 0.0025 lr: 0.02\n",
            "iteration: 398690 loss: 0.0022 lr: 0.02\n",
            "iteration: 398700 loss: 0.0016 lr: 0.02\n",
            "iteration: 398710 loss: 0.0012 lr: 0.02\n",
            "iteration: 398720 loss: 0.0015 lr: 0.02\n",
            "iteration: 398730 loss: 0.0017 lr: 0.02\n",
            "iteration: 398740 loss: 0.0022 lr: 0.02\n",
            "iteration: 398750 loss: 0.0013 lr: 0.02\n",
            "iteration: 398760 loss: 0.0018 lr: 0.02\n",
            "iteration: 398770 loss: 0.0013 lr: 0.02\n",
            "iteration: 398780 loss: 0.0018 lr: 0.02\n",
            "iteration: 398790 loss: 0.0014 lr: 0.02\n",
            "iteration: 398800 loss: 0.0013 lr: 0.02\n",
            "iteration: 398810 loss: 0.0015 lr: 0.02\n",
            "iteration: 398820 loss: 0.0018 lr: 0.02\n",
            "iteration: 398830 loss: 0.0017 lr: 0.02\n",
            "iteration: 398840 loss: 0.0016 lr: 0.02\n",
            "iteration: 398850 loss: 0.0018 lr: 0.02\n",
            "iteration: 398860 loss: 0.0019 lr: 0.02\n",
            "iteration: 398870 loss: 0.0015 lr: 0.02\n",
            "iteration: 398880 loss: 0.0012 lr: 0.02\n",
            "iteration: 398890 loss: 0.0016 lr: 0.02\n",
            "iteration: 398900 loss: 0.0021 lr: 0.02\n",
            "iteration: 398910 loss: 0.0015 lr: 0.02\n",
            "iteration: 398920 loss: 0.0015 lr: 0.02\n",
            "iteration: 398930 loss: 0.0016 lr: 0.02\n",
            "iteration: 398940 loss: 0.0026 lr: 0.02\n",
            "iteration: 398950 loss: 0.0014 lr: 0.02\n",
            "iteration: 398960 loss: 0.0019 lr: 0.02\n",
            "iteration: 398970 loss: 0.0016 lr: 0.02\n",
            "iteration: 398980 loss: 0.0020 lr: 0.02\n",
            "iteration: 398990 loss: 0.0011 lr: 0.02\n",
            "iteration: 399000 loss: 0.0012 lr: 0.02\n",
            "iteration: 399010 loss: 0.0016 lr: 0.02\n",
            "iteration: 399020 loss: 0.0015 lr: 0.02\n",
            "iteration: 399030 loss: 0.0017 lr: 0.02\n",
            "iteration: 399040 loss: 0.0019 lr: 0.02\n",
            "iteration: 399050 loss: 0.0018 lr: 0.02\n",
            "iteration: 399060 loss: 0.0013 lr: 0.02\n",
            "iteration: 399070 loss: 0.0019 lr: 0.02\n",
            "iteration: 399080 loss: 0.0017 lr: 0.02\n",
            "iteration: 399090 loss: 0.0014 lr: 0.02\n",
            "iteration: 399100 loss: 0.0021 lr: 0.02\n",
            "iteration: 399110 loss: 0.0019 lr: 0.02\n",
            "iteration: 399120 loss: 0.0017 lr: 0.02\n",
            "iteration: 399130 loss: 0.0024 lr: 0.02\n",
            "iteration: 399140 loss: 0.0018 lr: 0.02\n",
            "iteration: 399150 loss: 0.0019 lr: 0.02\n",
            "iteration: 399160 loss: 0.0014 lr: 0.02\n",
            "iteration: 399170 loss: 0.0021 lr: 0.02\n",
            "iteration: 399180 loss: 0.0014 lr: 0.02\n",
            "iteration: 399190 loss: 0.0013 lr: 0.02\n",
            "iteration: 399200 loss: 0.0018 lr: 0.02\n",
            "iteration: 399210 loss: 0.0016 lr: 0.02\n",
            "iteration: 399220 loss: 0.0017 lr: 0.02\n",
            "iteration: 399230 loss: 0.0017 lr: 0.02\n",
            "iteration: 399240 loss: 0.0016 lr: 0.02\n",
            "iteration: 399250 loss: 0.0015 lr: 0.02\n",
            "iteration: 399260 loss: 0.0018 lr: 0.02\n",
            "iteration: 399270 loss: 0.0013 lr: 0.02\n",
            "iteration: 399280 loss: 0.0017 lr: 0.02\n",
            "iteration: 399290 loss: 0.0020 lr: 0.02\n",
            "iteration: 399300 loss: 0.0013 lr: 0.02\n",
            "iteration: 399310 loss: 0.0014 lr: 0.02\n",
            "iteration: 399320 loss: 0.0020 lr: 0.02\n",
            "iteration: 399330 loss: 0.0016 lr: 0.02\n",
            "iteration: 399340 loss: 0.0017 lr: 0.02\n",
            "iteration: 399350 loss: 0.0017 lr: 0.02\n",
            "iteration: 399360 loss: 0.0019 lr: 0.02\n",
            "iteration: 399370 loss: 0.0019 lr: 0.02\n",
            "iteration: 399380 loss: 0.0014 lr: 0.02\n",
            "iteration: 399390 loss: 0.0021 lr: 0.02\n",
            "iteration: 399400 loss: 0.0018 lr: 0.02\n",
            "iteration: 399410 loss: 0.0021 lr: 0.02\n",
            "iteration: 399420 loss: 0.0019 lr: 0.02\n",
            "iteration: 399430 loss: 0.0015 lr: 0.02\n",
            "iteration: 399440 loss: 0.0015 lr: 0.02\n",
            "iteration: 399450 loss: 0.0014 lr: 0.02\n",
            "iteration: 399460 loss: 0.0012 lr: 0.02\n",
            "iteration: 399470 loss: 0.0013 lr: 0.02\n",
            "iteration: 399480 loss: 0.0016 lr: 0.02\n",
            "iteration: 399490 loss: 0.0015 lr: 0.02\n",
            "iteration: 399500 loss: 0.0017 lr: 0.02\n",
            "iteration: 399510 loss: 0.0012 lr: 0.02\n",
            "iteration: 399520 loss: 0.0017 lr: 0.02\n",
            "iteration: 399530 loss: 0.0015 lr: 0.02\n",
            "iteration: 399540 loss: 0.0013 lr: 0.02\n",
            "iteration: 399550 loss: 0.0013 lr: 0.02\n",
            "iteration: 399560 loss: 0.0016 lr: 0.02\n",
            "iteration: 399570 loss: 0.0018 lr: 0.02\n",
            "iteration: 399580 loss: 0.0013 lr: 0.02\n",
            "iteration: 399590 loss: 0.0018 lr: 0.02\n",
            "iteration: 399600 loss: 0.0017 lr: 0.02\n",
            "iteration: 399610 loss: 0.0015 lr: 0.02\n",
            "iteration: 399620 loss: 0.0014 lr: 0.02\n",
            "iteration: 399630 loss: 0.0018 lr: 0.02\n",
            "iteration: 399640 loss: 0.0020 lr: 0.02\n",
            "iteration: 399650 loss: 0.0014 lr: 0.02\n",
            "iteration: 399660 loss: 0.0012 lr: 0.02\n",
            "iteration: 399670 loss: 0.0027 lr: 0.02\n",
            "iteration: 399680 loss: 0.0019 lr: 0.02\n",
            "iteration: 399690 loss: 0.0019 lr: 0.02\n",
            "iteration: 399700 loss: 0.0014 lr: 0.02\n",
            "iteration: 399710 loss: 0.0015 lr: 0.02\n",
            "iteration: 399720 loss: 0.0020 lr: 0.02\n",
            "iteration: 399730 loss: 0.0017 lr: 0.02\n",
            "iteration: 399740 loss: 0.0019 lr: 0.02\n",
            "iteration: 399750 loss: 0.0016 lr: 0.02\n",
            "iteration: 399760 loss: 0.0015 lr: 0.02\n",
            "iteration: 399770 loss: 0.0020 lr: 0.02\n",
            "iteration: 399780 loss: 0.0011 lr: 0.02\n",
            "iteration: 399790 loss: 0.0015 lr: 0.02\n",
            "iteration: 399800 loss: 0.0014 lr: 0.02\n",
            "iteration: 399810 loss: 0.0015 lr: 0.02\n",
            "iteration: 399820 loss: 0.0016 lr: 0.02\n",
            "iteration: 399830 loss: 0.0021 lr: 0.02\n",
            "iteration: 399840 loss: 0.0014 lr: 0.02\n",
            "iteration: 399850 loss: 0.0024 lr: 0.02\n",
            "iteration: 399860 loss: 0.0016 lr: 0.02\n",
            "iteration: 399870 loss: 0.0016 lr: 0.02\n",
            "iteration: 399880 loss: 0.0015 lr: 0.02\n",
            "iteration: 399890 loss: 0.0015 lr: 0.02\n",
            "iteration: 399900 loss: 0.0013 lr: 0.02\n",
            "iteration: 399910 loss: 0.0014 lr: 0.02\n",
            "iteration: 399920 loss: 0.0016 lr: 0.02\n",
            "iteration: 399930 loss: 0.0012 lr: 0.02\n",
            "iteration: 399940 loss: 0.0018 lr: 0.02\n",
            "iteration: 399950 loss: 0.0014 lr: 0.02\n",
            "iteration: 399960 loss: 0.0013 lr: 0.02\n",
            "iteration: 399970 loss: 0.0017 lr: 0.02\n",
            "iteration: 399980 loss: 0.0018 lr: 0.02\n",
            "iteration: 399990 loss: 0.0022 lr: 0.02\n",
            "iteration: 400000 loss: 0.0014 lr: 0.02\n",
            "iteration: 400010 loss: 0.0013 lr: 0.02\n",
            "iteration: 400020 loss: 0.0016 lr: 0.02\n",
            "iteration: 400030 loss: 0.0019 lr: 0.02\n",
            "iteration: 400040 loss: 0.0013 lr: 0.02\n",
            "iteration: 400050 loss: 0.0017 lr: 0.02\n",
            "iteration: 400060 loss: 0.0013 lr: 0.02\n",
            "iteration: 400070 loss: 0.0014 lr: 0.02\n",
            "iteration: 400080 loss: 0.0017 lr: 0.02\n",
            "iteration: 400090 loss: 0.0021 lr: 0.02\n",
            "iteration: 400100 loss: 0.0020 lr: 0.02\n",
            "iteration: 400110 loss: 0.0016 lr: 0.02\n",
            "iteration: 400120 loss: 0.0016 lr: 0.02\n",
            "iteration: 400130 loss: 0.0013 lr: 0.02\n",
            "iteration: 400140 loss: 0.0019 lr: 0.02\n",
            "iteration: 400150 loss: 0.0017 lr: 0.02\n",
            "iteration: 400160 loss: 0.0016 lr: 0.02\n",
            "iteration: 400170 loss: 0.0019 lr: 0.02\n",
            "iteration: 400180 loss: 0.0017 lr: 0.02\n",
            "iteration: 400190 loss: 0.0015 lr: 0.02\n",
            "iteration: 400200 loss: 0.0013 lr: 0.02\n",
            "iteration: 400210 loss: 0.0017 lr: 0.02\n",
            "iteration: 400220 loss: 0.0021 lr: 0.02\n",
            "iteration: 400230 loss: 0.0013 lr: 0.02\n",
            "iteration: 400240 loss: 0.0014 lr: 0.02\n",
            "iteration: 400250 loss: 0.0015 lr: 0.02\n",
            "iteration: 400260 loss: 0.0016 lr: 0.02\n",
            "iteration: 400270 loss: 0.0012 lr: 0.02\n",
            "iteration: 400280 loss: 0.0016 lr: 0.02\n",
            "iteration: 400290 loss: 0.0016 lr: 0.02\n",
            "iteration: 400300 loss: 0.0014 lr: 0.02\n",
            "iteration: 400310 loss: 0.0015 lr: 0.02\n",
            "iteration: 400320 loss: 0.0015 lr: 0.02\n",
            "iteration: 400330 loss: 0.0019 lr: 0.02\n",
            "iteration: 400340 loss: 0.0015 lr: 0.02\n",
            "iteration: 400350 loss: 0.0013 lr: 0.02\n",
            "iteration: 400360 loss: 0.0015 lr: 0.02\n",
            "iteration: 400370 loss: 0.0018 lr: 0.02\n",
            "iteration: 400380 loss: 0.0017 lr: 0.02\n",
            "iteration: 400390 loss: 0.0020 lr: 0.02\n",
            "iteration: 400400 loss: 0.0017 lr: 0.02\n",
            "iteration: 400410 loss: 0.0018 lr: 0.02\n",
            "iteration: 400420 loss: 0.0018 lr: 0.02\n",
            "iteration: 400430 loss: 0.0016 lr: 0.02\n",
            "iteration: 400440 loss: 0.0012 lr: 0.02\n",
            "iteration: 400450 loss: 0.0020 lr: 0.02\n",
            "iteration: 400460 loss: 0.0014 lr: 0.02\n",
            "iteration: 400470 loss: 0.0018 lr: 0.02\n",
            "iteration: 400480 loss: 0.0012 lr: 0.02\n",
            "iteration: 400490 loss: 0.0018 lr: 0.02\n",
            "iteration: 400500 loss: 0.0013 lr: 0.02\n",
            "iteration: 400510 loss: 0.0017 lr: 0.02\n",
            "iteration: 400520 loss: 0.0020 lr: 0.02\n",
            "iteration: 400530 loss: 0.0018 lr: 0.02\n",
            "iteration: 400540 loss: 0.0019 lr: 0.02\n",
            "iteration: 400550 loss: 0.0018 lr: 0.02\n",
            "iteration: 400560 loss: 0.0021 lr: 0.02\n",
            "iteration: 400570 loss: 0.0012 lr: 0.02\n",
            "iteration: 400580 loss: 0.0015 lr: 0.02\n",
            "iteration: 400590 loss: 0.0021 lr: 0.02\n",
            "iteration: 400600 loss: 0.0020 lr: 0.02\n",
            "iteration: 400610 loss: 0.0018 lr: 0.02\n",
            "iteration: 400620 loss: 0.0018 lr: 0.02\n",
            "iteration: 400630 loss: 0.0016 lr: 0.02\n",
            "iteration: 400640 loss: 0.0020 lr: 0.02\n",
            "iteration: 400650 loss: 0.0009 lr: 0.02\n",
            "iteration: 400660 loss: 0.0019 lr: 0.02\n",
            "iteration: 400670 loss: 0.0016 lr: 0.02\n",
            "iteration: 400680 loss: 0.0019 lr: 0.02\n",
            "iteration: 400690 loss: 0.0012 lr: 0.02\n",
            "iteration: 400700 loss: 0.0016 lr: 0.02\n",
            "iteration: 400710 loss: 0.0015 lr: 0.02\n",
            "iteration: 400720 loss: 0.0018 lr: 0.02\n",
            "iteration: 400730 loss: 0.0019 lr: 0.02\n",
            "iteration: 400740 loss: 0.0015 lr: 0.02\n",
            "iteration: 400750 loss: 0.0014 lr: 0.02\n",
            "iteration: 400760 loss: 0.0015 lr: 0.02\n",
            "iteration: 400770 loss: 0.0014 lr: 0.02\n",
            "iteration: 400780 loss: 0.0018 lr: 0.02\n",
            "iteration: 400790 loss: 0.0016 lr: 0.02\n",
            "iteration: 400800 loss: 0.0012 lr: 0.02\n",
            "iteration: 400810 loss: 0.0016 lr: 0.02\n",
            "iteration: 400820 loss: 0.0015 lr: 0.02\n",
            "iteration: 400830 loss: 0.0022 lr: 0.02\n",
            "iteration: 400840 loss: 0.0025 lr: 0.02\n",
            "iteration: 400850 loss: 0.0014 lr: 0.02\n",
            "iteration: 400860 loss: 0.0015 lr: 0.02\n",
            "iteration: 400870 loss: 0.0012 lr: 0.02\n",
            "iteration: 400880 loss: 0.0017 lr: 0.02\n",
            "iteration: 400890 loss: 0.0021 lr: 0.02\n",
            "iteration: 400900 loss: 0.0015 lr: 0.02\n",
            "iteration: 400910 loss: 0.0013 lr: 0.02\n",
            "iteration: 400920 loss: 0.0016 lr: 0.02\n",
            "iteration: 400930 loss: 0.0016 lr: 0.02\n",
            "iteration: 400940 loss: 0.0013 lr: 0.02\n",
            "iteration: 400950 loss: 0.0020 lr: 0.02\n",
            "iteration: 400960 loss: 0.0016 lr: 0.02\n",
            "iteration: 400970 loss: 0.0020 lr: 0.02\n",
            "iteration: 400980 loss: 0.0022 lr: 0.02\n",
            "iteration: 400990 loss: 0.0014 lr: 0.02\n",
            "iteration: 401000 loss: 0.0013 lr: 0.02\n",
            "iteration: 401010 loss: 0.0014 lr: 0.02\n",
            "iteration: 401020 loss: 0.0021 lr: 0.02\n",
            "iteration: 401030 loss: 0.0016 lr: 0.02\n",
            "iteration: 401040 loss: 0.0013 lr: 0.02\n",
            "iteration: 401050 loss: 0.0014 lr: 0.02\n",
            "iteration: 401060 loss: 0.0009 lr: 0.02\n",
            "iteration: 401070 loss: 0.0014 lr: 0.02\n",
            "iteration: 401080 loss: 0.0015 lr: 0.02\n",
            "iteration: 401090 loss: 0.0017 lr: 0.02\n",
            "iteration: 401100 loss: 0.0016 lr: 0.02\n",
            "iteration: 401110 loss: 0.0015 lr: 0.02\n",
            "iteration: 401120 loss: 0.0015 lr: 0.02\n",
            "iteration: 401130 loss: 0.0026 lr: 0.02\n",
            "iteration: 401140 loss: 0.0022 lr: 0.02\n",
            "iteration: 401150 loss: 0.0020 lr: 0.02\n",
            "iteration: 401160 loss: 0.0011 lr: 0.02\n",
            "iteration: 401170 loss: 0.0019 lr: 0.02\n",
            "iteration: 401180 loss: 0.0014 lr: 0.02\n",
            "iteration: 401190 loss: 0.0020 lr: 0.02\n",
            "iteration: 401200 loss: 0.0020 lr: 0.02\n",
            "iteration: 401210 loss: 0.0013 lr: 0.02\n",
            "iteration: 401220 loss: 0.0015 lr: 0.02\n",
            "iteration: 401230 loss: 0.0017 lr: 0.02\n",
            "iteration: 401240 loss: 0.0011 lr: 0.02\n",
            "iteration: 401250 loss: 0.0019 lr: 0.02\n",
            "iteration: 401260 loss: 0.0018 lr: 0.02\n",
            "iteration: 401270 loss: 0.0011 lr: 0.02\n",
            "iteration: 401280 loss: 0.0014 lr: 0.02\n",
            "iteration: 401290 loss: 0.0012 lr: 0.02\n",
            "iteration: 401300 loss: 0.0020 lr: 0.02\n",
            "iteration: 401310 loss: 0.0014 lr: 0.02\n",
            "iteration: 401320 loss: 0.0017 lr: 0.02\n",
            "iteration: 401330 loss: 0.0017 lr: 0.02\n",
            "iteration: 401340 loss: 0.0010 lr: 0.02\n",
            "iteration: 401350 loss: 0.0013 lr: 0.02\n",
            "iteration: 401360 loss: 0.0013 lr: 0.02\n",
            "iteration: 401370 loss: 0.0014 lr: 0.02\n",
            "iteration: 401380 loss: 0.0017 lr: 0.02\n",
            "iteration: 401390 loss: 0.0015 lr: 0.02\n",
            "iteration: 401400 loss: 0.0014 lr: 0.02\n",
            "iteration: 401410 loss: 0.0011 lr: 0.02\n",
            "iteration: 401420 loss: 0.0015 lr: 0.02\n",
            "iteration: 401430 loss: 0.0016 lr: 0.02\n",
            "iteration: 401440 loss: 0.0015 lr: 0.02\n",
            "iteration: 401450 loss: 0.0014 lr: 0.02\n",
            "iteration: 401460 loss: 0.0023 lr: 0.02\n",
            "iteration: 401470 loss: 0.0014 lr: 0.02\n",
            "iteration: 401480 loss: 0.0019 lr: 0.02\n",
            "iteration: 401490 loss: 0.0015 lr: 0.02\n",
            "iteration: 401500 loss: 0.0017 lr: 0.02\n",
            "iteration: 401510 loss: 0.0014 lr: 0.02\n",
            "iteration: 401520 loss: 0.0013 lr: 0.02\n",
            "iteration: 401530 loss: 0.0014 lr: 0.02\n",
            "iteration: 401540 loss: 0.0015 lr: 0.02\n",
            "iteration: 401550 loss: 0.0014 lr: 0.02\n",
            "iteration: 401560 loss: 0.0021 lr: 0.02\n",
            "iteration: 401570 loss: 0.0012 lr: 0.02\n",
            "iteration: 401580 loss: 0.0016 lr: 0.02\n",
            "iteration: 401590 loss: 0.0016 lr: 0.02\n",
            "iteration: 401600 loss: 0.0013 lr: 0.02\n",
            "iteration: 401610 loss: 0.0020 lr: 0.02\n",
            "iteration: 401620 loss: 0.0019 lr: 0.02\n",
            "iteration: 401630 loss: 0.0015 lr: 0.02\n",
            "iteration: 401640 loss: 0.0014 lr: 0.02\n",
            "iteration: 401650 loss: 0.0011 lr: 0.02\n",
            "iteration: 401660 loss: 0.0018 lr: 0.02\n",
            "iteration: 401670 loss: 0.0015 lr: 0.02\n",
            "iteration: 401680 loss: 0.0013 lr: 0.02\n",
            "iteration: 401690 loss: 0.0014 lr: 0.02\n",
            "iteration: 401700 loss: 0.0021 lr: 0.02\n",
            "iteration: 401710 loss: 0.0012 lr: 0.02\n",
            "iteration: 401720 loss: 0.0018 lr: 0.02\n",
            "iteration: 401730 loss: 0.0012 lr: 0.02\n",
            "iteration: 401740 loss: 0.0017 lr: 0.02\n",
            "iteration: 401750 loss: 0.0016 lr: 0.02\n",
            "iteration: 401760 loss: 0.0011 lr: 0.02\n",
            "iteration: 401770 loss: 0.0017 lr: 0.02\n",
            "iteration: 401780 loss: 0.0017 lr: 0.02\n",
            "iteration: 401790 loss: 0.0023 lr: 0.02\n",
            "iteration: 401800 loss: 0.0013 lr: 0.02\n",
            "iteration: 401810 loss: 0.0016 lr: 0.02\n",
            "iteration: 401820 loss: 0.0018 lr: 0.02\n",
            "iteration: 401830 loss: 0.0014 lr: 0.02\n",
            "iteration: 401840 loss: 0.0017 lr: 0.02\n",
            "iteration: 401850 loss: 0.0015 lr: 0.02\n",
            "iteration: 401860 loss: 0.0015 lr: 0.02\n",
            "iteration: 401870 loss: 0.0015 lr: 0.02\n",
            "iteration: 401880 loss: 0.0023 lr: 0.02\n",
            "iteration: 401890 loss: 0.0014 lr: 0.02\n",
            "iteration: 401900 loss: 0.0023 lr: 0.02\n",
            "iteration: 401910 loss: 0.0021 lr: 0.02\n",
            "iteration: 401920 loss: 0.0021 lr: 0.02\n",
            "iteration: 401930 loss: 0.0022 lr: 0.02\n",
            "iteration: 401940 loss: 0.0015 lr: 0.02\n",
            "iteration: 401950 loss: 0.0019 lr: 0.02\n",
            "iteration: 401960 loss: 0.0015 lr: 0.02\n",
            "iteration: 401970 loss: 0.0014 lr: 0.02\n",
            "iteration: 401980 loss: 0.0016 lr: 0.02\n",
            "iteration: 401990 loss: 0.0018 lr: 0.02\n",
            "iteration: 402000 loss: 0.0015 lr: 0.02\n",
            "iteration: 402010 loss: 0.0016 lr: 0.02\n",
            "iteration: 402020 loss: 0.0020 lr: 0.02\n",
            "iteration: 402030 loss: 0.0021 lr: 0.02\n",
            "iteration: 402040 loss: 0.0022 lr: 0.02\n",
            "iteration: 402050 loss: 0.0020 lr: 0.02\n",
            "iteration: 402060 loss: 0.0018 lr: 0.02\n",
            "iteration: 402070 loss: 0.0018 lr: 0.02\n",
            "iteration: 402080 loss: 0.0017 lr: 0.02\n",
            "iteration: 402090 loss: 0.0015 lr: 0.02\n",
            "iteration: 402100 loss: 0.0020 lr: 0.02\n",
            "iteration: 402110 loss: 0.0013 lr: 0.02\n",
            "iteration: 402120 loss: 0.0014 lr: 0.02\n",
            "iteration: 402130 loss: 0.0016 lr: 0.02\n",
            "iteration: 402140 loss: 0.0015 lr: 0.02\n",
            "iteration: 402150 loss: 0.0017 lr: 0.02\n",
            "iteration: 402160 loss: 0.0022 lr: 0.02\n",
            "iteration: 402170 loss: 0.0025 lr: 0.02\n",
            "iteration: 402180 loss: 0.0012 lr: 0.02\n",
            "iteration: 402190 loss: 0.0015 lr: 0.02\n",
            "iteration: 402200 loss: 0.0021 lr: 0.02\n",
            "iteration: 402210 loss: 0.0018 lr: 0.02\n",
            "iteration: 402220 loss: 0.0013 lr: 0.02\n",
            "iteration: 402230 loss: 0.0016 lr: 0.02\n",
            "iteration: 402240 loss: 0.0016 lr: 0.02\n",
            "iteration: 402250 loss: 0.0013 lr: 0.02\n",
            "iteration: 402260 loss: 0.0013 lr: 0.02\n",
            "iteration: 402270 loss: 0.0017 lr: 0.02\n",
            "iteration: 402280 loss: 0.0016 lr: 0.02\n",
            "iteration: 402290 loss: 0.0015 lr: 0.02\n",
            "iteration: 402300 loss: 0.0017 lr: 0.02\n",
            "iteration: 402310 loss: 0.0012 lr: 0.02\n",
            "iteration: 402320 loss: 0.0022 lr: 0.02\n",
            "iteration: 402330 loss: 0.0017 lr: 0.02\n",
            "iteration: 402340 loss: 0.0017 lr: 0.02\n",
            "iteration: 402350 loss: 0.0016 lr: 0.02\n",
            "iteration: 402360 loss: 0.0011 lr: 0.02\n",
            "iteration: 402370 loss: 0.0019 lr: 0.02\n",
            "iteration: 402380 loss: 0.0014 lr: 0.02\n",
            "iteration: 402390 loss: 0.0018 lr: 0.02\n",
            "iteration: 402400 loss: 0.0017 lr: 0.02\n",
            "iteration: 402410 loss: 0.0018 lr: 0.02\n",
            "iteration: 402420 loss: 0.0016 lr: 0.02\n",
            "iteration: 402430 loss: 0.0018 lr: 0.02\n",
            "iteration: 402440 loss: 0.0013 lr: 0.02\n",
            "iteration: 402450 loss: 0.0014 lr: 0.02\n",
            "iteration: 402460 loss: 0.0018 lr: 0.02\n",
            "iteration: 402470 loss: 0.0016 lr: 0.02\n",
            "iteration: 402480 loss: 0.0011 lr: 0.02\n",
            "iteration: 402490 loss: 0.0016 lr: 0.02\n",
            "iteration: 402500 loss: 0.0015 lr: 0.02\n",
            "iteration: 402510 loss: 0.0017 lr: 0.02\n",
            "iteration: 402520 loss: 0.0014 lr: 0.02\n",
            "iteration: 402530 loss: 0.0011 lr: 0.02\n",
            "iteration: 402540 loss: 0.0015 lr: 0.02\n",
            "iteration: 402550 loss: 0.0023 lr: 0.02\n",
            "iteration: 402560 loss: 0.0017 lr: 0.02\n",
            "iteration: 402570 loss: 0.0014 lr: 0.02\n",
            "iteration: 402580 loss: 0.0012 lr: 0.02\n",
            "iteration: 402590 loss: 0.0016 lr: 0.02\n",
            "iteration: 402600 loss: 0.0018 lr: 0.02\n",
            "iteration: 402610 loss: 0.0019 lr: 0.02\n",
            "iteration: 402620 loss: 0.0015 lr: 0.02\n",
            "iteration: 402630 loss: 0.0016 lr: 0.02\n",
            "iteration: 402640 loss: 0.0015 lr: 0.02\n",
            "iteration: 402650 loss: 0.0016 lr: 0.02\n",
            "iteration: 402660 loss: 0.0015 lr: 0.02\n",
            "iteration: 402670 loss: 0.0024 lr: 0.02\n",
            "iteration: 402680 loss: 0.0012 lr: 0.02\n",
            "iteration: 402690 loss: 0.0020 lr: 0.02\n",
            "iteration: 402700 loss: 0.0014 lr: 0.02\n",
            "iteration: 402710 loss: 0.0015 lr: 0.02\n",
            "iteration: 402720 loss: 0.0016 lr: 0.02\n",
            "iteration: 402730 loss: 0.0014 lr: 0.02\n",
            "iteration: 402740 loss: 0.0018 lr: 0.02\n",
            "iteration: 402750 loss: 0.0015 lr: 0.02\n",
            "iteration: 402760 loss: 0.0018 lr: 0.02\n",
            "iteration: 402770 loss: 0.0018 lr: 0.02\n",
            "iteration: 402780 loss: 0.0016 lr: 0.02\n",
            "iteration: 402790 loss: 0.0019 lr: 0.02\n",
            "iteration: 402800 loss: 0.0017 lr: 0.02\n",
            "iteration: 402810 loss: 0.0013 lr: 0.02\n",
            "iteration: 402820 loss: 0.0017 lr: 0.02\n",
            "iteration: 402830 loss: 0.0017 lr: 0.02\n",
            "iteration: 402840 loss: 0.0020 lr: 0.02\n",
            "iteration: 402850 loss: 0.0016 lr: 0.02\n",
            "iteration: 402860 loss: 0.0015 lr: 0.02\n",
            "iteration: 402870 loss: 0.0016 lr: 0.02\n",
            "iteration: 402880 loss: 0.0015 lr: 0.02\n",
            "iteration: 402890 loss: 0.0016 lr: 0.02\n",
            "iteration: 402900 loss: 0.0015 lr: 0.02\n",
            "iteration: 402910 loss: 0.0021 lr: 0.02\n",
            "iteration: 402920 loss: 0.0018 lr: 0.02\n",
            "iteration: 402930 loss: 0.0020 lr: 0.02\n",
            "iteration: 402940 loss: 0.0016 lr: 0.02\n",
            "iteration: 402950 loss: 0.0011 lr: 0.02\n",
            "iteration: 402960 loss: 0.0014 lr: 0.02\n",
            "iteration: 402970 loss: 0.0018 lr: 0.02\n",
            "iteration: 402980 loss: 0.0018 lr: 0.02\n",
            "iteration: 402990 loss: 0.0013 lr: 0.02\n",
            "iteration: 403000 loss: 0.0013 lr: 0.02\n",
            "iteration: 403010 loss: 0.0020 lr: 0.02\n",
            "iteration: 403020 loss: 0.0013 lr: 0.02\n",
            "iteration: 403030 loss: 0.0015 lr: 0.02\n",
            "iteration: 403040 loss: 0.0016 lr: 0.02\n",
            "iteration: 403050 loss: 0.0016 lr: 0.02\n",
            "iteration: 403060 loss: 0.0025 lr: 0.02\n",
            "iteration: 403070 loss: 0.0015 lr: 0.02\n",
            "iteration: 403080 loss: 0.0013 lr: 0.02\n",
            "iteration: 403090 loss: 0.0014 lr: 0.02\n",
            "iteration: 403100 loss: 0.0017 lr: 0.02\n",
            "iteration: 403110 loss: 0.0012 lr: 0.02\n",
            "iteration: 403120 loss: 0.0013 lr: 0.02\n",
            "iteration: 403130 loss: 0.0018 lr: 0.02\n",
            "iteration: 403140 loss: 0.0015 lr: 0.02\n",
            "iteration: 403150 loss: 0.0019 lr: 0.02\n",
            "iteration: 403160 loss: 0.0017 lr: 0.02\n",
            "iteration: 403170 loss: 0.0016 lr: 0.02\n",
            "iteration: 403180 loss: 0.0015 lr: 0.02\n",
            "iteration: 403190 loss: 0.0018 lr: 0.02\n",
            "iteration: 403200 loss: 0.0019 lr: 0.02\n",
            "iteration: 403210 loss: 0.0015 lr: 0.02\n",
            "iteration: 403220 loss: 0.0022 lr: 0.02\n",
            "iteration: 403230 loss: 0.0018 lr: 0.02\n",
            "iteration: 403240 loss: 0.0022 lr: 0.02\n",
            "iteration: 403250 loss: 0.0014 lr: 0.02\n",
            "iteration: 403260 loss: 0.0017 lr: 0.02\n",
            "iteration: 403270 loss: 0.0016 lr: 0.02\n",
            "iteration: 403280 loss: 0.0011 lr: 0.02\n",
            "iteration: 403290 loss: 0.0015 lr: 0.02\n",
            "iteration: 403300 loss: 0.0017 lr: 0.02\n",
            "iteration: 403310 loss: 0.0014 lr: 0.02\n",
            "iteration: 403320 loss: 0.0016 lr: 0.02\n",
            "iteration: 403330 loss: 0.0018 lr: 0.02\n",
            "iteration: 403340 loss: 0.0015 lr: 0.02\n",
            "iteration: 403350 loss: 0.0013 lr: 0.02\n",
            "iteration: 403360 loss: 0.0017 lr: 0.02\n",
            "iteration: 403370 loss: 0.0016 lr: 0.02\n",
            "iteration: 403380 loss: 0.0015 lr: 0.02\n",
            "iteration: 403390 loss: 0.0013 lr: 0.02\n",
            "iteration: 403400 loss: 0.0018 lr: 0.02\n",
            "iteration: 403410 loss: 0.0014 lr: 0.02\n",
            "iteration: 403420 loss: 0.0016 lr: 0.02\n",
            "iteration: 403430 loss: 0.0012 lr: 0.02\n",
            "iteration: 403440 loss: 0.0011 lr: 0.02\n",
            "iteration: 403450 loss: 0.0017 lr: 0.02\n",
            "iteration: 403460 loss: 0.0020 lr: 0.02\n",
            "iteration: 403470 loss: 0.0016 lr: 0.02\n",
            "iteration: 403480 loss: 0.0022 lr: 0.02\n",
            "iteration: 403490 loss: 0.0015 lr: 0.02\n",
            "iteration: 403500 loss: 0.0017 lr: 0.02\n",
            "iteration: 403510 loss: 0.0017 lr: 0.02\n",
            "iteration: 403520 loss: 0.0013 lr: 0.02\n",
            "iteration: 403530 loss: 0.0012 lr: 0.02\n",
            "iteration: 403540 loss: 0.0019 lr: 0.02\n",
            "iteration: 403550 loss: 0.0021 lr: 0.02\n",
            "iteration: 403560 loss: 0.0017 lr: 0.02\n",
            "iteration: 403570 loss: 0.0020 lr: 0.02\n",
            "iteration: 403580 loss: 0.0013 lr: 0.02\n",
            "iteration: 403590 loss: 0.0019 lr: 0.02\n",
            "iteration: 403600 loss: 0.0019 lr: 0.02\n",
            "iteration: 403610 loss: 0.0021 lr: 0.02\n",
            "iteration: 403620 loss: 0.0014 lr: 0.02\n",
            "iteration: 403630 loss: 0.0016 lr: 0.02\n",
            "iteration: 403640 loss: 0.0020 lr: 0.02\n",
            "iteration: 403650 loss: 0.0016 lr: 0.02\n",
            "iteration: 403660 loss: 0.0017 lr: 0.02\n",
            "iteration: 403670 loss: 0.0011 lr: 0.02\n",
            "iteration: 403680 loss: 0.0016 lr: 0.02\n",
            "iteration: 403690 loss: 0.0014 lr: 0.02\n",
            "iteration: 403700 loss: 0.0011 lr: 0.02\n",
            "iteration: 403710 loss: 0.0018 lr: 0.02\n",
            "iteration: 403720 loss: 0.0019 lr: 0.02\n",
            "iteration: 403730 loss: 0.0016 lr: 0.02\n",
            "iteration: 403740 loss: 0.0015 lr: 0.02\n",
            "iteration: 403750 loss: 0.0012 lr: 0.02\n",
            "iteration: 403760 loss: 0.0013 lr: 0.02\n",
            "iteration: 403770 loss: 0.0018 lr: 0.02\n",
            "iteration: 403780 loss: 0.0014 lr: 0.02\n",
            "iteration: 403790 loss: 0.0019 lr: 0.02\n",
            "iteration: 403800 loss: 0.0013 lr: 0.02\n",
            "iteration: 403810 loss: 0.0019 lr: 0.02\n",
            "iteration: 403820 loss: 0.0020 lr: 0.02\n",
            "iteration: 403830 loss: 0.0013 lr: 0.02\n",
            "iteration: 403840 loss: 0.0025 lr: 0.02\n",
            "iteration: 403850 loss: 0.0014 lr: 0.02\n",
            "iteration: 403860 loss: 0.0017 lr: 0.02\n",
            "iteration: 403870 loss: 0.0017 lr: 0.02\n",
            "iteration: 403880 loss: 0.0018 lr: 0.02\n",
            "iteration: 403890 loss: 0.0014 lr: 0.02\n",
            "iteration: 403900 loss: 0.0017 lr: 0.02\n",
            "iteration: 403910 loss: 0.0017 lr: 0.02\n",
            "iteration: 403920 loss: 0.0012 lr: 0.02\n",
            "iteration: 403930 loss: 0.0015 lr: 0.02\n",
            "iteration: 403940 loss: 0.0013 lr: 0.02\n",
            "iteration: 403950 loss: 0.0014 lr: 0.02\n",
            "iteration: 403960 loss: 0.0014 lr: 0.02\n",
            "iteration: 403970 loss: 0.0018 lr: 0.02\n",
            "iteration: 403980 loss: 0.0017 lr: 0.02\n",
            "iteration: 403990 loss: 0.0019 lr: 0.02\n",
            "iteration: 404000 loss: 0.0018 lr: 0.02\n",
            "iteration: 404010 loss: 0.0013 lr: 0.02\n",
            "iteration: 404020 loss: 0.0015 lr: 0.02\n",
            "iteration: 404030 loss: 0.0018 lr: 0.02\n",
            "iteration: 404040 loss: 0.0018 lr: 0.02\n",
            "iteration: 404050 loss: 0.0019 lr: 0.02\n",
            "iteration: 404060 loss: 0.0021 lr: 0.02\n",
            "iteration: 404070 loss: 0.0019 lr: 0.02\n",
            "iteration: 404080 loss: 0.0013 lr: 0.02\n",
            "iteration: 404090 loss: 0.0017 lr: 0.02\n",
            "iteration: 404100 loss: 0.0019 lr: 0.02\n",
            "iteration: 404110 loss: 0.0016 lr: 0.02\n",
            "iteration: 404120 loss: 0.0023 lr: 0.02\n",
            "iteration: 404130 loss: 0.0016 lr: 0.02\n",
            "iteration: 404140 loss: 0.0024 lr: 0.02\n",
            "iteration: 404150 loss: 0.0015 lr: 0.02\n",
            "iteration: 404160 loss: 0.0025 lr: 0.02\n",
            "iteration: 404170 loss: 0.0015 lr: 0.02\n",
            "iteration: 404180 loss: 0.0011 lr: 0.02\n",
            "iteration: 404190 loss: 0.0016 lr: 0.02\n",
            "iteration: 404200 loss: 0.0019 lr: 0.02\n",
            "iteration: 404210 loss: 0.0015 lr: 0.02\n",
            "iteration: 404220 loss: 0.0016 lr: 0.02\n",
            "iteration: 404230 loss: 0.0016 lr: 0.02\n",
            "iteration: 404240 loss: 0.0013 lr: 0.02\n",
            "iteration: 404250 loss: 0.0026 lr: 0.02\n",
            "iteration: 404260 loss: 0.0013 lr: 0.02\n",
            "iteration: 404270 loss: 0.0026 lr: 0.02\n",
            "iteration: 404280 loss: 0.0025 lr: 0.02\n",
            "iteration: 404290 loss: 0.0014 lr: 0.02\n",
            "iteration: 404300 loss: 0.0016 lr: 0.02\n",
            "iteration: 404310 loss: 0.0014 lr: 0.02\n",
            "iteration: 404320 loss: 0.0016 lr: 0.02\n",
            "iteration: 404330 loss: 0.0014 lr: 0.02\n",
            "iteration: 404340 loss: 0.0012 lr: 0.02\n",
            "iteration: 404350 loss: 0.0019 lr: 0.02\n",
            "iteration: 404360 loss: 0.0014 lr: 0.02\n",
            "iteration: 404370 loss: 0.0011 lr: 0.02\n",
            "iteration: 404380 loss: 0.0020 lr: 0.02\n",
            "iteration: 404390 loss: 0.0022 lr: 0.02\n",
            "iteration: 404400 loss: 0.0017 lr: 0.02\n",
            "iteration: 404410 loss: 0.0015 lr: 0.02\n",
            "iteration: 404420 loss: 0.0014 lr: 0.02\n",
            "iteration: 404430 loss: 0.0012 lr: 0.02\n",
            "iteration: 404440 loss: 0.0013 lr: 0.02\n",
            "iteration: 404450 loss: 0.0015 lr: 0.02\n",
            "iteration: 404460 loss: 0.0017 lr: 0.02\n",
            "iteration: 404470 loss: 0.0018 lr: 0.02\n",
            "iteration: 404480 loss: 0.0018 lr: 0.02\n",
            "iteration: 404490 loss: 0.0019 lr: 0.02\n",
            "iteration: 404500 loss: 0.0010 lr: 0.02\n",
            "iteration: 404510 loss: 0.0018 lr: 0.02\n",
            "iteration: 404520 loss: 0.0018 lr: 0.02\n",
            "iteration: 404530 loss: 0.0014 lr: 0.02\n",
            "iteration: 404540 loss: 0.0016 lr: 0.02\n",
            "iteration: 404550 loss: 0.0013 lr: 0.02\n",
            "iteration: 404560 loss: 0.0014 lr: 0.02\n",
            "iteration: 404570 loss: 0.0015 lr: 0.02\n",
            "iteration: 404580 loss: 0.0020 lr: 0.02\n",
            "iteration: 404590 loss: 0.0015 lr: 0.02\n",
            "iteration: 404600 loss: 0.0021 lr: 0.02\n",
            "iteration: 404610 loss: 0.0016 lr: 0.02\n",
            "iteration: 404620 loss: 0.0017 lr: 0.02\n",
            "iteration: 404630 loss: 0.0014 lr: 0.02\n",
            "iteration: 404640 loss: 0.0013 lr: 0.02\n",
            "iteration: 404650 loss: 0.0015 lr: 0.02\n",
            "iteration: 404660 loss: 0.0013 lr: 0.02\n",
            "iteration: 404670 loss: 0.0016 lr: 0.02\n",
            "iteration: 404680 loss: 0.0015 lr: 0.02\n",
            "iteration: 404690 loss: 0.0019 lr: 0.02\n",
            "iteration: 404700 loss: 0.0012 lr: 0.02\n",
            "iteration: 404710 loss: 0.0013 lr: 0.02\n",
            "iteration: 404720 loss: 0.0018 lr: 0.02\n",
            "iteration: 404730 loss: 0.0018 lr: 0.02\n",
            "iteration: 404740 loss: 0.0013 lr: 0.02\n",
            "iteration: 404750 loss: 0.0024 lr: 0.02\n",
            "iteration: 404760 loss: 0.0020 lr: 0.02\n",
            "iteration: 404770 loss: 0.0020 lr: 0.02\n",
            "iteration: 404780 loss: 0.0018 lr: 0.02\n",
            "iteration: 404790 loss: 0.0013 lr: 0.02\n",
            "iteration: 404800 loss: 0.0018 lr: 0.02\n",
            "iteration: 404810 loss: 0.0013 lr: 0.02\n",
            "iteration: 404820 loss: 0.0015 lr: 0.02\n",
            "iteration: 404830 loss: 0.0029 lr: 0.02\n",
            "iteration: 404840 loss: 0.0029 lr: 0.02\n",
            "iteration: 404850 loss: 0.0013 lr: 0.02\n",
            "iteration: 404860 loss: 0.0014 lr: 0.02\n",
            "iteration: 404870 loss: 0.0022 lr: 0.02\n",
            "iteration: 404880 loss: 0.0018 lr: 0.02\n",
            "iteration: 404890 loss: 0.0013 lr: 0.02\n",
            "iteration: 404900 loss: 0.0017 lr: 0.02\n",
            "iteration: 404910 loss: 0.0017 lr: 0.02\n",
            "iteration: 404920 loss: 0.0017 lr: 0.02\n",
            "iteration: 404930 loss: 0.0017 lr: 0.02\n",
            "iteration: 404940 loss: 0.0015 lr: 0.02\n",
            "iteration: 404950 loss: 0.0017 lr: 0.02\n",
            "iteration: 404960 loss: 0.0021 lr: 0.02\n",
            "iteration: 404970 loss: 0.0015 lr: 0.02\n",
            "iteration: 404980 loss: 0.0022 lr: 0.02\n",
            "iteration: 404990 loss: 0.0018 lr: 0.02\n",
            "iteration: 405000 loss: 0.0014 lr: 0.02\n",
            "iteration: 405010 loss: 0.0013 lr: 0.02\n",
            "iteration: 405020 loss: 0.0017 lr: 0.02\n",
            "iteration: 405030 loss: 0.0014 lr: 0.02\n",
            "iteration: 405040 loss: 0.0015 lr: 0.02\n",
            "iteration: 405050 loss: 0.0017 lr: 0.02\n",
            "iteration: 405060 loss: 0.0019 lr: 0.02\n",
            "iteration: 405070 loss: 0.0018 lr: 0.02\n",
            "iteration: 405080 loss: 0.0013 lr: 0.02\n",
            "iteration: 405090 loss: 0.0016 lr: 0.02\n",
            "iteration: 405100 loss: 0.0010 lr: 0.02\n",
            "iteration: 405110 loss: 0.0016 lr: 0.02\n",
            "iteration: 405120 loss: 0.0019 lr: 0.02\n",
            "iteration: 405130 loss: 0.0014 lr: 0.02\n",
            "iteration: 405140 loss: 0.0015 lr: 0.02\n",
            "iteration: 405150 loss: 0.0015 lr: 0.02\n",
            "iteration: 405160 loss: 0.0013 lr: 0.02\n",
            "iteration: 405170 loss: 0.0012 lr: 0.02\n",
            "iteration: 405180 loss: 0.0015 lr: 0.02\n",
            "iteration: 405190 loss: 0.0013 lr: 0.02\n",
            "iteration: 405200 loss: 0.0019 lr: 0.02\n",
            "iteration: 405210 loss: 0.0012 lr: 0.02\n",
            "iteration: 405220 loss: 0.0014 lr: 0.02\n",
            "iteration: 405230 loss: 0.0015 lr: 0.02\n",
            "iteration: 405240 loss: 0.0022 lr: 0.02\n",
            "iteration: 405250 loss: 0.0012 lr: 0.02\n",
            "iteration: 405260 loss: 0.0023 lr: 0.02\n",
            "iteration: 405270 loss: 0.0015 lr: 0.02\n",
            "iteration: 405280 loss: 0.0014 lr: 0.02\n",
            "iteration: 405290 loss: 0.0018 lr: 0.02\n",
            "iteration: 405300 loss: 0.0015 lr: 0.02\n",
            "iteration: 405310 loss: 0.0021 lr: 0.02\n",
            "iteration: 405320 loss: 0.0019 lr: 0.02\n",
            "iteration: 405330 loss: 0.0018 lr: 0.02\n",
            "iteration: 405340 loss: 0.0016 lr: 0.02\n",
            "iteration: 405350 loss: 0.0020 lr: 0.02\n",
            "iteration: 405360 loss: 0.0014 lr: 0.02\n",
            "iteration: 405370 loss: 0.0012 lr: 0.02\n",
            "iteration: 405380 loss: 0.0017 lr: 0.02\n",
            "iteration: 405390 loss: 0.0015 lr: 0.02\n",
            "iteration: 405400 loss: 0.0017 lr: 0.02\n",
            "iteration: 405410 loss: 0.0022 lr: 0.02\n",
            "iteration: 405420 loss: 0.0015 lr: 0.02\n",
            "iteration: 405430 loss: 0.0020 lr: 0.02\n",
            "iteration: 405440 loss: 0.0013 lr: 0.02\n",
            "iteration: 405450 loss: 0.0013 lr: 0.02\n",
            "iteration: 405460 loss: 0.0015 lr: 0.02\n",
            "iteration: 405470 loss: 0.0012 lr: 0.02\n",
            "iteration: 405480 loss: 0.0015 lr: 0.02\n",
            "iteration: 405490 loss: 0.0011 lr: 0.02\n",
            "iteration: 405500 loss: 0.0013 lr: 0.02\n",
            "iteration: 405510 loss: 0.0015 lr: 0.02\n",
            "iteration: 405520 loss: 0.0012 lr: 0.02\n",
            "iteration: 405530 loss: 0.0025 lr: 0.02\n",
            "iteration: 405540 loss: 0.0013 lr: 0.02\n",
            "iteration: 405550 loss: 0.0012 lr: 0.02\n",
            "iteration: 405560 loss: 0.0017 lr: 0.02\n",
            "iteration: 405570 loss: 0.0014 lr: 0.02\n",
            "iteration: 405580 loss: 0.0018 lr: 0.02\n",
            "iteration: 405590 loss: 0.0017 lr: 0.02\n",
            "iteration: 405600 loss: 0.0012 lr: 0.02\n",
            "iteration: 405610 loss: 0.0015 lr: 0.02\n",
            "iteration: 405620 loss: 0.0015 lr: 0.02\n",
            "iteration: 405630 loss: 0.0012 lr: 0.02\n",
            "iteration: 405640 loss: 0.0016 lr: 0.02\n",
            "iteration: 405650 loss: 0.0019 lr: 0.02\n",
            "iteration: 405660 loss: 0.0016 lr: 0.02\n",
            "iteration: 405670 loss: 0.0019 lr: 0.02\n",
            "iteration: 405680 loss: 0.0024 lr: 0.02\n",
            "iteration: 405690 loss: 0.0016 lr: 0.02\n",
            "iteration: 405700 loss: 0.0019 lr: 0.02\n",
            "iteration: 405710 loss: 0.0024 lr: 0.02\n",
            "iteration: 405720 loss: 0.0023 lr: 0.02\n",
            "iteration: 405730 loss: 0.0014 lr: 0.02\n",
            "iteration: 405740 loss: 0.0016 lr: 0.02\n",
            "iteration: 405750 loss: 0.0014 lr: 0.02\n",
            "iteration: 405760 loss: 0.0013 lr: 0.02\n",
            "iteration: 405770 loss: 0.0012 lr: 0.02\n",
            "iteration: 405780 loss: 0.0019 lr: 0.02\n",
            "iteration: 405790 loss: 0.0016 lr: 0.02\n",
            "iteration: 405800 loss: 0.0015 lr: 0.02\n",
            "iteration: 405810 loss: 0.0013 lr: 0.02\n",
            "iteration: 405820 loss: 0.0013 lr: 0.02\n",
            "iteration: 405830 loss: 0.0017 lr: 0.02\n",
            "iteration: 405840 loss: 0.0012 lr: 0.02\n",
            "iteration: 405850 loss: 0.0016 lr: 0.02\n",
            "iteration: 405860 loss: 0.0015 lr: 0.02\n",
            "iteration: 405870 loss: 0.0013 lr: 0.02\n",
            "iteration: 405880 loss: 0.0017 lr: 0.02\n",
            "iteration: 405890 loss: 0.0013 lr: 0.02\n",
            "iteration: 405900 loss: 0.0016 lr: 0.02\n",
            "iteration: 405910 loss: 0.0012 lr: 0.02\n",
            "iteration: 405920 loss: 0.0021 lr: 0.02\n",
            "iteration: 405930 loss: 0.0016 lr: 0.02\n",
            "iteration: 405940 loss: 0.0018 lr: 0.02\n",
            "iteration: 405950 loss: 0.0014 lr: 0.02\n",
            "iteration: 405960 loss: 0.0020 lr: 0.02\n",
            "iteration: 405970 loss: 0.0021 lr: 0.02\n",
            "iteration: 405980 loss: 0.0015 lr: 0.02\n",
            "iteration: 405990 loss: 0.0014 lr: 0.02\n",
            "iteration: 406000 loss: 0.0014 lr: 0.02\n",
            "iteration: 406010 loss: 0.0016 lr: 0.02\n",
            "iteration: 406020 loss: 0.0014 lr: 0.02\n",
            "iteration: 406030 loss: 0.0018 lr: 0.02\n",
            "iteration: 406040 loss: 0.0018 lr: 0.02\n",
            "iteration: 406050 loss: 0.0016 lr: 0.02\n",
            "iteration: 406060 loss: 0.0017 lr: 0.02\n",
            "iteration: 406070 loss: 0.0010 lr: 0.02\n",
            "iteration: 406080 loss: 0.0016 lr: 0.02\n",
            "iteration: 406090 loss: 0.0020 lr: 0.02\n",
            "iteration: 406100 loss: 0.0017 lr: 0.02\n",
            "iteration: 406110 loss: 0.0020 lr: 0.02\n",
            "iteration: 406120 loss: 0.0018 lr: 0.02\n",
            "iteration: 406130 loss: 0.0017 lr: 0.02\n",
            "iteration: 406140 loss: 0.0019 lr: 0.02\n",
            "iteration: 406150 loss: 0.0015 lr: 0.02\n",
            "iteration: 406160 loss: 0.0017 lr: 0.02\n",
            "iteration: 406170 loss: 0.0017 lr: 0.02\n",
            "iteration: 406180 loss: 0.0021 lr: 0.02\n",
            "iteration: 406190 loss: 0.0015 lr: 0.02\n",
            "iteration: 406200 loss: 0.0020 lr: 0.02\n",
            "iteration: 406210 loss: 0.0013 lr: 0.02\n",
            "iteration: 406220 loss: 0.0012 lr: 0.02\n",
            "iteration: 406230 loss: 0.0020 lr: 0.02\n",
            "iteration: 406240 loss: 0.0018 lr: 0.02\n",
            "iteration: 406250 loss: 0.0022 lr: 0.02\n",
            "iteration: 406260 loss: 0.0012 lr: 0.02\n",
            "iteration: 406270 loss: 0.0020 lr: 0.02\n",
            "iteration: 406280 loss: 0.0017 lr: 0.02\n",
            "iteration: 406290 loss: 0.0016 lr: 0.02\n",
            "iteration: 406300 loss: 0.0016 lr: 0.02\n",
            "iteration: 406310 loss: 0.0020 lr: 0.02\n",
            "iteration: 406320 loss: 0.0016 lr: 0.02\n",
            "iteration: 406330 loss: 0.0017 lr: 0.02\n",
            "iteration: 406340 loss: 0.0015 lr: 0.02\n",
            "iteration: 406350 loss: 0.0015 lr: 0.02\n",
            "iteration: 406360 loss: 0.0018 lr: 0.02\n",
            "iteration: 406370 loss: 0.0014 lr: 0.02\n",
            "iteration: 406380 loss: 0.0017 lr: 0.02\n",
            "iteration: 406390 loss: 0.0014 lr: 0.02\n",
            "iteration: 406400 loss: 0.0017 lr: 0.02\n",
            "iteration: 406410 loss: 0.0014 lr: 0.02\n",
            "iteration: 406420 loss: 0.0014 lr: 0.02\n",
            "iteration: 406430 loss: 0.0018 lr: 0.02\n",
            "iteration: 406440 loss: 0.0023 lr: 0.02\n",
            "iteration: 406450 loss: 0.0017 lr: 0.02\n",
            "iteration: 406460 loss: 0.0015 lr: 0.02\n",
            "iteration: 406470 loss: 0.0017 lr: 0.02\n",
            "iteration: 406480 loss: 0.0017 lr: 0.02\n",
            "iteration: 406490 loss: 0.0014 lr: 0.02\n",
            "iteration: 406500 loss: 0.0016 lr: 0.02\n",
            "iteration: 406510 loss: 0.0016 lr: 0.02\n",
            "iteration: 406520 loss: 0.0016 lr: 0.02\n",
            "iteration: 406530 loss: 0.0019 lr: 0.02\n",
            "iteration: 406540 loss: 0.0013 lr: 0.02\n",
            "iteration: 406550 loss: 0.0014 lr: 0.02\n",
            "iteration: 406560 loss: 0.0018 lr: 0.02\n",
            "iteration: 406570 loss: 0.0017 lr: 0.02\n",
            "iteration: 406580 loss: 0.0014 lr: 0.02\n",
            "iteration: 406590 loss: 0.0018 lr: 0.02\n",
            "iteration: 406600 loss: 0.0014 lr: 0.02\n",
            "iteration: 406610 loss: 0.0014 lr: 0.02\n",
            "iteration: 406620 loss: 0.0023 lr: 0.02\n",
            "iteration: 406630 loss: 0.0014 lr: 0.02\n",
            "iteration: 406640 loss: 0.0018 lr: 0.02\n",
            "iteration: 406650 loss: 0.0015 lr: 0.02\n",
            "iteration: 406660 loss: 0.0022 lr: 0.02\n",
            "iteration: 406670 loss: 0.0021 lr: 0.02\n",
            "iteration: 406680 loss: 0.0017 lr: 0.02\n",
            "iteration: 406690 loss: 0.0013 lr: 0.02\n",
            "iteration: 406700 loss: 0.0023 lr: 0.02\n",
            "iteration: 406710 loss: 0.0014 lr: 0.02\n",
            "iteration: 406720 loss: 0.0012 lr: 0.02\n",
            "iteration: 406730 loss: 0.0015 lr: 0.02\n",
            "iteration: 406740 loss: 0.0014 lr: 0.02\n",
            "iteration: 406750 loss: 0.0015 lr: 0.02\n",
            "iteration: 406760 loss: 0.0015 lr: 0.02\n",
            "iteration: 406770 loss: 0.0019 lr: 0.02\n",
            "iteration: 406780 loss: 0.0029 lr: 0.02\n",
            "iteration: 406790 loss: 0.0020 lr: 0.02\n",
            "iteration: 406800 loss: 0.0014 lr: 0.02\n",
            "iteration: 406810 loss: 0.0019 lr: 0.02\n",
            "iteration: 406820 loss: 0.0016 lr: 0.02\n",
            "iteration: 406830 loss: 0.0016 lr: 0.02\n",
            "iteration: 406840 loss: 0.0020 lr: 0.02\n",
            "iteration: 406850 loss: 0.0016 lr: 0.02\n",
            "iteration: 406860 loss: 0.0014 lr: 0.02\n",
            "iteration: 406870 loss: 0.0017 lr: 0.02\n",
            "iteration: 406880 loss: 0.0022 lr: 0.02\n",
            "iteration: 406890 loss: 0.0016 lr: 0.02\n",
            "iteration: 406900 loss: 0.0014 lr: 0.02\n",
            "iteration: 406910 loss: 0.0018 lr: 0.02\n",
            "iteration: 406920 loss: 0.0015 lr: 0.02\n",
            "iteration: 406930 loss: 0.0020 lr: 0.02\n",
            "iteration: 406940 loss: 0.0023 lr: 0.02\n",
            "iteration: 406950 loss: 0.0018 lr: 0.02\n",
            "iteration: 406960 loss: 0.0014 lr: 0.02\n",
            "iteration: 406970 loss: 0.0015 lr: 0.02\n",
            "iteration: 406980 loss: 0.0015 lr: 0.02\n",
            "iteration: 406990 loss: 0.0019 lr: 0.02\n",
            "iteration: 407000 loss: 0.0014 lr: 0.02\n",
            "iteration: 407010 loss: 0.0018 lr: 0.02\n",
            "iteration: 407020 loss: 0.0016 lr: 0.02\n",
            "iteration: 407030 loss: 0.0013 lr: 0.02\n",
            "iteration: 407040 loss: 0.0016 lr: 0.02\n",
            "iteration: 407050 loss: 0.0029 lr: 0.02\n",
            "iteration: 407060 loss: 0.0025 lr: 0.02\n",
            "iteration: 407070 loss: 0.0023 lr: 0.02\n",
            "iteration: 407080 loss: 0.0025 lr: 0.02\n",
            "iteration: 407090 loss: 0.0023 lr: 0.02\n",
            "iteration: 407100 loss: 0.0014 lr: 0.02\n",
            "iteration: 407110 loss: 0.0023 lr: 0.02\n",
            "iteration: 407120 loss: 0.0016 lr: 0.02\n",
            "iteration: 407130 loss: 0.0016 lr: 0.02\n",
            "iteration: 407140 loss: 0.0020 lr: 0.02\n",
            "iteration: 407150 loss: 0.0019 lr: 0.02\n",
            "iteration: 407160 loss: 0.0015 lr: 0.02\n",
            "iteration: 407170 loss: 0.0014 lr: 0.02\n",
            "iteration: 407180 loss: 0.0017 lr: 0.02\n",
            "iteration: 407190 loss: 0.0016 lr: 0.02\n",
            "iteration: 407200 loss: 0.0018 lr: 0.02\n",
            "iteration: 407210 loss: 0.0016 lr: 0.02\n",
            "iteration: 407220 loss: 0.0015 lr: 0.02\n",
            "iteration: 407230 loss: 0.0016 lr: 0.02\n",
            "iteration: 407240 loss: 0.0018 lr: 0.02\n",
            "iteration: 407250 loss: 0.0015 lr: 0.02\n",
            "iteration: 407260 loss: 0.0008 lr: 0.02\n",
            "iteration: 407270 loss: 0.0016 lr: 0.02\n",
            "iteration: 407280 loss: 0.0016 lr: 0.02\n",
            "iteration: 407290 loss: 0.0019 lr: 0.02\n",
            "iteration: 407300 loss: 0.0017 lr: 0.02\n",
            "iteration: 407310 loss: 0.0018 lr: 0.02\n",
            "iteration: 407320 loss: 0.0016 lr: 0.02\n",
            "iteration: 407330 loss: 0.0018 lr: 0.02\n",
            "iteration: 407340 loss: 0.0016 lr: 0.02\n",
            "iteration: 407350 loss: 0.0019 lr: 0.02\n",
            "iteration: 407360 loss: 0.0016 lr: 0.02\n",
            "iteration: 407370 loss: 0.0017 lr: 0.02\n",
            "iteration: 407380 loss: 0.0014 lr: 0.02\n",
            "iteration: 407390 loss: 0.0014 lr: 0.02\n",
            "iteration: 407400 loss: 0.0021 lr: 0.02\n",
            "iteration: 407410 loss: 0.0022 lr: 0.02\n",
            "iteration: 407420 loss: 0.0016 lr: 0.02\n",
            "iteration: 407430 loss: 0.0015 lr: 0.02\n",
            "iteration: 407440 loss: 0.0021 lr: 0.02\n",
            "iteration: 407450 loss: 0.0013 lr: 0.02\n",
            "iteration: 407460 loss: 0.0017 lr: 0.02\n",
            "iteration: 407470 loss: 0.0016 lr: 0.02\n",
            "iteration: 407480 loss: 0.0012 lr: 0.02\n",
            "iteration: 407490 loss: 0.0019 lr: 0.02\n",
            "iteration: 407500 loss: 0.0016 lr: 0.02\n",
            "iteration: 407510 loss: 0.0015 lr: 0.02\n",
            "iteration: 407520 loss: 0.0014 lr: 0.02\n",
            "iteration: 407530 loss: 0.0011 lr: 0.02\n",
            "iteration: 407540 loss: 0.0015 lr: 0.02\n",
            "iteration: 407550 loss: 0.0018 lr: 0.02\n",
            "iteration: 407560 loss: 0.0018 lr: 0.02\n",
            "iteration: 407570 loss: 0.0015 lr: 0.02\n",
            "iteration: 407580 loss: 0.0015 lr: 0.02\n",
            "iteration: 407590 loss: 0.0024 lr: 0.02\n",
            "iteration: 407600 loss: 0.0013 lr: 0.02\n",
            "iteration: 407610 loss: 0.0011 lr: 0.02\n",
            "iteration: 407620 loss: 0.0018 lr: 0.02\n",
            "iteration: 407630 loss: 0.0015 lr: 0.02\n",
            "iteration: 407640 loss: 0.0019 lr: 0.02\n",
            "iteration: 407650 loss: 0.0017 lr: 0.02\n",
            "iteration: 407660 loss: 0.0013 lr: 0.02\n",
            "iteration: 407670 loss: 0.0013 lr: 0.02\n",
            "iteration: 407680 loss: 0.0017 lr: 0.02\n",
            "iteration: 407690 loss: 0.0015 lr: 0.02\n",
            "iteration: 407700 loss: 0.0015 lr: 0.02\n",
            "iteration: 407710 loss: 0.0014 lr: 0.02\n",
            "iteration: 407720 loss: 0.0016 lr: 0.02\n",
            "iteration: 407730 loss: 0.0014 lr: 0.02\n",
            "iteration: 407740 loss: 0.0013 lr: 0.02\n",
            "iteration: 407750 loss: 0.0015 lr: 0.02\n",
            "iteration: 407760 loss: 0.0009 lr: 0.02\n",
            "iteration: 407770 loss: 0.0011 lr: 0.02\n",
            "iteration: 407780 loss: 0.0020 lr: 0.02\n",
            "iteration: 407790 loss: 0.0015 lr: 0.02\n",
            "iteration: 407800 loss: 0.0018 lr: 0.02\n",
            "iteration: 407810 loss: 0.0017 lr: 0.02\n",
            "iteration: 407820 loss: 0.0017 lr: 0.02\n",
            "iteration: 407830 loss: 0.0015 lr: 0.02\n",
            "iteration: 407840 loss: 0.0019 lr: 0.02\n",
            "iteration: 407850 loss: 0.0014 lr: 0.02\n",
            "iteration: 407860 loss: 0.0016 lr: 0.02\n",
            "iteration: 407870 loss: 0.0014 lr: 0.02\n",
            "iteration: 407880 loss: 0.0017 lr: 0.02\n",
            "iteration: 407890 loss: 0.0015 lr: 0.02\n",
            "iteration: 407900 loss: 0.0016 lr: 0.02\n",
            "iteration: 407910 loss: 0.0014 lr: 0.02\n",
            "iteration: 407920 loss: 0.0017 lr: 0.02\n",
            "iteration: 407930 loss: 0.0016 lr: 0.02\n",
            "iteration: 407940 loss: 0.0012 lr: 0.02\n",
            "iteration: 407950 loss: 0.0022 lr: 0.02\n",
            "iteration: 407960 loss: 0.0018 lr: 0.02\n",
            "iteration: 407970 loss: 0.0014 lr: 0.02\n",
            "iteration: 407980 loss: 0.0019 lr: 0.02\n",
            "iteration: 407990 loss: 0.0022 lr: 0.02\n",
            "iteration: 408000 loss: 0.0014 lr: 0.02\n",
            "iteration: 408010 loss: 0.0022 lr: 0.02\n",
            "iteration: 408020 loss: 0.0013 lr: 0.02\n",
            "iteration: 408030 loss: 0.0015 lr: 0.02\n",
            "iteration: 408040 loss: 0.0017 lr: 0.02\n",
            "iteration: 408050 loss: 0.0016 lr: 0.02\n",
            "iteration: 408060 loss: 0.0019 lr: 0.02\n",
            "iteration: 408070 loss: 0.0016 lr: 0.02\n",
            "iteration: 408080 loss: 0.0015 lr: 0.02\n",
            "iteration: 408090 loss: 0.0014 lr: 0.02\n",
            "iteration: 408100 loss: 0.0016 lr: 0.02\n",
            "iteration: 408110 loss: 0.0020 lr: 0.02\n",
            "iteration: 408120 loss: 0.0013 lr: 0.02\n",
            "iteration: 408130 loss: 0.0017 lr: 0.02\n",
            "iteration: 408140 loss: 0.0015 lr: 0.02\n",
            "iteration: 408150 loss: 0.0019 lr: 0.02\n",
            "iteration: 408160 loss: 0.0015 lr: 0.02\n",
            "iteration: 408170 loss: 0.0012 lr: 0.02\n",
            "iteration: 408180 loss: 0.0012 lr: 0.02\n",
            "iteration: 408190 loss: 0.0016 lr: 0.02\n",
            "iteration: 408200 loss: 0.0013 lr: 0.02\n",
            "iteration: 408210 loss: 0.0013 lr: 0.02\n",
            "iteration: 408220 loss: 0.0030 lr: 0.02\n",
            "iteration: 408230 loss: 0.0016 lr: 0.02\n",
            "iteration: 408240 loss: 0.0016 lr: 0.02\n",
            "iteration: 408250 loss: 0.0018 lr: 0.02\n",
            "iteration: 408260 loss: 0.0023 lr: 0.02\n",
            "iteration: 408270 loss: 0.0014 lr: 0.02\n",
            "iteration: 408280 loss: 0.0011 lr: 0.02\n",
            "iteration: 408290 loss: 0.0017 lr: 0.02\n",
            "iteration: 408300 loss: 0.0017 lr: 0.02\n",
            "iteration: 408310 loss: 0.0016 lr: 0.02\n",
            "iteration: 408320 loss: 0.0025 lr: 0.02\n",
            "iteration: 408330 loss: 0.0022 lr: 0.02\n",
            "iteration: 408340 loss: 0.0014 lr: 0.02\n",
            "iteration: 408350 loss: 0.0012 lr: 0.02\n",
            "iteration: 408360 loss: 0.0022 lr: 0.02\n",
            "iteration: 408370 loss: 0.0020 lr: 0.02\n",
            "iteration: 408380 loss: 0.0022 lr: 0.02\n",
            "iteration: 408390 loss: 0.0018 lr: 0.02\n",
            "iteration: 408400 loss: 0.0017 lr: 0.02\n",
            "iteration: 408410 loss: 0.0018 lr: 0.02\n",
            "iteration: 408420 loss: 0.0017 lr: 0.02\n",
            "iteration: 408430 loss: 0.0015 lr: 0.02\n",
            "iteration: 408440 loss: 0.0011 lr: 0.02\n",
            "iteration: 408450 loss: 0.0015 lr: 0.02\n",
            "iteration: 408460 loss: 0.0019 lr: 0.02\n",
            "iteration: 408470 loss: 0.0010 lr: 0.02\n",
            "iteration: 408480 loss: 0.0015 lr: 0.02\n",
            "iteration: 408490 loss: 0.0017 lr: 0.02\n",
            "iteration: 408500 loss: 0.0019 lr: 0.02\n",
            "iteration: 408510 loss: 0.0014 lr: 0.02\n",
            "iteration: 408520 loss: 0.0016 lr: 0.02\n",
            "iteration: 408530 loss: 0.0017 lr: 0.02\n",
            "iteration: 408540 loss: 0.0017 lr: 0.02\n",
            "iteration: 408550 loss: 0.0015 lr: 0.02\n",
            "iteration: 408560 loss: 0.0012 lr: 0.02\n",
            "iteration: 408570 loss: 0.0012 lr: 0.02\n",
            "iteration: 408580 loss: 0.0014 lr: 0.02\n",
            "iteration: 408590 loss: 0.0016 lr: 0.02\n",
            "iteration: 408600 loss: 0.0017 lr: 0.02\n",
            "iteration: 408610 loss: 0.0014 lr: 0.02\n",
            "iteration: 408620 loss: 0.0018 lr: 0.02\n",
            "iteration: 408630 loss: 0.0014 lr: 0.02\n",
            "iteration: 408640 loss: 0.0010 lr: 0.02\n",
            "iteration: 408650 loss: 0.0017 lr: 0.02\n",
            "iteration: 408660 loss: 0.0016 lr: 0.02\n",
            "iteration: 408670 loss: 0.0019 lr: 0.02\n",
            "iteration: 408680 loss: 0.0014 lr: 0.02\n",
            "iteration: 408690 loss: 0.0011 lr: 0.02\n",
            "iteration: 408700 loss: 0.0014 lr: 0.02\n",
            "iteration: 408710 loss: 0.0018 lr: 0.02\n",
            "iteration: 408720 loss: 0.0016 lr: 0.02\n",
            "iteration: 408730 loss: 0.0012 lr: 0.02\n",
            "iteration: 408740 loss: 0.0014 lr: 0.02\n",
            "iteration: 408750 loss: 0.0015 lr: 0.02\n",
            "iteration: 408760 loss: 0.0016 lr: 0.02\n",
            "iteration: 408770 loss: 0.0015 lr: 0.02\n",
            "iteration: 408780 loss: 0.0014 lr: 0.02\n",
            "iteration: 408790 loss: 0.0014 lr: 0.02\n",
            "iteration: 408800 loss: 0.0013 lr: 0.02\n",
            "iteration: 408810 loss: 0.0016 lr: 0.02\n",
            "iteration: 408820 loss: 0.0021 lr: 0.02\n",
            "iteration: 408830 loss: 0.0014 lr: 0.02\n",
            "iteration: 408840 loss: 0.0016 lr: 0.02\n",
            "iteration: 408850 loss: 0.0016 lr: 0.02\n",
            "iteration: 408860 loss: 0.0017 lr: 0.02\n",
            "iteration: 408870 loss: 0.0019 lr: 0.02\n",
            "iteration: 408880 loss: 0.0020 lr: 0.02\n",
            "iteration: 408890 loss: 0.0018 lr: 0.02\n",
            "iteration: 408900 loss: 0.0016 lr: 0.02\n",
            "iteration: 408910 loss: 0.0011 lr: 0.02\n",
            "iteration: 408920 loss: 0.0018 lr: 0.02\n",
            "iteration: 408930 loss: 0.0013 lr: 0.02\n",
            "iteration: 408940 loss: 0.0012 lr: 0.02\n",
            "iteration: 408950 loss: 0.0012 lr: 0.02\n",
            "iteration: 408960 loss: 0.0018 lr: 0.02\n",
            "iteration: 408970 loss: 0.0023 lr: 0.02\n",
            "iteration: 408980 loss: 0.0015 lr: 0.02\n",
            "iteration: 408990 loss: 0.0024 lr: 0.02\n",
            "iteration: 409000 loss: 0.0016 lr: 0.02\n",
            "iteration: 409010 loss: 0.0013 lr: 0.02\n",
            "iteration: 409020 loss: 0.0038 lr: 0.02\n",
            "iteration: 409030 loss: 0.0019 lr: 0.02\n",
            "iteration: 409040 loss: 0.0016 lr: 0.02\n",
            "iteration: 409050 loss: 0.0015 lr: 0.02\n",
            "iteration: 409060 loss: 0.0024 lr: 0.02\n",
            "iteration: 409070 loss: 0.0015 lr: 0.02\n",
            "iteration: 409080 loss: 0.0015 lr: 0.02\n",
            "iteration: 409090 loss: 0.0011 lr: 0.02\n",
            "iteration: 409100 loss: 0.0014 lr: 0.02\n",
            "iteration: 409110 loss: 0.0015 lr: 0.02\n",
            "iteration: 409120 loss: 0.0019 lr: 0.02\n",
            "iteration: 409130 loss: 0.0014 lr: 0.02\n",
            "iteration: 409140 loss: 0.0019 lr: 0.02\n",
            "iteration: 409150 loss: 0.0012 lr: 0.02\n",
            "iteration: 409160 loss: 0.0015 lr: 0.02\n",
            "iteration: 409170 loss: 0.0020 lr: 0.02\n",
            "iteration: 409180 loss: 0.0014 lr: 0.02\n",
            "iteration: 409190 loss: 0.0012 lr: 0.02\n",
            "iteration: 409200 loss: 0.0020 lr: 0.02\n",
            "iteration: 409210 loss: 0.0014 lr: 0.02\n",
            "iteration: 409220 loss: 0.0016 lr: 0.02\n",
            "iteration: 409230 loss: 0.0015 lr: 0.02\n",
            "iteration: 409240 loss: 0.0017 lr: 0.02\n",
            "iteration: 409250 loss: 0.0022 lr: 0.02\n",
            "iteration: 409260 loss: 0.0014 lr: 0.02\n",
            "iteration: 409270 loss: 0.0015 lr: 0.02\n",
            "iteration: 409280 loss: 0.0022 lr: 0.02\n",
            "iteration: 409290 loss: 0.0016 lr: 0.02\n",
            "iteration: 409300 loss: 0.0017 lr: 0.02\n",
            "iteration: 409310 loss: 0.0022 lr: 0.02\n",
            "iteration: 409320 loss: 0.0016 lr: 0.02\n",
            "iteration: 409330 loss: 0.0018 lr: 0.02\n",
            "iteration: 409340 loss: 0.0013 lr: 0.02\n",
            "iteration: 409350 loss: 0.0015 lr: 0.02\n",
            "iteration: 409360 loss: 0.0015 lr: 0.02\n",
            "iteration: 409370 loss: 0.0018 lr: 0.02\n",
            "iteration: 409380 loss: 0.0024 lr: 0.02\n",
            "iteration: 409390 loss: 0.0017 lr: 0.02\n",
            "iteration: 409400 loss: 0.0010 lr: 0.02\n",
            "iteration: 409410 loss: 0.0016 lr: 0.02\n",
            "iteration: 409420 loss: 0.0021 lr: 0.02\n",
            "iteration: 409430 loss: 0.0013 lr: 0.02\n",
            "iteration: 409440 loss: 0.0016 lr: 0.02\n",
            "iteration: 409450 loss: 0.0016 lr: 0.02\n",
            "iteration: 409460 loss: 0.0016 lr: 0.02\n",
            "iteration: 409470 loss: 0.0013 lr: 0.02\n",
            "iteration: 409480 loss: 0.0016 lr: 0.02\n",
            "iteration: 409490 loss: 0.0012 lr: 0.02\n",
            "iteration: 409500 loss: 0.0016 lr: 0.02\n",
            "iteration: 409510 loss: 0.0016 lr: 0.02\n",
            "iteration: 409520 loss: 0.0021 lr: 0.02\n",
            "iteration: 409530 loss: 0.0014 lr: 0.02\n",
            "iteration: 409540 loss: 0.0021 lr: 0.02\n",
            "iteration: 409550 loss: 0.0020 lr: 0.02\n",
            "iteration: 409560 loss: 0.0018 lr: 0.02\n",
            "iteration: 409570 loss: 0.0014 lr: 0.02\n",
            "iteration: 409580 loss: 0.0015 lr: 0.02\n",
            "iteration: 409590 loss: 0.0017 lr: 0.02\n",
            "iteration: 409600 loss: 0.0018 lr: 0.02\n",
            "iteration: 409610 loss: 0.0016 lr: 0.02\n",
            "iteration: 409620 loss: 0.0012 lr: 0.02\n",
            "iteration: 409630 loss: 0.0014 lr: 0.02\n",
            "iteration: 409640 loss: 0.0020 lr: 0.02\n",
            "iteration: 409650 loss: 0.0014 lr: 0.02\n",
            "iteration: 409660 loss: 0.0014 lr: 0.02\n",
            "iteration: 409670 loss: 0.0014 lr: 0.02\n",
            "iteration: 409680 loss: 0.0016 lr: 0.02\n",
            "iteration: 409690 loss: 0.0015 lr: 0.02\n",
            "iteration: 409700 loss: 0.0013 lr: 0.02\n",
            "iteration: 409710 loss: 0.0011 lr: 0.02\n",
            "iteration: 409720 loss: 0.0014 lr: 0.02\n",
            "iteration: 409730 loss: 0.0018 lr: 0.02\n",
            "iteration: 409740 loss: 0.0013 lr: 0.02\n",
            "iteration: 409750 loss: 0.0014 lr: 0.02\n",
            "iteration: 409760 loss: 0.0019 lr: 0.02\n",
            "iteration: 409770 loss: 0.0019 lr: 0.02\n",
            "iteration: 409780 loss: 0.0017 lr: 0.02\n",
            "iteration: 409790 loss: 0.0015 lr: 0.02\n",
            "iteration: 409800 loss: 0.0019 lr: 0.02\n",
            "iteration: 409810 loss: 0.0016 lr: 0.02\n",
            "iteration: 409820 loss: 0.0013 lr: 0.02\n",
            "iteration: 409830 loss: 0.0011 lr: 0.02\n",
            "iteration: 409840 loss: 0.0014 lr: 0.02\n",
            "iteration: 409850 loss: 0.0014 lr: 0.02\n",
            "iteration: 409860 loss: 0.0017 lr: 0.02\n",
            "iteration: 409870 loss: 0.0016 lr: 0.02\n",
            "iteration: 409880 loss: 0.0017 lr: 0.02\n",
            "iteration: 409890 loss: 0.0018 lr: 0.02\n",
            "iteration: 409900 loss: 0.0025 lr: 0.02\n",
            "iteration: 409910 loss: 0.0020 lr: 0.02\n",
            "iteration: 409920 loss: 0.0015 lr: 0.02\n",
            "iteration: 409930 loss: 0.0014 lr: 0.02\n",
            "iteration: 409940 loss: 0.0016 lr: 0.02\n",
            "iteration: 409950 loss: 0.0020 lr: 0.02\n",
            "iteration: 409960 loss: 0.0019 lr: 0.02\n",
            "iteration: 409970 loss: 0.0012 lr: 0.02\n",
            "iteration: 409980 loss: 0.0021 lr: 0.02\n",
            "iteration: 409990 loss: 0.0016 lr: 0.02\n",
            "iteration: 410000 loss: 0.0013 lr: 0.02\n",
            "iteration: 410010 loss: 0.0018 lr: 0.02\n",
            "iteration: 410020 loss: 0.0019 lr: 0.02\n",
            "iteration: 410030 loss: 0.0016 lr: 0.02\n",
            "iteration: 410040 loss: 0.0016 lr: 0.02\n",
            "iteration: 410050 loss: 0.0018 lr: 0.02\n",
            "iteration: 410060 loss: 0.0019 lr: 0.02\n",
            "iteration: 410070 loss: 0.0020 lr: 0.02\n",
            "iteration: 410080 loss: 0.0020 lr: 0.02\n",
            "iteration: 410090 loss: 0.0016 lr: 0.02\n",
            "iteration: 410100 loss: 0.0012 lr: 0.02\n",
            "iteration: 410110 loss: 0.0015 lr: 0.02\n",
            "iteration: 410120 loss: 0.0023 lr: 0.02\n",
            "iteration: 410130 loss: 0.0013 lr: 0.02\n",
            "iteration: 410140 loss: 0.0013 lr: 0.02\n",
            "iteration: 410150 loss: 0.0018 lr: 0.02\n",
            "iteration: 410160 loss: 0.0015 lr: 0.02\n",
            "iteration: 410170 loss: 0.0017 lr: 0.02\n",
            "iteration: 410180 loss: 0.0023 lr: 0.02\n",
            "iteration: 410190 loss: 0.0015 lr: 0.02\n",
            "iteration: 410200 loss: 0.0020 lr: 0.02\n",
            "iteration: 410210 loss: 0.0014 lr: 0.02\n",
            "iteration: 410220 loss: 0.0013 lr: 0.02\n",
            "iteration: 410230 loss: 0.0021 lr: 0.02\n",
            "iteration: 410240 loss: 0.0016 lr: 0.02\n",
            "iteration: 410250 loss: 0.0017 lr: 0.02\n",
            "iteration: 410260 loss: 0.0016 lr: 0.02\n",
            "iteration: 410270 loss: 0.0014 lr: 0.02\n",
            "iteration: 410280 loss: 0.0020 lr: 0.02\n",
            "iteration: 410290 loss: 0.0015 lr: 0.02\n",
            "iteration: 410300 loss: 0.0015 lr: 0.02\n",
            "iteration: 410310 loss: 0.0023 lr: 0.02\n",
            "iteration: 410320 loss: 0.0012 lr: 0.02\n",
            "iteration: 410330 loss: 0.0019 lr: 0.02\n",
            "iteration: 410340 loss: 0.0018 lr: 0.02\n",
            "iteration: 410350 loss: 0.0015 lr: 0.02\n",
            "iteration: 410360 loss: 0.0015 lr: 0.02\n",
            "iteration: 410370 loss: 0.0014 lr: 0.02\n",
            "iteration: 410380 loss: 0.0019 lr: 0.02\n",
            "iteration: 410390 loss: 0.0016 lr: 0.02\n",
            "iteration: 410400 loss: 0.0015 lr: 0.02\n",
            "iteration: 410410 loss: 0.0014 lr: 0.02\n",
            "iteration: 410420 loss: 0.0014 lr: 0.02\n",
            "iteration: 410430 loss: 0.0023 lr: 0.02\n",
            "iteration: 410440 loss: 0.0013 lr: 0.02\n",
            "iteration: 410450 loss: 0.0014 lr: 0.02\n",
            "iteration: 410460 loss: 0.0018 lr: 0.02\n",
            "iteration: 410470 loss: 0.0013 lr: 0.02\n",
            "iteration: 410480 loss: 0.0014 lr: 0.02\n",
            "iteration: 410490 loss: 0.0016 lr: 0.02\n",
            "iteration: 410500 loss: 0.0020 lr: 0.02\n",
            "iteration: 410510 loss: 0.0014 lr: 0.02\n",
            "iteration: 410520 loss: 0.0017 lr: 0.02\n",
            "iteration: 410530 loss: 0.0018 lr: 0.02\n",
            "iteration: 410540 loss: 0.0015 lr: 0.02\n",
            "iteration: 410550 loss: 0.0014 lr: 0.02\n",
            "iteration: 410560 loss: 0.0013 lr: 0.02\n",
            "iteration: 410570 loss: 0.0018 lr: 0.02\n",
            "iteration: 410580 loss: 0.0015 lr: 0.02\n",
            "iteration: 410590 loss: 0.0013 lr: 0.02\n",
            "iteration: 410600 loss: 0.0017 lr: 0.02\n",
            "iteration: 410610 loss: 0.0010 lr: 0.02\n",
            "iteration: 410620 loss: 0.0015 lr: 0.02\n",
            "iteration: 410630 loss: 0.0010 lr: 0.02\n",
            "iteration: 410640 loss: 0.0015 lr: 0.02\n",
            "iteration: 410650 loss: 0.0013 lr: 0.02\n",
            "iteration: 410660 loss: 0.0012 lr: 0.02\n",
            "iteration: 410670 loss: 0.0014 lr: 0.02\n",
            "iteration: 410680 loss: 0.0012 lr: 0.02\n",
            "iteration: 410690 loss: 0.0017 lr: 0.02\n",
            "iteration: 410700 loss: 0.0016 lr: 0.02\n",
            "iteration: 410710 loss: 0.0014 lr: 0.02\n",
            "iteration: 410720 loss: 0.0020 lr: 0.02\n",
            "iteration: 410730 loss: 0.0021 lr: 0.02\n",
            "iteration: 410740 loss: 0.0015 lr: 0.02\n",
            "iteration: 410750 loss: 0.0012 lr: 0.02\n",
            "iteration: 410760 loss: 0.0015 lr: 0.02\n",
            "iteration: 410770 loss: 0.0016 lr: 0.02\n",
            "iteration: 410780 loss: 0.0013 lr: 0.02\n",
            "iteration: 410790 loss: 0.0015 lr: 0.02\n",
            "iteration: 410800 loss: 0.0013 lr: 0.02\n",
            "iteration: 410810 loss: 0.0019 lr: 0.02\n",
            "iteration: 410820 loss: 0.0016 lr: 0.02\n",
            "iteration: 410830 loss: 0.0016 lr: 0.02\n",
            "iteration: 410840 loss: 0.0016 lr: 0.02\n",
            "iteration: 410850 loss: 0.0023 lr: 0.02\n",
            "iteration: 410860 loss: 0.0016 lr: 0.02\n",
            "iteration: 410870 loss: 0.0013 lr: 0.02\n",
            "iteration: 410880 loss: 0.0014 lr: 0.02\n",
            "iteration: 410890 loss: 0.0011 lr: 0.02\n",
            "iteration: 410900 loss: 0.0014 lr: 0.02\n",
            "iteration: 410910 loss: 0.0016 lr: 0.02\n",
            "iteration: 410920 loss: 0.0015 lr: 0.02\n",
            "iteration: 410930 loss: 0.0013 lr: 0.02\n",
            "iteration: 410940 loss: 0.0015 lr: 0.02\n",
            "iteration: 410950 loss: 0.0010 lr: 0.02\n",
            "iteration: 410960 loss: 0.0026 lr: 0.02\n",
            "iteration: 410970 loss: 0.0014 lr: 0.02\n",
            "iteration: 410980 loss: 0.0013 lr: 0.02\n",
            "iteration: 410990 loss: 0.0010 lr: 0.02\n",
            "iteration: 411000 loss: 0.0018 lr: 0.02\n",
            "iteration: 411010 loss: 0.0016 lr: 0.02\n",
            "iteration: 411020 loss: 0.0013 lr: 0.02\n",
            "iteration: 411030 loss: 0.0016 lr: 0.02\n",
            "iteration: 411040 loss: 0.0017 lr: 0.02\n",
            "iteration: 411050 loss: 0.0028 lr: 0.02\n",
            "iteration: 411060 loss: 0.0018 lr: 0.02\n",
            "iteration: 411070 loss: 0.0016 lr: 0.02\n",
            "iteration: 411080 loss: 0.0018 lr: 0.02\n",
            "iteration: 411090 loss: 0.0015 lr: 0.02\n",
            "iteration: 411100 loss: 0.0018 lr: 0.02\n",
            "iteration: 411110 loss: 0.0011 lr: 0.02\n",
            "iteration: 411120 loss: 0.0021 lr: 0.02\n",
            "iteration: 411130 loss: 0.0017 lr: 0.02\n",
            "iteration: 411140 loss: 0.0014 lr: 0.02\n",
            "iteration: 411150 loss: 0.0015 lr: 0.02\n",
            "iteration: 411160 loss: 0.0015 lr: 0.02\n",
            "iteration: 411170 loss: 0.0009 lr: 0.02\n",
            "iteration: 411180 loss: 0.0020 lr: 0.02\n",
            "iteration: 411190 loss: 0.0016 lr: 0.02\n",
            "iteration: 411200 loss: 0.0016 lr: 0.02\n",
            "iteration: 411210 loss: 0.0016 lr: 0.02\n",
            "iteration: 411220 loss: 0.0017 lr: 0.02\n",
            "iteration: 411230 loss: 0.0020 lr: 0.02\n",
            "iteration: 411240 loss: 0.0017 lr: 0.02\n",
            "iteration: 411250 loss: 0.0014 lr: 0.02\n",
            "iteration: 411260 loss: 0.0018 lr: 0.02\n",
            "iteration: 411270 loss: 0.0014 lr: 0.02\n",
            "iteration: 411280 loss: 0.0016 lr: 0.02\n",
            "iteration: 411290 loss: 0.0013 lr: 0.02\n",
            "iteration: 411300 loss: 0.0011 lr: 0.02\n",
            "iteration: 411310 loss: 0.0029 lr: 0.02\n",
            "iteration: 411320 loss: 0.0014 lr: 0.02\n",
            "iteration: 411330 loss: 0.0016 lr: 0.02\n",
            "iteration: 411340 loss: 0.0012 lr: 0.02\n",
            "iteration: 411350 loss: 0.0009 lr: 0.02\n",
            "iteration: 411360 loss: 0.0011 lr: 0.02\n",
            "iteration: 411370 loss: 0.0013 lr: 0.02\n",
            "iteration: 411380 loss: 0.0015 lr: 0.02\n",
            "iteration: 411390 loss: 0.0017 lr: 0.02\n",
            "iteration: 411400 loss: 0.0019 lr: 0.02\n",
            "iteration: 411410 loss: 0.0017 lr: 0.02\n",
            "iteration: 411420 loss: 0.0013 lr: 0.02\n",
            "iteration: 411430 loss: 0.0017 lr: 0.02\n",
            "iteration: 411440 loss: 0.0017 lr: 0.02\n",
            "iteration: 411450 loss: 0.0015 lr: 0.02\n",
            "iteration: 411460 loss: 0.0013 lr: 0.02\n",
            "iteration: 411470 loss: 0.0016 lr: 0.02\n",
            "iteration: 411480 loss: 0.0017 lr: 0.02\n",
            "iteration: 411490 loss: 0.0019 lr: 0.02\n",
            "iteration: 411500 loss: 0.0016 lr: 0.02\n",
            "iteration: 411510 loss: 0.0021 lr: 0.02\n",
            "iteration: 411520 loss: 0.0017 lr: 0.02\n",
            "iteration: 411530 loss: 0.0015 lr: 0.02\n",
            "iteration: 411540 loss: 0.0016 lr: 0.02\n",
            "iteration: 411550 loss: 0.0017 lr: 0.02\n",
            "iteration: 411560 loss: 0.0016 lr: 0.02\n",
            "iteration: 411570 loss: 0.0018 lr: 0.02\n",
            "iteration: 411580 loss: 0.0022 lr: 0.02\n",
            "iteration: 411590 loss: 0.0019 lr: 0.02\n",
            "iteration: 411600 loss: 0.0016 lr: 0.02\n",
            "iteration: 411610 loss: 0.0016 lr: 0.02\n",
            "iteration: 411620 loss: 0.0013 lr: 0.02\n",
            "iteration: 411630 loss: 0.0013 lr: 0.02\n",
            "iteration: 411640 loss: 0.0011 lr: 0.02\n",
            "iteration: 411650 loss: 0.0017 lr: 0.02\n",
            "iteration: 411660 loss: 0.0021 lr: 0.02\n",
            "iteration: 411670 loss: 0.0018 lr: 0.02\n",
            "iteration: 411680 loss: 0.0014 lr: 0.02\n",
            "iteration: 411690 loss: 0.0014 lr: 0.02\n",
            "iteration: 411700 loss: 0.0017 lr: 0.02\n",
            "iteration: 411710 loss: 0.0020 lr: 0.02\n",
            "iteration: 411720 loss: 0.0017 lr: 0.02\n",
            "iteration: 411730 loss: 0.0023 lr: 0.02\n",
            "iteration: 411740 loss: 0.0012 lr: 0.02\n",
            "iteration: 411750 loss: 0.0015 lr: 0.02\n",
            "iteration: 411760 loss: 0.0018 lr: 0.02\n",
            "iteration: 411770 loss: 0.0017 lr: 0.02\n",
            "iteration: 411780 loss: 0.0012 lr: 0.02\n",
            "iteration: 411790 loss: 0.0012 lr: 0.02\n",
            "iteration: 411800 loss: 0.0016 lr: 0.02\n",
            "iteration: 411810 loss: 0.0015 lr: 0.02\n",
            "iteration: 411820 loss: 0.0014 lr: 0.02\n",
            "iteration: 411830 loss: 0.0013 lr: 0.02\n",
            "iteration: 411840 loss: 0.0027 lr: 0.02\n",
            "iteration: 411850 loss: 0.0016 lr: 0.02\n",
            "iteration: 411860 loss: 0.0016 lr: 0.02\n",
            "iteration: 411870 loss: 0.0015 lr: 0.02\n",
            "iteration: 411880 loss: 0.0013 lr: 0.02\n",
            "iteration: 411890 loss: 0.0013 lr: 0.02\n",
            "iteration: 411900 loss: 0.0014 lr: 0.02\n",
            "iteration: 411910 loss: 0.0014 lr: 0.02\n",
            "iteration: 411920 loss: 0.0016 lr: 0.02\n",
            "iteration: 411930 loss: 0.0011 lr: 0.02\n",
            "iteration: 411940 loss: 0.0011 lr: 0.02\n",
            "iteration: 411950 loss: 0.0016 lr: 0.02\n",
            "iteration: 411960 loss: 0.0014 lr: 0.02\n",
            "iteration: 411970 loss: 0.0018 lr: 0.02\n",
            "iteration: 411980 loss: 0.0014 lr: 0.02\n",
            "iteration: 411990 loss: 0.0011 lr: 0.02\n",
            "iteration: 412000 loss: 0.0015 lr: 0.02\n",
            "iteration: 412010 loss: 0.0017 lr: 0.02\n",
            "iteration: 412020 loss: 0.0017 lr: 0.02\n",
            "iteration: 412030 loss: 0.0015 lr: 0.02\n",
            "iteration: 412040 loss: 0.0017 lr: 0.02\n",
            "iteration: 412050 loss: 0.0018 lr: 0.02\n",
            "iteration: 412060 loss: 0.0017 lr: 0.02\n",
            "iteration: 412070 loss: 0.0011 lr: 0.02\n",
            "iteration: 412080 loss: 0.0010 lr: 0.02\n",
            "iteration: 412090 loss: 0.0015 lr: 0.02\n",
            "iteration: 412100 loss: 0.0012 lr: 0.02\n",
            "iteration: 412110 loss: 0.0013 lr: 0.02\n",
            "iteration: 412120 loss: 0.0014 lr: 0.02\n",
            "iteration: 412130 loss: 0.0012 lr: 0.02\n",
            "iteration: 412140 loss: 0.0014 lr: 0.02\n",
            "iteration: 412150 loss: 0.0014 lr: 0.02\n",
            "iteration: 412160 loss: 0.0013 lr: 0.02\n",
            "iteration: 412170 loss: 0.0013 lr: 0.02\n",
            "iteration: 412180 loss: 0.0016 lr: 0.02\n",
            "iteration: 412190 loss: 0.0016 lr: 0.02\n",
            "iteration: 412200 loss: 0.0022 lr: 0.02\n",
            "iteration: 412210 loss: 0.0024 lr: 0.02\n",
            "iteration: 412220 loss: 0.0018 lr: 0.02\n",
            "iteration: 412230 loss: 0.0015 lr: 0.02\n",
            "iteration: 412240 loss: 0.0017 lr: 0.02\n",
            "iteration: 412250 loss: 0.0013 lr: 0.02\n",
            "iteration: 412260 loss: 0.0017 lr: 0.02\n",
            "iteration: 412270 loss: 0.0020 lr: 0.02\n",
            "iteration: 412280 loss: 0.0018 lr: 0.02\n",
            "iteration: 412290 loss: 0.0015 lr: 0.02\n",
            "iteration: 412300 loss: 0.0013 lr: 0.02\n",
            "iteration: 412310 loss: 0.0016 lr: 0.02\n",
            "iteration: 412320 loss: 0.0016 lr: 0.02\n",
            "iteration: 412330 loss: 0.0014 lr: 0.02\n",
            "iteration: 412340 loss: 0.0015 lr: 0.02\n",
            "iteration: 412350 loss: 0.0013 lr: 0.02\n",
            "iteration: 412360 loss: 0.0013 lr: 0.02\n",
            "iteration: 412370 loss: 0.0016 lr: 0.02\n",
            "iteration: 412380 loss: 0.0022 lr: 0.02\n",
            "iteration: 412390 loss: 0.0018 lr: 0.02\n",
            "iteration: 412400 loss: 0.0014 lr: 0.02\n",
            "iteration: 412410 loss: 0.0019 lr: 0.02\n",
            "iteration: 412420 loss: 0.0015 lr: 0.02\n",
            "iteration: 412430 loss: 0.0016 lr: 0.02\n",
            "iteration: 412440 loss: 0.0019 lr: 0.02\n",
            "iteration: 412450 loss: 0.0013 lr: 0.02\n",
            "iteration: 412460 loss: 0.0011 lr: 0.02\n",
            "iteration: 412470 loss: 0.0016 lr: 0.02\n",
            "iteration: 412480 loss: 0.0012 lr: 0.02\n",
            "iteration: 412490 loss: 0.0019 lr: 0.02\n",
            "iteration: 412500 loss: 0.0016 lr: 0.02\n",
            "iteration: 412510 loss: 0.0015 lr: 0.02\n",
            "iteration: 412520 loss: 0.0015 lr: 0.02\n",
            "iteration: 412530 loss: 0.0013 lr: 0.02\n",
            "iteration: 412540 loss: 0.0015 lr: 0.02\n",
            "iteration: 412550 loss: 0.0018 lr: 0.02\n",
            "iteration: 412560 loss: 0.0013 lr: 0.02\n",
            "iteration: 412570 loss: 0.0017 lr: 0.02\n",
            "iteration: 412580 loss: 0.0019 lr: 0.02\n",
            "iteration: 412590 loss: 0.0012 lr: 0.02\n",
            "iteration: 412600 loss: 0.0016 lr: 0.02\n",
            "iteration: 412610 loss: 0.0012 lr: 0.02\n",
            "iteration: 412620 loss: 0.0023 lr: 0.02\n",
            "iteration: 412630 loss: 0.0013 lr: 0.02\n",
            "iteration: 412640 loss: 0.0013 lr: 0.02\n",
            "iteration: 412650 loss: 0.0024 lr: 0.02\n",
            "iteration: 412660 loss: 0.0011 lr: 0.02\n",
            "iteration: 412670 loss: 0.0018 lr: 0.02\n",
            "iteration: 412680 loss: 0.0012 lr: 0.02\n",
            "iteration: 412690 loss: 0.0018 lr: 0.02\n",
            "iteration: 412700 loss: 0.0014 lr: 0.02\n",
            "iteration: 412710 loss: 0.0022 lr: 0.02\n",
            "iteration: 412720 loss: 0.0015 lr: 0.02\n",
            "iteration: 412730 loss: 0.0017 lr: 0.02\n",
            "iteration: 412740 loss: 0.0016 lr: 0.02\n",
            "iteration: 412750 loss: 0.0015 lr: 0.02\n",
            "iteration: 412760 loss: 0.0015 lr: 0.02\n",
            "iteration: 412770 loss: 0.0010 lr: 0.02\n",
            "iteration: 412780 loss: 0.0014 lr: 0.02\n",
            "iteration: 412790 loss: 0.0015 lr: 0.02\n",
            "iteration: 412800 loss: 0.0012 lr: 0.02\n",
            "iteration: 412810 loss: 0.0017 lr: 0.02\n",
            "iteration: 412820 loss: 0.0016 lr: 0.02\n",
            "iteration: 412830 loss: 0.0013 lr: 0.02\n",
            "iteration: 412840 loss: 0.0012 lr: 0.02\n",
            "iteration: 412850 loss: 0.0015 lr: 0.02\n",
            "iteration: 412860 loss: 0.0017 lr: 0.02\n",
            "iteration: 412870 loss: 0.0013 lr: 0.02\n",
            "iteration: 412880 loss: 0.0019 lr: 0.02\n",
            "iteration: 412890 loss: 0.0015 lr: 0.02\n",
            "iteration: 412900 loss: 0.0014 lr: 0.02\n",
            "iteration: 412910 loss: 0.0020 lr: 0.02\n",
            "iteration: 412920 loss: 0.0017 lr: 0.02\n",
            "iteration: 412930 loss: 0.0016 lr: 0.02\n",
            "iteration: 412940 loss: 0.0017 lr: 0.02\n",
            "iteration: 412950 loss: 0.0013 lr: 0.02\n",
            "iteration: 412960 loss: 0.0014 lr: 0.02\n",
            "iteration: 412970 loss: 0.0012 lr: 0.02\n",
            "iteration: 412980 loss: 0.0012 lr: 0.02\n",
            "iteration: 412990 loss: 0.0016 lr: 0.02\n",
            "iteration: 413000 loss: 0.0010 lr: 0.02\n",
            "iteration: 413010 loss: 0.0014 lr: 0.02\n",
            "iteration: 413020 loss: 0.0010 lr: 0.02\n",
            "iteration: 413030 loss: 0.0017 lr: 0.02\n",
            "iteration: 413040 loss: 0.0016 lr: 0.02\n",
            "iteration: 413050 loss: 0.0017 lr: 0.02\n",
            "iteration: 413060 loss: 0.0016 lr: 0.02\n",
            "iteration: 413070 loss: 0.0019 lr: 0.02\n",
            "iteration: 413080 loss: 0.0015 lr: 0.02\n",
            "iteration: 413090 loss: 0.0014 lr: 0.02\n",
            "iteration: 413100 loss: 0.0019 lr: 0.02\n",
            "iteration: 413110 loss: 0.0013 lr: 0.02\n",
            "iteration: 413120 loss: 0.0022 lr: 0.02\n",
            "iteration: 413130 loss: 0.0018 lr: 0.02\n",
            "iteration: 413140 loss: 0.0019 lr: 0.02\n",
            "iteration: 413150 loss: 0.0018 lr: 0.02\n",
            "iteration: 413160 loss: 0.0017 lr: 0.02\n",
            "iteration: 413170 loss: 0.0013 lr: 0.02\n",
            "iteration: 413180 loss: 0.0015 lr: 0.02\n",
            "iteration: 413190 loss: 0.0015 lr: 0.02\n",
            "iteration: 413200 loss: 0.0014 lr: 0.02\n",
            "iteration: 413210 loss: 0.0023 lr: 0.02\n",
            "iteration: 413220 loss: 0.0015 lr: 0.02\n",
            "iteration: 413230 loss: 0.0022 lr: 0.02\n",
            "iteration: 413240 loss: 0.0017 lr: 0.02\n",
            "iteration: 413250 loss: 0.0012 lr: 0.02\n",
            "iteration: 413260 loss: 0.0013 lr: 0.02\n",
            "iteration: 413270 loss: 0.0019 lr: 0.02\n",
            "iteration: 413280 loss: 0.0013 lr: 0.02\n",
            "iteration: 413290 loss: 0.0016 lr: 0.02\n",
            "iteration: 413300 loss: 0.0016 lr: 0.02\n",
            "iteration: 413310 loss: 0.0017 lr: 0.02\n",
            "iteration: 413320 loss: 0.0018 lr: 0.02\n",
            "iteration: 413330 loss: 0.0014 lr: 0.02\n",
            "iteration: 413340 loss: 0.0021 lr: 0.02\n",
            "iteration: 413350 loss: 0.0016 lr: 0.02\n",
            "iteration: 413360 loss: 0.0013 lr: 0.02\n",
            "iteration: 413370 loss: 0.0014 lr: 0.02\n",
            "iteration: 413380 loss: 0.0014 lr: 0.02\n",
            "iteration: 413390 loss: 0.0015 lr: 0.02\n",
            "iteration: 413400 loss: 0.0018 lr: 0.02\n",
            "iteration: 413410 loss: 0.0012 lr: 0.02\n",
            "iteration: 413420 loss: 0.0022 lr: 0.02\n",
            "iteration: 413430 loss: 0.0021 lr: 0.02\n",
            "iteration: 413440 loss: 0.0017 lr: 0.02\n",
            "iteration: 413450 loss: 0.0017 lr: 0.02\n",
            "iteration: 413460 loss: 0.0016 lr: 0.02\n",
            "iteration: 413470 loss: 0.0016 lr: 0.02\n",
            "iteration: 413480 loss: 0.0015 lr: 0.02\n",
            "iteration: 413490 loss: 0.0016 lr: 0.02\n",
            "iteration: 413500 loss: 0.0015 lr: 0.02\n",
            "iteration: 413510 loss: 0.0013 lr: 0.02\n",
            "iteration: 413520 loss: 0.0020 lr: 0.02\n",
            "iteration: 413530 loss: 0.0016 lr: 0.02\n",
            "iteration: 413540 loss: 0.0011 lr: 0.02\n",
            "iteration: 413550 loss: 0.0015 lr: 0.02\n",
            "iteration: 413560 loss: 0.0017 lr: 0.02\n",
            "iteration: 413570 loss: 0.0015 lr: 0.02\n",
            "iteration: 413580 loss: 0.0016 lr: 0.02\n",
            "iteration: 413590 loss: 0.0015 lr: 0.02\n",
            "iteration: 413600 loss: 0.0016 lr: 0.02\n",
            "iteration: 413610 loss: 0.0016 lr: 0.02\n",
            "iteration: 413620 loss: 0.0020 lr: 0.02\n",
            "iteration: 413630 loss: 0.0017 lr: 0.02\n",
            "iteration: 413640 loss: 0.0019 lr: 0.02\n",
            "iteration: 413650 loss: 0.0016 lr: 0.02\n",
            "iteration: 413660 loss: 0.0015 lr: 0.02\n",
            "iteration: 413670 loss: 0.0018 lr: 0.02\n",
            "iteration: 413680 loss: 0.0014 lr: 0.02\n",
            "iteration: 413690 loss: 0.0017 lr: 0.02\n",
            "iteration: 413700 loss: 0.0014 lr: 0.02\n",
            "iteration: 413710 loss: 0.0013 lr: 0.02\n",
            "iteration: 413720 loss: 0.0021 lr: 0.02\n",
            "iteration: 413730 loss: 0.0022 lr: 0.02\n",
            "iteration: 413740 loss: 0.0018 lr: 0.02\n",
            "iteration: 413750 loss: 0.0015 lr: 0.02\n",
            "iteration: 413760 loss: 0.0013 lr: 0.02\n",
            "iteration: 413770 loss: 0.0018 lr: 0.02\n",
            "iteration: 413780 loss: 0.0018 lr: 0.02\n",
            "iteration: 413790 loss: 0.0012 lr: 0.02\n",
            "iteration: 413800 loss: 0.0015 lr: 0.02\n",
            "iteration: 413810 loss: 0.0020 lr: 0.02\n",
            "iteration: 413820 loss: 0.0013 lr: 0.02\n",
            "iteration: 413830 loss: 0.0017 lr: 0.02\n",
            "iteration: 413840 loss: 0.0016 lr: 0.02\n",
            "iteration: 413850 loss: 0.0018 lr: 0.02\n",
            "iteration: 413860 loss: 0.0017 lr: 0.02\n",
            "iteration: 413870 loss: 0.0018 lr: 0.02\n",
            "iteration: 413880 loss: 0.0020 lr: 0.02\n",
            "iteration: 413890 loss: 0.0014 lr: 0.02\n",
            "iteration: 413900 loss: 0.0014 lr: 0.02\n",
            "iteration: 413910 loss: 0.0012 lr: 0.02\n",
            "iteration: 413920 loss: 0.0016 lr: 0.02\n",
            "iteration: 413930 loss: 0.0009 lr: 0.02\n",
            "iteration: 413940 loss: 0.0017 lr: 0.02\n",
            "iteration: 413950 loss: 0.0013 lr: 0.02\n",
            "iteration: 413960 loss: 0.0012 lr: 0.02\n",
            "iteration: 413970 loss: 0.0014 lr: 0.02\n",
            "iteration: 413980 loss: 0.0015 lr: 0.02\n",
            "iteration: 413990 loss: 0.0022 lr: 0.02\n",
            "iteration: 414000 loss: 0.0015 lr: 0.02\n",
            "iteration: 414010 loss: 0.0016 lr: 0.02\n",
            "iteration: 414020 loss: 0.0022 lr: 0.02\n",
            "iteration: 414030 loss: 0.0017 lr: 0.02\n",
            "iteration: 414040 loss: 0.0018 lr: 0.02\n",
            "iteration: 414050 loss: 0.0013 lr: 0.02\n",
            "iteration: 414060 loss: 0.0023 lr: 0.02\n",
            "iteration: 414070 loss: 0.0022 lr: 0.02\n",
            "iteration: 414080 loss: 0.0018 lr: 0.02\n",
            "iteration: 414090 loss: 0.0016 lr: 0.02\n",
            "iteration: 414100 loss: 0.0018 lr: 0.02\n",
            "iteration: 414110 loss: 0.0017 lr: 0.02\n",
            "iteration: 414120 loss: 0.0014 lr: 0.02\n",
            "iteration: 414130 loss: 0.0015 lr: 0.02\n",
            "iteration: 414140 loss: 0.0017 lr: 0.02\n",
            "iteration: 414150 loss: 0.0020 lr: 0.02\n",
            "iteration: 414160 loss: 0.0022 lr: 0.02\n",
            "iteration: 414170 loss: 0.0034 lr: 0.02\n",
            "iteration: 414180 loss: 0.0017 lr: 0.02\n",
            "iteration: 414190 loss: 0.0018 lr: 0.02\n",
            "iteration: 414200 loss: 0.0017 lr: 0.02\n",
            "iteration: 414210 loss: 0.0020 lr: 0.02\n",
            "iteration: 414220 loss: 0.0018 lr: 0.02\n",
            "iteration: 414230 loss: 0.0014 lr: 0.02\n",
            "iteration: 414240 loss: 0.0017 lr: 0.02\n",
            "iteration: 414250 loss: 0.0018 lr: 0.02\n",
            "iteration: 414260 loss: 0.0015 lr: 0.02\n",
            "iteration: 414270 loss: 0.0012 lr: 0.02\n",
            "iteration: 414280 loss: 0.0016 lr: 0.02\n",
            "iteration: 414290 loss: 0.0013 lr: 0.02\n",
            "iteration: 414300 loss: 0.0015 lr: 0.02\n",
            "iteration: 414310 loss: 0.0016 lr: 0.02\n",
            "iteration: 414320 loss: 0.0016 lr: 0.02\n",
            "iteration: 414330 loss: 0.0018 lr: 0.02\n",
            "iteration: 414340 loss: 0.0013 lr: 0.02\n",
            "iteration: 414350 loss: 0.0011 lr: 0.02\n",
            "iteration: 414360 loss: 0.0019 lr: 0.02\n",
            "iteration: 414370 loss: 0.0016 lr: 0.02\n",
            "iteration: 414380 loss: 0.0015 lr: 0.02\n",
            "iteration: 414390 loss: 0.0018 lr: 0.02\n",
            "iteration: 414400 loss: 0.0017 lr: 0.02\n",
            "iteration: 414410 loss: 0.0016 lr: 0.02\n",
            "iteration: 414420 loss: 0.0015 lr: 0.02\n",
            "iteration: 414430 loss: 0.0018 lr: 0.02\n",
            "iteration: 414440 loss: 0.0017 lr: 0.02\n",
            "iteration: 414450 loss: 0.0013 lr: 0.02\n",
            "iteration: 414460 loss: 0.0015 lr: 0.02\n",
            "iteration: 414470 loss: 0.0013 lr: 0.02\n",
            "iteration: 414480 loss: 0.0020 lr: 0.02\n",
            "iteration: 414490 loss: 0.0020 lr: 0.02\n",
            "iteration: 414500 loss: 0.0015 lr: 0.02\n",
            "iteration: 414510 loss: 0.0014 lr: 0.02\n",
            "iteration: 414520 loss: 0.0018 lr: 0.02\n",
            "iteration: 414530 loss: 0.0014 lr: 0.02\n",
            "iteration: 414540 loss: 0.0013 lr: 0.02\n",
            "iteration: 414550 loss: 0.0017 lr: 0.02\n",
            "iteration: 414560 loss: 0.0015 lr: 0.02\n",
            "iteration: 414570 loss: 0.0015 lr: 0.02\n",
            "iteration: 414580 loss: 0.0020 lr: 0.02\n",
            "iteration: 414590 loss: 0.0013 lr: 0.02\n",
            "iteration: 414600 loss: 0.0015 lr: 0.02\n",
            "iteration: 414610 loss: 0.0015 lr: 0.02\n",
            "iteration: 414620 loss: 0.0018 lr: 0.02\n",
            "iteration: 414630 loss: 0.0012 lr: 0.02\n",
            "iteration: 414640 loss: 0.0015 lr: 0.02\n",
            "iteration: 414650 loss: 0.0017 lr: 0.02\n",
            "iteration: 414660 loss: 0.0015 lr: 0.02\n",
            "iteration: 414670 loss: 0.0012 lr: 0.02\n",
            "iteration: 414680 loss: 0.0010 lr: 0.02\n",
            "iteration: 414690 loss: 0.0019 lr: 0.02\n",
            "iteration: 414700 loss: 0.0014 lr: 0.02\n",
            "iteration: 414710 loss: 0.0014 lr: 0.02\n",
            "iteration: 414720 loss: 0.0033 lr: 0.02\n",
            "iteration: 414730 loss: 0.0018 lr: 0.02\n",
            "iteration: 414740 loss: 0.0013 lr: 0.02\n",
            "iteration: 414750 loss: 0.0018 lr: 0.02\n",
            "iteration: 414760 loss: 0.0017 lr: 0.02\n",
            "iteration: 414770 loss: 0.0017 lr: 0.02\n",
            "iteration: 414780 loss: 0.0015 lr: 0.02\n",
            "iteration: 414790 loss: 0.0021 lr: 0.02\n",
            "iteration: 414800 loss: 0.0015 lr: 0.02\n",
            "iteration: 414810 loss: 0.0016 lr: 0.02\n",
            "iteration: 414820 loss: 0.0016 lr: 0.02\n",
            "iteration: 414830 loss: 0.0019 lr: 0.02\n",
            "iteration: 414840 loss: 0.0021 lr: 0.02\n",
            "iteration: 414850 loss: 0.0021 lr: 0.02\n",
            "iteration: 414860 loss: 0.0019 lr: 0.02\n",
            "iteration: 414870 loss: 0.0017 lr: 0.02\n",
            "iteration: 414880 loss: 0.0015 lr: 0.02\n",
            "iteration: 414890 loss: 0.0023 lr: 0.02\n",
            "iteration: 414900 loss: 0.0015 lr: 0.02\n",
            "iteration: 414910 loss: 0.0014 lr: 0.02\n",
            "iteration: 414920 loss: 0.0018 lr: 0.02\n",
            "iteration: 414930 loss: 0.0013 lr: 0.02\n",
            "iteration: 414940 loss: 0.0014 lr: 0.02\n",
            "iteration: 414950 loss: 0.0015 lr: 0.02\n",
            "iteration: 414960 loss: 0.0017 lr: 0.02\n",
            "iteration: 414970 loss: 0.0024 lr: 0.02\n",
            "iteration: 414980 loss: 0.0016 lr: 0.02\n",
            "iteration: 414990 loss: 0.0014 lr: 0.02\n",
            "iteration: 415000 loss: 0.0014 lr: 0.02\n",
            "iteration: 415010 loss: 0.0014 lr: 0.02\n",
            "iteration: 415020 loss: 0.0014 lr: 0.02\n",
            "iteration: 415030 loss: 0.0015 lr: 0.02\n",
            "iteration: 415040 loss: 0.0016 lr: 0.02\n",
            "iteration: 415050 loss: 0.0013 lr: 0.02\n",
            "iteration: 415060 loss: 0.0016 lr: 0.02\n",
            "iteration: 415070 loss: 0.0020 lr: 0.02\n",
            "iteration: 415080 loss: 0.0016 lr: 0.02\n",
            "iteration: 415090 loss: 0.0015 lr: 0.02\n",
            "iteration: 415100 loss: 0.0019 lr: 0.02\n",
            "iteration: 415110 loss: 0.0018 lr: 0.02\n",
            "iteration: 415120 loss: 0.0015 lr: 0.02\n",
            "iteration: 415130 loss: 0.0014 lr: 0.02\n",
            "iteration: 415140 loss: 0.0017 lr: 0.02\n",
            "iteration: 415150 loss: 0.0016 lr: 0.02\n",
            "iteration: 415160 loss: 0.0013 lr: 0.02\n",
            "iteration: 415170 loss: 0.0015 lr: 0.02\n",
            "iteration: 415180 loss: 0.0013 lr: 0.02\n",
            "iteration: 415190 loss: 0.0013 lr: 0.02\n",
            "iteration: 415200 loss: 0.0015 lr: 0.02\n",
            "iteration: 415210 loss: 0.0014 lr: 0.02\n",
            "iteration: 415220 loss: 0.0015 lr: 0.02\n",
            "iteration: 415230 loss: 0.0028 lr: 0.02\n",
            "iteration: 415240 loss: 0.0015 lr: 0.02\n",
            "iteration: 415250 loss: 0.0020 lr: 0.02\n",
            "iteration: 415260 loss: 0.0011 lr: 0.02\n",
            "iteration: 415270 loss: 0.0013 lr: 0.02\n",
            "iteration: 415280 loss: 0.0016 lr: 0.02\n",
            "iteration: 415290 loss: 0.0013 lr: 0.02\n",
            "iteration: 415300 loss: 0.0012 lr: 0.02\n",
            "iteration: 415310 loss: 0.0017 lr: 0.02\n",
            "iteration: 415320 loss: 0.0013 lr: 0.02\n",
            "iteration: 415330 loss: 0.0019 lr: 0.02\n",
            "iteration: 415340 loss: 0.0011 lr: 0.02\n",
            "iteration: 415350 loss: 0.0017 lr: 0.02\n",
            "iteration: 415360 loss: 0.0022 lr: 0.02\n",
            "iteration: 415370 loss: 0.0019 lr: 0.02\n",
            "iteration: 415380 loss: 0.0018 lr: 0.02\n",
            "iteration: 415390 loss: 0.0016 lr: 0.02\n",
            "iteration: 415400 loss: 0.0016 lr: 0.02\n",
            "iteration: 415410 loss: 0.0013 lr: 0.02\n",
            "iteration: 415420 loss: 0.0015 lr: 0.02\n",
            "iteration: 415430 loss: 0.0013 lr: 0.02\n",
            "iteration: 415440 loss: 0.0015 lr: 0.02\n",
            "iteration: 415450 loss: 0.0014 lr: 0.02\n",
            "iteration: 415460 loss: 0.0020 lr: 0.02\n",
            "iteration: 415470 loss: 0.0017 lr: 0.02\n",
            "iteration: 415480 loss: 0.0024 lr: 0.02\n",
            "iteration: 415490 loss: 0.0015 lr: 0.02\n",
            "iteration: 415500 loss: 0.0018 lr: 0.02\n",
            "iteration: 415510 loss: 0.0015 lr: 0.02\n",
            "iteration: 415520 loss: 0.0015 lr: 0.02\n",
            "iteration: 415530 loss: 0.0018 lr: 0.02\n",
            "iteration: 415540 loss: 0.0018 lr: 0.02\n",
            "iteration: 415550 loss: 0.0022 lr: 0.02\n",
            "iteration: 415560 loss: 0.0018 lr: 0.02\n",
            "iteration: 415570 loss: 0.0014 lr: 0.02\n",
            "iteration: 415580 loss: 0.0012 lr: 0.02\n",
            "iteration: 415590 loss: 0.0015 lr: 0.02\n",
            "iteration: 415600 loss: 0.0014 lr: 0.02\n",
            "iteration: 415610 loss: 0.0023 lr: 0.02\n",
            "iteration: 415620 loss: 0.0019 lr: 0.02\n",
            "iteration: 415630 loss: 0.0020 lr: 0.02\n",
            "iteration: 415640 loss: 0.0016 lr: 0.02\n",
            "iteration: 415650 loss: 0.0016 lr: 0.02\n",
            "iteration: 415660 loss: 0.0013 lr: 0.02\n",
            "iteration: 415670 loss: 0.0016 lr: 0.02\n",
            "iteration: 415680 loss: 0.0013 lr: 0.02\n",
            "iteration: 415690 loss: 0.0022 lr: 0.02\n",
            "iteration: 415700 loss: 0.0018 lr: 0.02\n",
            "iteration: 415710 loss: 0.0013 lr: 0.02\n",
            "iteration: 415720 loss: 0.0012 lr: 0.02\n",
            "iteration: 415730 loss: 0.0021 lr: 0.02\n",
            "iteration: 415740 loss: 0.0020 lr: 0.02\n",
            "iteration: 415750 loss: 0.0021 lr: 0.02\n",
            "iteration: 415760 loss: 0.0020 lr: 0.02\n",
            "iteration: 415770 loss: 0.0014 lr: 0.02\n",
            "iteration: 415780 loss: 0.0020 lr: 0.02\n",
            "iteration: 415790 loss: 0.0012 lr: 0.02\n",
            "iteration: 415800 loss: 0.0014 lr: 0.02\n",
            "iteration: 415810 loss: 0.0018 lr: 0.02\n",
            "iteration: 415820 loss: 0.0022 lr: 0.02\n",
            "iteration: 415830 loss: 0.0016 lr: 0.02\n",
            "iteration: 415840 loss: 0.0016 lr: 0.02\n",
            "iteration: 415850 loss: 0.0014 lr: 0.02\n",
            "iteration: 415860 loss: 0.0012 lr: 0.02\n",
            "iteration: 415870 loss: 0.0014 lr: 0.02\n",
            "iteration: 415880 loss: 0.0016 lr: 0.02\n",
            "iteration: 415890 loss: 0.0020 lr: 0.02\n",
            "iteration: 415900 loss: 0.0017 lr: 0.02\n",
            "iteration: 415910 loss: 0.0012 lr: 0.02\n",
            "iteration: 415920 loss: 0.0016 lr: 0.02\n",
            "iteration: 415930 loss: 0.0013 lr: 0.02\n",
            "iteration: 415940 loss: 0.0019 lr: 0.02\n",
            "iteration: 415950 loss: 0.0025 lr: 0.02\n",
            "iteration: 415960 loss: 0.0014 lr: 0.02\n",
            "iteration: 415970 loss: 0.0011 lr: 0.02\n",
            "iteration: 415980 loss: 0.0021 lr: 0.02\n",
            "iteration: 415990 loss: 0.0012 lr: 0.02\n",
            "iteration: 416000 loss: 0.0016 lr: 0.02\n",
            "iteration: 416010 loss: 0.0014 lr: 0.02\n",
            "iteration: 416020 loss: 0.0015 lr: 0.02\n",
            "iteration: 416030 loss: 0.0018 lr: 0.02\n",
            "iteration: 416040 loss: 0.0019 lr: 0.02\n",
            "iteration: 416050 loss: 0.0014 lr: 0.02\n",
            "iteration: 416060 loss: 0.0016 lr: 0.02\n",
            "iteration: 416070 loss: 0.0019 lr: 0.02\n",
            "iteration: 416080 loss: 0.0016 lr: 0.02\n",
            "iteration: 416090 loss: 0.0012 lr: 0.02\n",
            "iteration: 416100 loss: 0.0015 lr: 0.02\n",
            "iteration: 416110 loss: 0.0016 lr: 0.02\n",
            "iteration: 416120 loss: 0.0016 lr: 0.02\n",
            "iteration: 416130 loss: 0.0010 lr: 0.02\n",
            "iteration: 416140 loss: 0.0014 lr: 0.02\n",
            "iteration: 416150 loss: 0.0018 lr: 0.02\n",
            "iteration: 416160 loss: 0.0015 lr: 0.02\n",
            "iteration: 416170 loss: 0.0019 lr: 0.02\n",
            "iteration: 416180 loss: 0.0016 lr: 0.02\n",
            "iteration: 416190 loss: 0.0013 lr: 0.02\n",
            "iteration: 416200 loss: 0.0020 lr: 0.02\n",
            "iteration: 416210 loss: 0.0016 lr: 0.02\n",
            "iteration: 416220 loss: 0.0023 lr: 0.02\n",
            "iteration: 416230 loss: 0.0016 lr: 0.02\n",
            "iteration: 416240 loss: 0.0013 lr: 0.02\n",
            "iteration: 416250 loss: 0.0017 lr: 0.02\n",
            "iteration: 416260 loss: 0.0022 lr: 0.02\n",
            "iteration: 416270 loss: 0.0021 lr: 0.02\n",
            "iteration: 416280 loss: 0.0013 lr: 0.02\n",
            "iteration: 416290 loss: 0.0016 lr: 0.02\n",
            "iteration: 416300 loss: 0.0017 lr: 0.02\n",
            "iteration: 416310 loss: 0.0015 lr: 0.02\n",
            "iteration: 416320 loss: 0.0015 lr: 0.02\n",
            "iteration: 416330 loss: 0.0018 lr: 0.02\n",
            "iteration: 416340 loss: 0.0016 lr: 0.02\n",
            "iteration: 416350 loss: 0.0016 lr: 0.02\n",
            "iteration: 416360 loss: 0.0014 lr: 0.02\n",
            "iteration: 416370 loss: 0.0032 lr: 0.02\n",
            "iteration: 416380 loss: 0.0015 lr: 0.02\n",
            "iteration: 416390 loss: 0.0017 lr: 0.02\n",
            "iteration: 416400 loss: 0.0013 lr: 0.02\n",
            "iteration: 416410 loss: 0.0017 lr: 0.02\n",
            "iteration: 416420 loss: 0.0018 lr: 0.02\n",
            "iteration: 416430 loss: 0.0015 lr: 0.02\n",
            "iteration: 416440 loss: 0.0018 lr: 0.02\n",
            "iteration: 416450 loss: 0.0029 lr: 0.02\n",
            "iteration: 416460 loss: 0.0014 lr: 0.02\n",
            "iteration: 416470 loss: 0.0016 lr: 0.02\n",
            "iteration: 416480 loss: 0.0019 lr: 0.02\n",
            "iteration: 416490 loss: 0.0018 lr: 0.02\n",
            "iteration: 416500 loss: 0.0017 lr: 0.02\n",
            "iteration: 416510 loss: 0.0015 lr: 0.02\n",
            "iteration: 416520 loss: 0.0015 lr: 0.02\n",
            "iteration: 416530 loss: 0.0010 lr: 0.02\n",
            "iteration: 416540 loss: 0.0019 lr: 0.02\n",
            "iteration: 416550 loss: 0.0018 lr: 0.02\n",
            "iteration: 416560 loss: 0.0015 lr: 0.02\n",
            "iteration: 416570 loss: 0.0019 lr: 0.02\n",
            "iteration: 416580 loss: 0.0027 lr: 0.02\n",
            "iteration: 416590 loss: 0.0018 lr: 0.02\n",
            "iteration: 416600 loss: 0.0014 lr: 0.02\n",
            "iteration: 416610 loss: 0.0013 lr: 0.02\n",
            "iteration: 416620 loss: 0.0017 lr: 0.02\n",
            "iteration: 416630 loss: 0.0026 lr: 0.02\n",
            "iteration: 416640 loss: 0.0018 lr: 0.02\n",
            "iteration: 416650 loss: 0.0012 lr: 0.02\n",
            "iteration: 416660 loss: 0.0017 lr: 0.02\n",
            "iteration: 416670 loss: 0.0012 lr: 0.02\n",
            "iteration: 416680 loss: 0.0016 lr: 0.02\n",
            "iteration: 416690 loss: 0.0017 lr: 0.02\n",
            "iteration: 416700 loss: 0.0020 lr: 0.02\n",
            "iteration: 416710 loss: 0.0015 lr: 0.02\n",
            "iteration: 416720 loss: 0.0016 lr: 0.02\n",
            "iteration: 416730 loss: 0.0018 lr: 0.02\n",
            "iteration: 416740 loss: 0.0017 lr: 0.02\n",
            "iteration: 416750 loss: 0.0017 lr: 0.02\n",
            "iteration: 416760 loss: 0.0015 lr: 0.02\n",
            "iteration: 416770 loss: 0.0022 lr: 0.02\n",
            "iteration: 416780 loss: 0.0020 lr: 0.02\n",
            "iteration: 416790 loss: 0.0013 lr: 0.02\n",
            "iteration: 416800 loss: 0.0018 lr: 0.02\n",
            "iteration: 416810 loss: 0.0018 lr: 0.02\n",
            "iteration: 416820 loss: 0.0018 lr: 0.02\n",
            "iteration: 416830 loss: 0.0032 lr: 0.02\n",
            "iteration: 416840 loss: 0.0020 lr: 0.02\n",
            "iteration: 416850 loss: 0.0021 lr: 0.02\n",
            "iteration: 416860 loss: 0.0012 lr: 0.02\n",
            "iteration: 416870 loss: 0.0013 lr: 0.02\n",
            "iteration: 416880 loss: 0.0021 lr: 0.02\n",
            "iteration: 416890 loss: 0.0020 lr: 0.02\n",
            "iteration: 416900 loss: 0.0014 lr: 0.02\n",
            "iteration: 416910 loss: 0.0018 lr: 0.02\n",
            "iteration: 416920 loss: 0.0017 lr: 0.02\n",
            "iteration: 416930 loss: 0.0018 lr: 0.02\n",
            "iteration: 416940 loss: 0.0013 lr: 0.02\n",
            "iteration: 416950 loss: 0.0012 lr: 0.02\n",
            "iteration: 416960 loss: 0.0018 lr: 0.02\n",
            "iteration: 416970 loss: 0.0016 lr: 0.02\n",
            "iteration: 416980 loss: 0.0016 lr: 0.02\n",
            "iteration: 416990 loss: 0.0020 lr: 0.02\n",
            "iteration: 417000 loss: 0.0014 lr: 0.02\n",
            "iteration: 417010 loss: 0.0018 lr: 0.02\n",
            "iteration: 417020 loss: 0.0017 lr: 0.02\n",
            "iteration: 417030 loss: 0.0017 lr: 0.02\n",
            "iteration: 417040 loss: 0.0013 lr: 0.02\n",
            "iteration: 417050 loss: 0.0019 lr: 0.02\n",
            "iteration: 417060 loss: 0.0015 lr: 0.02\n",
            "iteration: 417070 loss: 0.0015 lr: 0.02\n",
            "iteration: 417080 loss: 0.0018 lr: 0.02\n",
            "iteration: 417090 loss: 0.0015 lr: 0.02\n",
            "iteration: 417100 loss: 0.0015 lr: 0.02\n",
            "iteration: 417110 loss: 0.0014 lr: 0.02\n",
            "iteration: 417120 loss: 0.0014 lr: 0.02\n",
            "iteration: 417130 loss: 0.0011 lr: 0.02\n",
            "iteration: 417140 loss: 0.0019 lr: 0.02\n",
            "iteration: 417150 loss: 0.0016 lr: 0.02\n",
            "iteration: 417160 loss: 0.0015 lr: 0.02\n",
            "iteration: 417170 loss: 0.0025 lr: 0.02\n",
            "iteration: 417180 loss: 0.0020 lr: 0.02\n",
            "iteration: 417190 loss: 0.0017 lr: 0.02\n",
            "iteration: 417200 loss: 0.0013 lr: 0.02\n",
            "iteration: 417210 loss: 0.0012 lr: 0.02\n",
            "iteration: 417220 loss: 0.0019 lr: 0.02\n",
            "iteration: 417230 loss: 0.0019 lr: 0.02\n",
            "iteration: 417240 loss: 0.0016 lr: 0.02\n",
            "iteration: 417250 loss: 0.0012 lr: 0.02\n",
            "iteration: 417260 loss: 0.0017 lr: 0.02\n",
            "iteration: 417270 loss: 0.0012 lr: 0.02\n",
            "iteration: 417280 loss: 0.0016 lr: 0.02\n",
            "iteration: 417290 loss: 0.0014 lr: 0.02\n",
            "iteration: 417300 loss: 0.0015 lr: 0.02\n",
            "iteration: 417310 loss: 0.0017 lr: 0.02\n",
            "iteration: 417320 loss: 0.0016 lr: 0.02\n",
            "iteration: 417330 loss: 0.0018 lr: 0.02\n",
            "iteration: 417340 loss: 0.0012 lr: 0.02\n",
            "iteration: 417350 loss: 0.0019 lr: 0.02\n",
            "iteration: 417360 loss: 0.0015 lr: 0.02\n",
            "iteration: 417370 loss: 0.0016 lr: 0.02\n",
            "iteration: 417380 loss: 0.0013 lr: 0.02\n",
            "iteration: 417390 loss: 0.0014 lr: 0.02\n",
            "iteration: 417400 loss: 0.0014 lr: 0.02\n",
            "iteration: 417410 loss: 0.0014 lr: 0.02\n",
            "iteration: 417420 loss: 0.0021 lr: 0.02\n",
            "iteration: 417430 loss: 0.0017 lr: 0.02\n",
            "iteration: 417440 loss: 0.0022 lr: 0.02\n",
            "iteration: 417450 loss: 0.0019 lr: 0.02\n",
            "iteration: 417460 loss: 0.0014 lr: 0.02\n",
            "iteration: 417470 loss: 0.0016 lr: 0.02\n",
            "iteration: 417480 loss: 0.0013 lr: 0.02\n",
            "iteration: 417490 loss: 0.0015 lr: 0.02\n",
            "iteration: 417500 loss: 0.0014 lr: 0.02\n",
            "iteration: 417510 loss: 0.0016 lr: 0.02\n",
            "iteration: 417520 loss: 0.0015 lr: 0.02\n",
            "iteration: 417530 loss: 0.0015 lr: 0.02\n",
            "iteration: 417540 loss: 0.0016 lr: 0.02\n",
            "iteration: 417550 loss: 0.0012 lr: 0.02\n",
            "iteration: 417560 loss: 0.0018 lr: 0.02\n",
            "iteration: 417570 loss: 0.0014 lr: 0.02\n",
            "iteration: 417580 loss: 0.0016 lr: 0.02\n",
            "iteration: 417590 loss: 0.0016 lr: 0.02\n",
            "iteration: 417600 loss: 0.0014 lr: 0.02\n",
            "iteration: 417610 loss: 0.0015 lr: 0.02\n",
            "iteration: 417620 loss: 0.0014 lr: 0.02\n",
            "iteration: 417630 loss: 0.0018 lr: 0.02\n",
            "iteration: 417640 loss: 0.0018 lr: 0.02\n",
            "iteration: 417650 loss: 0.0016 lr: 0.02\n",
            "iteration: 417660 loss: 0.0017 lr: 0.02\n",
            "iteration: 417670 loss: 0.0015 lr: 0.02\n",
            "iteration: 417680 loss: 0.0011 lr: 0.02\n",
            "iteration: 417690 loss: 0.0012 lr: 0.02\n",
            "iteration: 417700 loss: 0.0015 lr: 0.02\n",
            "iteration: 417710 loss: 0.0024 lr: 0.02\n",
            "iteration: 417720 loss: 0.0015 lr: 0.02\n",
            "iteration: 417730 loss: 0.0018 lr: 0.02\n",
            "iteration: 417740 loss: 0.0015 lr: 0.02\n",
            "iteration: 417750 loss: 0.0016 lr: 0.02\n",
            "iteration: 417760 loss: 0.0014 lr: 0.02\n",
            "iteration: 417770 loss: 0.0017 lr: 0.02\n",
            "iteration: 417780 loss: 0.0012 lr: 0.02\n",
            "iteration: 417790 loss: 0.0015 lr: 0.02\n",
            "iteration: 417800 loss: 0.0021 lr: 0.02\n",
            "iteration: 417810 loss: 0.0013 lr: 0.02\n",
            "iteration: 417820 loss: 0.0024 lr: 0.02\n",
            "iteration: 417830 loss: 0.0017 lr: 0.02\n",
            "iteration: 417840 loss: 0.0013 lr: 0.02\n",
            "iteration: 417850 loss: 0.0018 lr: 0.02\n",
            "iteration: 417860 loss: 0.0020 lr: 0.02\n",
            "iteration: 417870 loss: 0.0010 lr: 0.02\n",
            "iteration: 417880 loss: 0.0012 lr: 0.02\n",
            "iteration: 417890 loss: 0.0015 lr: 0.02\n",
            "iteration: 417900 loss: 0.0016 lr: 0.02\n",
            "iteration: 417910 loss: 0.0014 lr: 0.02\n",
            "iteration: 417920 loss: 0.0015 lr: 0.02\n",
            "iteration: 417930 loss: 0.0018 lr: 0.02\n",
            "iteration: 417940 loss: 0.0019 lr: 0.02\n",
            "iteration: 417950 loss: 0.0014 lr: 0.02\n",
            "iteration: 417960 loss: 0.0015 lr: 0.02\n",
            "iteration: 417970 loss: 0.0014 lr: 0.02\n",
            "iteration: 417980 loss: 0.0016 lr: 0.02\n",
            "iteration: 417990 loss: 0.0013 lr: 0.02\n",
            "iteration: 418000 loss: 0.0016 lr: 0.02\n",
            "iteration: 418010 loss: 0.0017 lr: 0.02\n",
            "iteration: 418020 loss: 0.0016 lr: 0.02\n",
            "iteration: 418030 loss: 0.0012 lr: 0.02\n",
            "iteration: 418040 loss: 0.0017 lr: 0.02\n",
            "iteration: 418050 loss: 0.0013 lr: 0.02\n",
            "iteration: 418060 loss: 0.0017 lr: 0.02\n",
            "iteration: 418070 loss: 0.0009 lr: 0.02\n",
            "iteration: 418080 loss: 0.0016 lr: 0.02\n",
            "iteration: 418090 loss: 0.0019 lr: 0.02\n",
            "iteration: 418100 loss: 0.0015 lr: 0.02\n",
            "iteration: 418110 loss: 0.0022 lr: 0.02\n",
            "iteration: 418120 loss: 0.0014 lr: 0.02\n",
            "iteration: 418130 loss: 0.0021 lr: 0.02\n",
            "iteration: 418140 loss: 0.0013 lr: 0.02\n",
            "iteration: 418150 loss: 0.0016 lr: 0.02\n",
            "iteration: 418160 loss: 0.0016 lr: 0.02\n",
            "iteration: 418170 loss: 0.0021 lr: 0.02\n",
            "iteration: 418180 loss: 0.0011 lr: 0.02\n",
            "iteration: 418190 loss: 0.0013 lr: 0.02\n",
            "iteration: 418200 loss: 0.0012 lr: 0.02\n",
            "iteration: 418210 loss: 0.0017 lr: 0.02\n",
            "iteration: 418220 loss: 0.0015 lr: 0.02\n",
            "iteration: 418230 loss: 0.0019 lr: 0.02\n",
            "iteration: 418240 loss: 0.0015 lr: 0.02\n",
            "iteration: 418250 loss: 0.0016 lr: 0.02\n",
            "iteration: 418260 loss: 0.0022 lr: 0.02\n",
            "iteration: 418270 loss: 0.0016 lr: 0.02\n",
            "iteration: 418280 loss: 0.0020 lr: 0.02\n",
            "iteration: 418290 loss: 0.0016 lr: 0.02\n",
            "iteration: 418300 loss: 0.0015 lr: 0.02\n",
            "iteration: 418310 loss: 0.0020 lr: 0.02\n",
            "iteration: 418320 loss: 0.0016 lr: 0.02\n",
            "iteration: 418330 loss: 0.0015 lr: 0.02\n",
            "iteration: 418340 loss: 0.0017 lr: 0.02\n",
            "iteration: 418350 loss: 0.0016 lr: 0.02\n",
            "iteration: 418360 loss: 0.0014 lr: 0.02\n",
            "iteration: 418370 loss: 0.0013 lr: 0.02\n",
            "iteration: 418380 loss: 0.0017 lr: 0.02\n",
            "iteration: 418390 loss: 0.0016 lr: 0.02\n",
            "iteration: 418400 loss: 0.0018 lr: 0.02\n",
            "iteration: 418410 loss: 0.0012 lr: 0.02\n",
            "iteration: 418420 loss: 0.0016 lr: 0.02\n",
            "iteration: 418430 loss: 0.0014 lr: 0.02\n",
            "iteration: 418440 loss: 0.0019 lr: 0.02\n",
            "iteration: 418450 loss: 0.0013 lr: 0.02\n",
            "iteration: 418460 loss: 0.0014 lr: 0.02\n",
            "iteration: 418470 loss: 0.0016 lr: 0.02\n",
            "iteration: 418480 loss: 0.0014 lr: 0.02\n",
            "iteration: 418490 loss: 0.0018 lr: 0.02\n",
            "iteration: 418500 loss: 0.0017 lr: 0.02\n",
            "iteration: 418510 loss: 0.0012 lr: 0.02\n",
            "iteration: 418520 loss: 0.0024 lr: 0.02\n",
            "iteration: 418530 loss: 0.0019 lr: 0.02\n",
            "iteration: 418540 loss: 0.0016 lr: 0.02\n",
            "iteration: 418550 loss: 0.0021 lr: 0.02\n",
            "iteration: 418560 loss: 0.0015 lr: 0.02\n",
            "iteration: 418570 loss: 0.0019 lr: 0.02\n",
            "iteration: 418580 loss: 0.0015 lr: 0.02\n",
            "iteration: 418590 loss: 0.0015 lr: 0.02\n",
            "iteration: 418600 loss: 0.0018 lr: 0.02\n",
            "iteration: 418610 loss: 0.0016 lr: 0.02\n",
            "iteration: 418620 loss: 0.0017 lr: 0.02\n",
            "iteration: 418630 loss: 0.0015 lr: 0.02\n",
            "iteration: 418640 loss: 0.0018 lr: 0.02\n",
            "iteration: 418650 loss: 0.0013 lr: 0.02\n",
            "iteration: 418660 loss: 0.0015 lr: 0.02\n",
            "iteration: 418670 loss: 0.0017 lr: 0.02\n",
            "iteration: 418680 loss: 0.0016 lr: 0.02\n",
            "iteration: 418690 loss: 0.0017 lr: 0.02\n",
            "iteration: 418700 loss: 0.0013 lr: 0.02\n",
            "iteration: 418710 loss: 0.0012 lr: 0.02\n",
            "iteration: 418720 loss: 0.0021 lr: 0.02\n",
            "iteration: 418730 loss: 0.0020 lr: 0.02\n",
            "iteration: 418740 loss: 0.0012 lr: 0.02\n",
            "iteration: 418750 loss: 0.0013 lr: 0.02\n",
            "iteration: 418760 loss: 0.0022 lr: 0.02\n",
            "iteration: 418770 loss: 0.0014 lr: 0.02\n",
            "iteration: 418780 loss: 0.0013 lr: 0.02\n",
            "iteration: 418790 loss: 0.0014 lr: 0.02\n",
            "iteration: 418800 loss: 0.0017 lr: 0.02\n",
            "iteration: 418810 loss: 0.0013 lr: 0.02\n",
            "iteration: 418820 loss: 0.0016 lr: 0.02\n",
            "iteration: 418830 loss: 0.0017 lr: 0.02\n",
            "iteration: 418840 loss: 0.0020 lr: 0.02\n",
            "iteration: 418850 loss: 0.0020 lr: 0.02\n",
            "iteration: 418860 loss: 0.0014 lr: 0.02\n",
            "iteration: 418870 loss: 0.0016 lr: 0.02\n",
            "iteration: 418880 loss: 0.0014 lr: 0.02\n",
            "iteration: 418890 loss: 0.0018 lr: 0.02\n",
            "iteration: 418900 loss: 0.0017 lr: 0.02\n",
            "iteration: 418910 loss: 0.0012 lr: 0.02\n",
            "iteration: 418920 loss: 0.0019 lr: 0.02\n",
            "iteration: 418930 loss: 0.0015 lr: 0.02\n",
            "iteration: 418940 loss: 0.0011 lr: 0.02\n",
            "iteration: 418950 loss: 0.0017 lr: 0.02\n",
            "iteration: 418960 loss: 0.0024 lr: 0.02\n",
            "iteration: 418970 loss: 0.0014 lr: 0.02\n",
            "iteration: 418980 loss: 0.0017 lr: 0.02\n",
            "iteration: 418990 loss: 0.0017 lr: 0.02\n",
            "iteration: 419000 loss: 0.0018 lr: 0.02\n",
            "iteration: 419010 loss: 0.0020 lr: 0.02\n",
            "iteration: 419020 loss: 0.0013 lr: 0.02\n",
            "iteration: 419030 loss: 0.0017 lr: 0.02\n",
            "iteration: 419040 loss: 0.0014 lr: 0.02\n",
            "iteration: 419050 loss: 0.0018 lr: 0.02\n",
            "iteration: 419060 loss: 0.0016 lr: 0.02\n",
            "iteration: 419070 loss: 0.0014 lr: 0.02\n",
            "iteration: 419080 loss: 0.0014 lr: 0.02\n",
            "iteration: 419090 loss: 0.0014 lr: 0.02\n",
            "iteration: 419100 loss: 0.0014 lr: 0.02\n",
            "iteration: 419110 loss: 0.0015 lr: 0.02\n",
            "iteration: 419120 loss: 0.0018 lr: 0.02\n",
            "iteration: 419130 loss: 0.0020 lr: 0.02\n",
            "iteration: 419140 loss: 0.0016 lr: 0.02\n",
            "iteration: 419150 loss: 0.0012 lr: 0.02\n",
            "iteration: 419160 loss: 0.0021 lr: 0.02\n",
            "iteration: 419170 loss: 0.0018 lr: 0.02\n",
            "iteration: 419180 loss: 0.0018 lr: 0.02\n",
            "iteration: 419190 loss: 0.0016 lr: 0.02\n",
            "iteration: 419200 loss: 0.0016 lr: 0.02\n",
            "iteration: 419210 loss: 0.0020 lr: 0.02\n",
            "iteration: 419220 loss: 0.0014 lr: 0.02\n",
            "iteration: 419230 loss: 0.0018 lr: 0.02\n",
            "iteration: 419240 loss: 0.0012 lr: 0.02\n",
            "iteration: 419250 loss: 0.0012 lr: 0.02\n",
            "iteration: 419260 loss: 0.0018 lr: 0.02\n",
            "iteration: 419270 loss: 0.0016 lr: 0.02\n",
            "iteration: 419280 loss: 0.0015 lr: 0.02\n",
            "iteration: 419290 loss: 0.0012 lr: 0.02\n",
            "iteration: 419300 loss: 0.0012 lr: 0.02\n",
            "iteration: 419310 loss: 0.0017 lr: 0.02\n",
            "iteration: 419320 loss: 0.0014 lr: 0.02\n",
            "iteration: 419330 loss: 0.0018 lr: 0.02\n",
            "iteration: 419340 loss: 0.0022 lr: 0.02\n",
            "iteration: 419350 loss: 0.0022 lr: 0.02\n",
            "iteration: 419360 loss: 0.0014 lr: 0.02\n",
            "iteration: 419370 loss: 0.0016 lr: 0.02\n",
            "iteration: 419380 loss: 0.0017 lr: 0.02\n",
            "iteration: 419390 loss: 0.0013 lr: 0.02\n",
            "iteration: 419400 loss: 0.0011 lr: 0.02\n",
            "iteration: 419410 loss: 0.0022 lr: 0.02\n",
            "iteration: 419420 loss: 0.0016 lr: 0.02\n",
            "iteration: 419430 loss: 0.0019 lr: 0.02\n",
            "iteration: 419440 loss: 0.0019 lr: 0.02\n",
            "iteration: 419450 loss: 0.0012 lr: 0.02\n",
            "iteration: 419460 loss: 0.0014 lr: 0.02\n",
            "iteration: 419470 loss: 0.0015 lr: 0.02\n",
            "iteration: 419480 loss: 0.0018 lr: 0.02\n",
            "iteration: 419490 loss: 0.0016 lr: 0.02\n",
            "iteration: 419500 loss: 0.0018 lr: 0.02\n",
            "iteration: 419510 loss: 0.0016 lr: 0.02\n",
            "iteration: 419520 loss: 0.0016 lr: 0.02\n",
            "iteration: 419530 loss: 0.0017 lr: 0.02\n",
            "iteration: 419540 loss: 0.0017 lr: 0.02\n",
            "iteration: 419550 loss: 0.0013 lr: 0.02\n",
            "iteration: 419560 loss: 0.0021 lr: 0.02\n",
            "iteration: 419570 loss: 0.0017 lr: 0.02\n",
            "iteration: 419580 loss: 0.0017 lr: 0.02\n",
            "iteration: 419590 loss: 0.0016 lr: 0.02\n",
            "iteration: 419600 loss: 0.0016 lr: 0.02\n",
            "iteration: 419610 loss: 0.0020 lr: 0.02\n",
            "iteration: 419620 loss: 0.0013 lr: 0.02\n",
            "iteration: 419630 loss: 0.0026 lr: 0.02\n",
            "iteration: 419640 loss: 0.0015 lr: 0.02\n",
            "iteration: 419650 loss: 0.0013 lr: 0.02\n",
            "iteration: 419660 loss: 0.0017 lr: 0.02\n",
            "iteration: 419670 loss: 0.0018 lr: 0.02\n",
            "iteration: 419680 loss: 0.0015 lr: 0.02\n",
            "iteration: 419690 loss: 0.0014 lr: 0.02\n",
            "iteration: 419700 loss: 0.0020 lr: 0.02\n",
            "iteration: 419710 loss: 0.0015 lr: 0.02\n",
            "iteration: 419720 loss: 0.0011 lr: 0.02\n",
            "iteration: 419730 loss: 0.0014 lr: 0.02\n",
            "iteration: 419740 loss: 0.0018 lr: 0.02\n",
            "iteration: 419750 loss: 0.0012 lr: 0.02\n",
            "iteration: 419760 loss: 0.0019 lr: 0.02\n",
            "iteration: 419770 loss: 0.0015 lr: 0.02\n",
            "iteration: 419780 loss: 0.0023 lr: 0.02\n",
            "iteration: 419790 loss: 0.0011 lr: 0.02\n",
            "iteration: 419800 loss: 0.0015 lr: 0.02\n",
            "iteration: 419810 loss: 0.0011 lr: 0.02\n",
            "iteration: 419820 loss: 0.0013 lr: 0.02\n",
            "iteration: 419830 loss: 0.0016 lr: 0.02\n",
            "iteration: 419840 loss: 0.0013 lr: 0.02\n",
            "iteration: 419850 loss: 0.0015 lr: 0.02\n",
            "iteration: 419860 loss: 0.0019 lr: 0.02\n",
            "iteration: 419870 loss: 0.0014 lr: 0.02\n",
            "iteration: 419880 loss: 0.0013 lr: 0.02\n",
            "iteration: 419890 loss: 0.0023 lr: 0.02\n",
            "iteration: 419900 loss: 0.0014 lr: 0.02\n",
            "iteration: 419910 loss: 0.0020 lr: 0.02\n",
            "iteration: 419920 loss: 0.0018 lr: 0.02\n",
            "iteration: 419930 loss: 0.0018 lr: 0.02\n",
            "iteration: 419940 loss: 0.0016 lr: 0.02\n",
            "iteration: 419950 loss: 0.0019 lr: 0.02\n",
            "iteration: 419960 loss: 0.0016 lr: 0.02\n",
            "iteration: 419970 loss: 0.0015 lr: 0.02\n",
            "iteration: 419980 loss: 0.0017 lr: 0.02\n",
            "iteration: 419990 loss: 0.0015 lr: 0.02\n",
            "iteration: 420000 loss: 0.0018 lr: 0.02\n",
            "iteration: 420010 loss: 0.0020 lr: 0.02\n",
            "iteration: 420020 loss: 0.0018 lr: 0.02\n",
            "iteration: 420030 loss: 0.0017 lr: 0.02\n",
            "iteration: 420040 loss: 0.0013 lr: 0.02\n",
            "iteration: 420050 loss: 0.0014 lr: 0.02\n",
            "iteration: 420060 loss: 0.0019 lr: 0.02\n",
            "iteration: 420070 loss: 0.0013 lr: 0.02\n",
            "iteration: 420080 loss: 0.0020 lr: 0.02\n",
            "iteration: 420090 loss: 0.0018 lr: 0.02\n",
            "iteration: 420100 loss: 0.0014 lr: 0.02\n",
            "iteration: 420110 loss: 0.0018 lr: 0.02\n",
            "iteration: 420120 loss: 0.0013 lr: 0.02\n",
            "iteration: 420130 loss: 0.0014 lr: 0.02\n",
            "iteration: 420140 loss: 0.0012 lr: 0.02\n",
            "iteration: 420150 loss: 0.0016 lr: 0.02\n",
            "iteration: 420160 loss: 0.0014 lr: 0.02\n",
            "iteration: 420170 loss: 0.0026 lr: 0.02\n",
            "iteration: 420180 loss: 0.0014 lr: 0.02\n",
            "iteration: 420190 loss: 0.0013 lr: 0.02\n",
            "iteration: 420200 loss: 0.0014 lr: 0.02\n",
            "iteration: 420210 loss: 0.0014 lr: 0.02\n",
            "iteration: 420220 loss: 0.0010 lr: 0.02\n",
            "iteration: 420230 loss: 0.0014 lr: 0.02\n",
            "iteration: 420240 loss: 0.0017 lr: 0.02\n",
            "iteration: 420250 loss: 0.0016 lr: 0.02\n",
            "iteration: 420260 loss: 0.0019 lr: 0.02\n",
            "iteration: 420270 loss: 0.0012 lr: 0.02\n",
            "iteration: 420280 loss: 0.0016 lr: 0.02\n",
            "iteration: 420290 loss: 0.0014 lr: 0.02\n",
            "iteration: 420300 loss: 0.0016 lr: 0.02\n",
            "iteration: 420310 loss: 0.0015 lr: 0.02\n",
            "iteration: 420320 loss: 0.0017 lr: 0.02\n",
            "iteration: 420330 loss: 0.0015 lr: 0.02\n",
            "iteration: 420340 loss: 0.0016 lr: 0.02\n",
            "iteration: 420350 loss: 0.0017 lr: 0.02\n",
            "iteration: 420360 loss: 0.0012 lr: 0.02\n",
            "iteration: 420370 loss: 0.0017 lr: 0.02\n",
            "iteration: 420380 loss: 0.0013 lr: 0.02\n",
            "iteration: 420390 loss: 0.0021 lr: 0.02\n",
            "iteration: 420400 loss: 0.0015 lr: 0.02\n",
            "iteration: 420410 loss: 0.0014 lr: 0.02\n",
            "iteration: 420420 loss: 0.0016 lr: 0.02\n",
            "iteration: 420430 loss: 0.0015 lr: 0.02\n",
            "iteration: 420440 loss: 0.0025 lr: 0.02\n",
            "iteration: 420450 loss: 0.0024 lr: 0.02\n",
            "iteration: 420460 loss: 0.0013 lr: 0.02\n",
            "iteration: 420470 loss: 0.0016 lr: 0.02\n",
            "iteration: 420480 loss: 0.0018 lr: 0.02\n",
            "iteration: 420490 loss: 0.0017 lr: 0.02\n",
            "iteration: 420500 loss: 0.0017 lr: 0.02\n",
            "iteration: 420510 loss: 0.0016 lr: 0.02\n",
            "iteration: 420520 loss: 0.0015 lr: 0.02\n",
            "iteration: 420530 loss: 0.0016 lr: 0.02\n",
            "iteration: 420540 loss: 0.0014 lr: 0.02\n",
            "iteration: 420550 loss: 0.0025 lr: 0.02\n",
            "iteration: 420560 loss: 0.0020 lr: 0.02\n",
            "iteration: 420570 loss: 0.0015 lr: 0.02\n",
            "iteration: 420580 loss: 0.0016 lr: 0.02\n",
            "iteration: 420590 loss: 0.0015 lr: 0.02\n",
            "iteration: 420600 loss: 0.0018 lr: 0.02\n",
            "iteration: 420610 loss: 0.0014 lr: 0.02\n",
            "iteration: 420620 loss: 0.0018 lr: 0.02\n",
            "iteration: 420630 loss: 0.0026 lr: 0.02\n",
            "iteration: 420640 loss: 0.0017 lr: 0.02\n",
            "iteration: 420650 loss: 0.0012 lr: 0.02\n",
            "iteration: 420660 loss: 0.0019 lr: 0.02\n",
            "iteration: 420670 loss: 0.0018 lr: 0.02\n",
            "iteration: 420680 loss: 0.0015 lr: 0.02\n",
            "iteration: 420690 loss: 0.0012 lr: 0.02\n",
            "iteration: 420700 loss: 0.0017 lr: 0.02\n",
            "iteration: 420710 loss: 0.0014 lr: 0.02\n",
            "iteration: 420720 loss: 0.0017 lr: 0.02\n",
            "iteration: 420730 loss: 0.0018 lr: 0.02\n",
            "iteration: 420740 loss: 0.0011 lr: 0.02\n",
            "iteration: 420750 loss: 0.0018 lr: 0.02\n",
            "iteration: 420760 loss: 0.0019 lr: 0.02\n",
            "iteration: 420770 loss: 0.0015 lr: 0.02\n",
            "iteration: 420780 loss: 0.0015 lr: 0.02\n",
            "iteration: 420790 loss: 0.0020 lr: 0.02\n",
            "iteration: 420800 loss: 0.0018 lr: 0.02\n",
            "iteration: 420810 loss: 0.0015 lr: 0.02\n",
            "iteration: 420820 loss: 0.0014 lr: 0.02\n",
            "iteration: 420830 loss: 0.0014 lr: 0.02\n",
            "iteration: 420840 loss: 0.0010 lr: 0.02\n",
            "iteration: 420850 loss: 0.0019 lr: 0.02\n",
            "iteration: 420860 loss: 0.0011 lr: 0.02\n",
            "iteration: 420870 loss: 0.0015 lr: 0.02\n",
            "iteration: 420880 loss: 0.0017 lr: 0.02\n",
            "iteration: 420890 loss: 0.0017 lr: 0.02\n",
            "iteration: 420900 loss: 0.0016 lr: 0.02\n",
            "iteration: 420910 loss: 0.0012 lr: 0.02\n",
            "iteration: 420920 loss: 0.0020 lr: 0.02\n",
            "iteration: 420930 loss: 0.0016 lr: 0.02\n",
            "iteration: 420940 loss: 0.0015 lr: 0.02\n",
            "iteration: 420950 loss: 0.0016 lr: 0.02\n",
            "iteration: 420960 loss: 0.0019 lr: 0.02\n",
            "iteration: 420970 loss: 0.0014 lr: 0.02\n",
            "iteration: 420980 loss: 0.0015 lr: 0.02\n",
            "iteration: 420990 loss: 0.0016 lr: 0.02\n",
            "iteration: 421000 loss: 0.0017 lr: 0.02\n",
            "iteration: 421010 loss: 0.0017 lr: 0.02\n",
            "iteration: 421020 loss: 0.0012 lr: 0.02\n",
            "iteration: 421030 loss: 0.0018 lr: 0.02\n",
            "iteration: 421040 loss: 0.0018 lr: 0.02\n",
            "iteration: 421050 loss: 0.0016 lr: 0.02\n",
            "iteration: 421060 loss: 0.0013 lr: 0.02\n",
            "iteration: 421070 loss: 0.0016 lr: 0.02\n",
            "iteration: 421080 loss: 0.0019 lr: 0.02\n",
            "iteration: 421090 loss: 0.0013 lr: 0.02\n",
            "iteration: 421100 loss: 0.0019 lr: 0.02\n",
            "iteration: 421110 loss: 0.0015 lr: 0.02\n",
            "iteration: 421120 loss: 0.0012 lr: 0.02\n",
            "iteration: 421130 loss: 0.0021 lr: 0.02\n",
            "iteration: 421140 loss: 0.0013 lr: 0.02\n",
            "iteration: 421150 loss: 0.0022 lr: 0.02\n",
            "iteration: 421160 loss: 0.0017 lr: 0.02\n",
            "iteration: 421170 loss: 0.0025 lr: 0.02\n",
            "iteration: 421180 loss: 0.0013 lr: 0.02\n",
            "iteration: 421190 loss: 0.0017 lr: 0.02\n",
            "iteration: 421200 loss: 0.0017 lr: 0.02\n",
            "iteration: 421210 loss: 0.0014 lr: 0.02\n",
            "iteration: 421220 loss: 0.0015 lr: 0.02\n",
            "iteration: 421230 loss: 0.0013 lr: 0.02\n",
            "iteration: 421240 loss: 0.0022 lr: 0.02\n",
            "iteration: 421250 loss: 0.0022 lr: 0.02\n",
            "iteration: 421260 loss: 0.0023 lr: 0.02\n",
            "iteration: 421270 loss: 0.0015 lr: 0.02\n",
            "iteration: 421280 loss: 0.0017 lr: 0.02\n",
            "iteration: 421290 loss: 0.0014 lr: 0.02\n",
            "iteration: 421300 loss: 0.0016 lr: 0.02\n",
            "iteration: 421310 loss: 0.0013 lr: 0.02\n",
            "iteration: 421320 loss: 0.0013 lr: 0.02\n",
            "iteration: 421330 loss: 0.0014 lr: 0.02\n",
            "iteration: 421340 loss: 0.0014 lr: 0.02\n",
            "iteration: 421350 loss: 0.0016 lr: 0.02\n",
            "iteration: 421360 loss: 0.0015 lr: 0.02\n",
            "iteration: 421370 loss: 0.0018 lr: 0.02\n",
            "iteration: 421380 loss: 0.0014 lr: 0.02\n",
            "iteration: 421390 loss: 0.0020 lr: 0.02\n",
            "iteration: 421400 loss: 0.0017 lr: 0.02\n",
            "iteration: 421410 loss: 0.0015 lr: 0.02\n",
            "iteration: 421420 loss: 0.0011 lr: 0.02\n",
            "iteration: 421430 loss: 0.0010 lr: 0.02\n",
            "iteration: 421440 loss: 0.0021 lr: 0.02\n",
            "iteration: 421450 loss: 0.0013 lr: 0.02\n",
            "iteration: 421460 loss: 0.0020 lr: 0.02\n",
            "iteration: 421470 loss: 0.0012 lr: 0.02\n",
            "iteration: 421480 loss: 0.0011 lr: 0.02\n",
            "iteration: 421490 loss: 0.0017 lr: 0.02\n",
            "iteration: 421500 loss: 0.0016 lr: 0.02\n",
            "iteration: 421510 loss: 0.0015 lr: 0.02\n",
            "iteration: 421520 loss: 0.0015 lr: 0.02\n",
            "iteration: 421530 loss: 0.0015 lr: 0.02\n",
            "iteration: 421540 loss: 0.0017 lr: 0.02\n",
            "iteration: 421550 loss: 0.0012 lr: 0.02\n",
            "iteration: 421560 loss: 0.0013 lr: 0.02\n",
            "iteration: 421570 loss: 0.0021 lr: 0.02\n",
            "iteration: 421580 loss: 0.0017 lr: 0.02\n",
            "iteration: 421590 loss: 0.0019 lr: 0.02\n",
            "iteration: 421600 loss: 0.0012 lr: 0.02\n",
            "iteration: 421610 loss: 0.0022 lr: 0.02\n",
            "iteration: 421620 loss: 0.0015 lr: 0.02\n",
            "iteration: 421630 loss: 0.0015 lr: 0.02\n",
            "iteration: 421640 loss: 0.0017 lr: 0.02\n",
            "iteration: 421650 loss: 0.0014 lr: 0.02\n",
            "iteration: 421660 loss: 0.0014 lr: 0.02\n",
            "iteration: 421670 loss: 0.0017 lr: 0.02\n",
            "iteration: 421680 loss: 0.0017 lr: 0.02\n",
            "iteration: 421690 loss: 0.0012 lr: 0.02\n",
            "iteration: 421700 loss: 0.0012 lr: 0.02\n",
            "iteration: 421710 loss: 0.0012 lr: 0.02\n",
            "iteration: 421720 loss: 0.0020 lr: 0.02\n",
            "iteration: 421730 loss: 0.0014 lr: 0.02\n",
            "iteration: 421740 loss: 0.0012 lr: 0.02\n",
            "iteration: 421750 loss: 0.0013 lr: 0.02\n",
            "iteration: 421760 loss: 0.0017 lr: 0.02\n",
            "iteration: 421770 loss: 0.0013 lr: 0.02\n",
            "iteration: 421780 loss: 0.0016 lr: 0.02\n",
            "iteration: 421790 loss: 0.0010 lr: 0.02\n",
            "iteration: 421800 loss: 0.0014 lr: 0.02\n",
            "iteration: 421810 loss: 0.0021 lr: 0.02\n",
            "iteration: 421820 loss: 0.0017 lr: 0.02\n",
            "iteration: 421830 loss: 0.0013 lr: 0.02\n",
            "iteration: 421840 loss: 0.0022 lr: 0.02\n",
            "iteration: 421850 loss: 0.0015 lr: 0.02\n",
            "iteration: 421860 loss: 0.0018 lr: 0.02\n",
            "iteration: 421870 loss: 0.0016 lr: 0.02\n",
            "iteration: 421880 loss: 0.0014 lr: 0.02\n",
            "iteration: 421890 loss: 0.0018 lr: 0.02\n",
            "iteration: 421900 loss: 0.0017 lr: 0.02\n",
            "iteration: 421910 loss: 0.0013 lr: 0.02\n",
            "iteration: 421920 loss: 0.0012 lr: 0.02\n",
            "iteration: 421930 loss: 0.0018 lr: 0.02\n",
            "iteration: 421940 loss: 0.0019 lr: 0.02\n",
            "iteration: 421950 loss: 0.0017 lr: 0.02\n",
            "iteration: 421960 loss: 0.0012 lr: 0.02\n",
            "iteration: 421970 loss: 0.0015 lr: 0.02\n",
            "iteration: 421980 loss: 0.0013 lr: 0.02\n",
            "iteration: 421990 loss: 0.0013 lr: 0.02\n",
            "iteration: 422000 loss: 0.0017 lr: 0.02\n",
            "iteration: 422010 loss: 0.0017 lr: 0.02\n",
            "iteration: 422020 loss: 0.0022 lr: 0.02\n",
            "iteration: 422030 loss: 0.0021 lr: 0.02\n",
            "iteration: 422040 loss: 0.0019 lr: 0.02\n",
            "iteration: 422050 loss: 0.0013 lr: 0.02\n",
            "iteration: 422060 loss: 0.0013 lr: 0.02\n",
            "iteration: 422070 loss: 0.0016 lr: 0.02\n",
            "iteration: 422080 loss: 0.0018 lr: 0.02\n",
            "iteration: 422090 loss: 0.0012 lr: 0.02\n",
            "iteration: 422100 loss: 0.0017 lr: 0.02\n",
            "iteration: 422110 loss: 0.0014 lr: 0.02\n",
            "iteration: 422120 loss: 0.0014 lr: 0.02\n",
            "iteration: 422130 loss: 0.0014 lr: 0.02\n",
            "iteration: 422140 loss: 0.0015 lr: 0.02\n",
            "iteration: 422150 loss: 0.0016 lr: 0.02\n",
            "iteration: 422160 loss: 0.0013 lr: 0.02\n",
            "iteration: 422170 loss: 0.0016 lr: 0.02\n",
            "iteration: 422180 loss: 0.0014 lr: 0.02\n",
            "iteration: 422190 loss: 0.0015 lr: 0.02\n",
            "iteration: 422200 loss: 0.0014 lr: 0.02\n",
            "iteration: 422210 loss: 0.0014 lr: 0.02\n",
            "iteration: 422220 loss: 0.0017 lr: 0.02\n",
            "iteration: 422230 loss: 0.0013 lr: 0.02\n",
            "iteration: 422240 loss: 0.0017 lr: 0.02\n",
            "iteration: 422250 loss: 0.0026 lr: 0.02\n",
            "iteration: 422260 loss: 0.0026 lr: 0.02\n",
            "iteration: 422270 loss: 0.0018 lr: 0.02\n",
            "iteration: 422280 loss: 0.0018 lr: 0.02\n",
            "iteration: 422290 loss: 0.0014 lr: 0.02\n",
            "iteration: 422300 loss: 0.0016 lr: 0.02\n",
            "iteration: 422310 loss: 0.0013 lr: 0.02\n",
            "iteration: 422320 loss: 0.0014 lr: 0.02\n",
            "iteration: 422330 loss: 0.0016 lr: 0.02\n",
            "iteration: 422340 loss: 0.0022 lr: 0.02\n",
            "iteration: 422350 loss: 0.0016 lr: 0.02\n",
            "iteration: 422360 loss: 0.0015 lr: 0.02\n",
            "iteration: 422370 loss: 0.0015 lr: 0.02\n",
            "iteration: 422380 loss: 0.0020 lr: 0.02\n",
            "iteration: 422390 loss: 0.0015 lr: 0.02\n",
            "iteration: 422400 loss: 0.0012 lr: 0.02\n",
            "iteration: 422410 loss: 0.0013 lr: 0.02\n",
            "iteration: 422420 loss: 0.0016 lr: 0.02\n",
            "iteration: 422430 loss: 0.0015 lr: 0.02\n",
            "iteration: 422440 loss: 0.0015 lr: 0.02\n",
            "iteration: 422450 loss: 0.0020 lr: 0.02\n",
            "iteration: 422460 loss: 0.0017 lr: 0.02\n",
            "iteration: 422470 loss: 0.0018 lr: 0.02\n",
            "iteration: 422480 loss: 0.0014 lr: 0.02\n",
            "iteration: 422490 loss: 0.0020 lr: 0.02\n",
            "iteration: 422500 loss: 0.0020 lr: 0.02\n",
            "iteration: 422510 loss: 0.0013 lr: 0.02\n",
            "iteration: 422520 loss: 0.0017 lr: 0.02\n",
            "iteration: 422530 loss: 0.0013 lr: 0.02\n",
            "iteration: 422540 loss: 0.0017 lr: 0.02\n",
            "iteration: 422550 loss: 0.0016 lr: 0.02\n",
            "iteration: 422560 loss: 0.0014 lr: 0.02\n",
            "iteration: 422570 loss: 0.0016 lr: 0.02\n",
            "iteration: 422580 loss: 0.0013 lr: 0.02\n",
            "iteration: 422590 loss: 0.0014 lr: 0.02\n",
            "iteration: 422600 loss: 0.0019 lr: 0.02\n",
            "iteration: 422610 loss: 0.0017 lr: 0.02\n",
            "iteration: 422620 loss: 0.0013 lr: 0.02\n",
            "iteration: 422630 loss: 0.0020 lr: 0.02\n",
            "iteration: 422640 loss: 0.0015 lr: 0.02\n",
            "iteration: 422650 loss: 0.0017 lr: 0.02\n",
            "iteration: 422660 loss: 0.0014 lr: 0.02\n",
            "iteration: 422670 loss: 0.0011 lr: 0.02\n",
            "iteration: 422680 loss: 0.0025 lr: 0.02\n",
            "iteration: 422690 loss: 0.0013 lr: 0.02\n",
            "iteration: 422700 loss: 0.0018 lr: 0.02\n",
            "iteration: 422710 loss: 0.0014 lr: 0.02\n",
            "iteration: 422720 loss: 0.0023 lr: 0.02\n",
            "iteration: 422730 loss: 0.0019 lr: 0.02\n",
            "iteration: 422740 loss: 0.0017 lr: 0.02\n",
            "iteration: 422750 loss: 0.0015 lr: 0.02\n",
            "iteration: 422760 loss: 0.0014 lr: 0.02\n",
            "iteration: 422770 loss: 0.0018 lr: 0.02\n",
            "iteration: 422780 loss: 0.0012 lr: 0.02\n",
            "iteration: 422790 loss: 0.0020 lr: 0.02\n",
            "iteration: 422800 loss: 0.0018 lr: 0.02\n",
            "iteration: 422810 loss: 0.0023 lr: 0.02\n",
            "iteration: 422820 loss: 0.0012 lr: 0.02\n",
            "iteration: 422830 loss: 0.0014 lr: 0.02\n",
            "iteration: 422840 loss: 0.0016 lr: 0.02\n",
            "iteration: 422850 loss: 0.0020 lr: 0.02\n",
            "iteration: 422860 loss: 0.0016 lr: 0.02\n",
            "iteration: 422870 loss: 0.0019 lr: 0.02\n",
            "iteration: 422880 loss: 0.0016 lr: 0.02\n",
            "iteration: 422890 loss: 0.0016 lr: 0.02\n",
            "iteration: 422900 loss: 0.0018 lr: 0.02\n",
            "iteration: 422910 loss: 0.0017 lr: 0.02\n",
            "iteration: 422920 loss: 0.0019 lr: 0.02\n",
            "iteration: 422930 loss: 0.0015 lr: 0.02\n",
            "iteration: 422940 loss: 0.0015 lr: 0.02\n",
            "iteration: 422950 loss: 0.0017 lr: 0.02\n",
            "iteration: 422960 loss: 0.0016 lr: 0.02\n",
            "iteration: 422970 loss: 0.0014 lr: 0.02\n",
            "iteration: 422980 loss: 0.0016 lr: 0.02\n",
            "iteration: 422990 loss: 0.0011 lr: 0.02\n",
            "iteration: 423000 loss: 0.0016 lr: 0.02\n",
            "iteration: 423010 loss: 0.0018 lr: 0.02\n",
            "iteration: 423020 loss: 0.0018 lr: 0.02\n",
            "iteration: 423030 loss: 0.0015 lr: 0.02\n",
            "iteration: 423040 loss: 0.0022 lr: 0.02\n",
            "iteration: 423050 loss: 0.0026 lr: 0.02\n",
            "iteration: 423060 loss: 0.0013 lr: 0.02\n",
            "iteration: 423070 loss: 0.0021 lr: 0.02\n",
            "iteration: 423080 loss: 0.0021 lr: 0.02\n",
            "iteration: 423090 loss: 0.0015 lr: 0.02\n",
            "iteration: 423100 loss: 0.0017 lr: 0.02\n",
            "iteration: 423110 loss: 0.0015 lr: 0.02\n",
            "iteration: 423120 loss: 0.0016 lr: 0.02\n",
            "iteration: 423130 loss: 0.0016 lr: 0.02\n",
            "iteration: 423140 loss: 0.0016 lr: 0.02\n",
            "iteration: 423150 loss: 0.0016 lr: 0.02\n",
            "iteration: 423160 loss: 0.0014 lr: 0.02\n",
            "iteration: 423170 loss: 0.0016 lr: 0.02\n",
            "iteration: 423180 loss: 0.0021 lr: 0.02\n",
            "iteration: 423190 loss: 0.0012 lr: 0.02\n",
            "iteration: 423200 loss: 0.0016 lr: 0.02\n",
            "iteration: 423210 loss: 0.0016 lr: 0.02\n",
            "iteration: 423220 loss: 0.0017 lr: 0.02\n",
            "iteration: 423230 loss: 0.0013 lr: 0.02\n",
            "iteration: 423240 loss: 0.0011 lr: 0.02\n",
            "iteration: 423250 loss: 0.0017 lr: 0.02\n",
            "iteration: 423260 loss: 0.0014 lr: 0.02\n",
            "iteration: 423270 loss: 0.0017 lr: 0.02\n",
            "iteration: 423280 loss: 0.0011 lr: 0.02\n",
            "iteration: 423290 loss: 0.0014 lr: 0.02\n",
            "iteration: 423300 loss: 0.0014 lr: 0.02\n",
            "iteration: 423310 loss: 0.0022 lr: 0.02\n",
            "iteration: 423320 loss: 0.0015 lr: 0.02\n",
            "iteration: 423330 loss: 0.0013 lr: 0.02\n",
            "iteration: 423340 loss: 0.0018 lr: 0.02\n",
            "iteration: 423350 loss: 0.0016 lr: 0.02\n",
            "iteration: 423360 loss: 0.0015 lr: 0.02\n",
            "iteration: 423370 loss: 0.0012 lr: 0.02\n",
            "iteration: 423380 loss: 0.0017 lr: 0.02\n",
            "iteration: 423390 loss: 0.0016 lr: 0.02\n",
            "iteration: 423400 loss: 0.0019 lr: 0.02\n",
            "iteration: 423410 loss: 0.0016 lr: 0.02\n",
            "iteration: 423420 loss: 0.0013 lr: 0.02\n",
            "iteration: 423430 loss: 0.0012 lr: 0.02\n",
            "iteration: 423440 loss: 0.0010 lr: 0.02\n",
            "iteration: 423450 loss: 0.0015 lr: 0.02\n",
            "iteration: 423460 loss: 0.0013 lr: 0.02\n",
            "iteration: 423470 loss: 0.0014 lr: 0.02\n",
            "iteration: 423480 loss: 0.0015 lr: 0.02\n",
            "iteration: 423490 loss: 0.0015 lr: 0.02\n",
            "iteration: 423500 loss: 0.0012 lr: 0.02\n",
            "iteration: 423510 loss: 0.0014 lr: 0.02\n",
            "iteration: 423520 loss: 0.0016 lr: 0.02\n",
            "iteration: 423530 loss: 0.0015 lr: 0.02\n",
            "iteration: 423540 loss: 0.0013 lr: 0.02\n",
            "iteration: 423550 loss: 0.0016 lr: 0.02\n",
            "iteration: 423560 loss: 0.0013 lr: 0.02\n",
            "iteration: 423570 loss: 0.0016 lr: 0.02\n",
            "iteration: 423580 loss: 0.0019 lr: 0.02\n",
            "iteration: 423590 loss: 0.0013 lr: 0.02\n",
            "iteration: 423600 loss: 0.0016 lr: 0.02\n",
            "iteration: 423610 loss: 0.0014 lr: 0.02\n",
            "iteration: 423620 loss: 0.0019 lr: 0.02\n",
            "iteration: 423630 loss: 0.0017 lr: 0.02\n",
            "iteration: 423640 loss: 0.0017 lr: 0.02\n",
            "iteration: 423650 loss: 0.0015 lr: 0.02\n",
            "iteration: 423660 loss: 0.0016 lr: 0.02\n",
            "iteration: 423670 loss: 0.0011 lr: 0.02\n"
          ]
        }
      ],
      "source": [
        "#let's also change the display and save_iters just in case Colab takes away the GPU... \n",
        "#if that happens, you can reload from a saved point. Typically, you want to train to 200,000 + iterations.\n",
        "#more info and there are more things you can set: https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/functionDetails.md#g-train-the-network\n",
        "\n",
        "deeplabcut.train_network(path_config_file, shuffle=SHUF, displayiters=10, saveiters=500, maxiters=500000)\n",
        "\n",
        "#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 1.03M iterations). \n",
        "#Whichever you chose, you will see what looks like an error message, but it's not an error - don't worry...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWmdkUZ1BMeX"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3xUK2gmNBU7d",
        "outputId": "acc74a61-af71-4f90-d0fd-a55786fc75e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-29187424b64c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mShuffles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSHUF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Here you want to see a low pixel error! Of course, it can only be as good as the labeler,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#so be sure your labels are good! (And you have trained enough ;).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Also note that the test is typically on only a few images, so also good to look\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'deeplabcut' is not defined"
          ]
        }
      ],
      "source": [
        "deeplabcut.evaluate_network(path_config_file,Shuffles=[SHUF], plotting=False)\n",
        "\n",
        "# Here you want to see a low pixel error! Of course, it can only be as good as the labeler, \n",
        "#so be sure your labels are good! (And you have trained enough ;). \n",
        "# Also note that the test is typically on only a few images, so also good to look\n",
        "# at video performance (below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEi6mj5jBYWW"
      },
      "source": [
        "Analyze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB6DrJqeBZoO"
      },
      "outputs": [],
      "source": [
        "deeplabcut.analyze_videos(path_config_file, videofile_path, videotype=VideoType, shuffle=SHUF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBMbwkbTBeHO"
      },
      "source": [
        "Smooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBt-IjguBb5N"
      },
      "outputs": [],
      "source": [
        "deeplabcut.filterpredictions(path_config_file, videofile_path, videotype=VideoType, shuffle=SHUF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erZDJAtJBg6O"
      },
      "source": [
        "Plot Trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgoEuDHTBisd"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "deeplabcut.plot_trajectories(path_config_file, videofile_path, videotype=VideoType, shuffle=SHUF, filtered=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh1EdE4KBlQ2"
      },
      "source": [
        "Create Labeled Video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UNLzhWpBkqd"
      },
      "outputs": [],
      "source": [
        "deeplabcut.create_labeled_video(path_config_file,videofile_path, videotype=VideoType, shuffle=SHUF, filtered=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "digging-assay-colab",
      "provenance": [],
      "authorship_tag": "ABX9TyNwSze2LyabLUj2ptkOL3BI"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}